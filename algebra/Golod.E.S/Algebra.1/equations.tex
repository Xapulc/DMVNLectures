\section{Системы линейных уравнений}\index{системы линейных уравнений}
\label{slu}
%
%\epigraph{We are not interested in the fact that the brain has the consistency of cold porridge.}{Alan Turing}

\subsection{Основные понятия. Метод Гаусса.}\index{метод!Гаусса}

\begin{df}
  Система линейных уравнений (далее: СЛУ) имеет вид
  $$
    \left\{
      \begin{array}{cll}
      a_{11}x_1 + a_{12}x_2+\ldots+a_{1n}x_n & = & b_1\\
      a_{21}x_1 + a_{22}x_2+\ldots+a_{2n}x_n & = & b_2\\
      \ldots&&\\
      a_{m1}x_1 + a_{m2}x_2+\ldots+a_{mn}x_n & = & b_m\\
      \end{array}
    \right.
  $$
\end{df}

  Для удобства имеет смысл рассматривать не саму СЛУ, а матрицу её коэффициентов $A$ или расширенную матрицу коэффициентов $\tilde A$.\index{матрица!коэффициентов}
  $$
  A =
    \begin{pmatrix}
     a_{11}&a_{12}&\dots&a_{1n}\\
     a_{21}&a_{22}&\dots&a_{2n}\\
     \vdots&\vdots&\ddots&\vdots\\
     a_{n1}&a_{n2}&\dots&a_{mn}
    \end{pmatrix}
  \cln
  \tilde A =
    \begin{pmatrix}
     a_{11}&a_{12}&\dots&a_{1n}&\vline&b_1\\
     a_{21}&a_{22}&\dots&a_{2n}&\vline&b_2\\
     \vdots&\vdots&\ddots&\vdots&\vline&\\
     a_{n1}&a_{n2}&\dots&a_{mn}&\vline& b_m
    \end{pmatrix}
  $$

  Также иногда имеет смысл рассматривать всю систему в матричном виде $AX\bw=B$, где $A$ -- матрица коэффициентов, $X$ -- вектор-столбец неизвестных, $B$ -- вектор-столбец свободных членов. В таком случае произведение $A^{(i)}$ на $X$ будет равно $b_i$ и соответствовать $i$-му уравнению системы. Можно рассматривать произведение двух матриц как систему из нескольких систем линейных уравнений.

\begin{df}\index{решение}
  Под решением системы будем понимать набор $x^0 = (x_1^0,\ldots,x_n^0)$, такой, что при подстановке уравнения обращаются в верные равенства. Под понятием <<\emph{решить СЛУ}>> следует подразумевать найти все её решения. Если СЛУ не имеет решений, то она называется \emph{несовместной}\index{системы линейных уравнений!несовместные}. Если СЛУ имеет решения, то она называется \emph{совместной}\index{системы линейных уравнений!совместные}. В таком случае возможно 2 варианта: если существует только единственное решение, то такая система называется \emph{определённой}\index{системы линейных уравнений!определённые}, если же решений бесконечно много, то \emph{неопределённой}\index{системы линейных уравнений!неопределённые}.%
\end{df}

\begin{df}
  Две СЛУ называются \emph{эквивалентными}\index{системы линейных уравнений!эквивалентные}, если они имеют одинаковое множество решений.
\end{df}

Легко понять, что если любую СЛУ рассматривать как расширенную матрицу её коэффициентов, то при ЭП строк этой матрицы множество решений исходной СЛУ не меняется. (\emph{Это прямо вытекает из обратимости ЭП: на каждом шаге множество решений системы не уменьшается})

 Тогда понятно, что от одной из двух эквивалентных СЛУ мы можем перейти к другой при помощи ЭП. Для решения СЛУ мы должны понять, какой вид матрицы её коэффициентов нам больше всего удобен. Оказывается, что наиболее удобно для решения СЛУ приводить матрицу её коэффициентов к так называемому ступенчатому виду.

  После приведения расширенной матрицы коэффициентов, ассоциированной со СЛУ, к ступенчатому виду возможно несколько ситуаций:
  \begin{itemize}
    \item Есть строка, в которой все элементы, кроме самого последнего (столбца свободных членов), равны нулю. Такую строку назовём <<\emph{экзотической}>>. В этом случае СЛУ несовместна.
    \item Если же экзотических строк нет, то система совместна. Далее приведём алгоритм нахождения решений.
  \end{itemize}

  Неизвестные в СЛУ можно разделить на 2 части: главные и свободные так, что если свободным неизвестным придать произвольные значения, то существует единственное решение данной систему, в котором свободные неизвестные принимают эти значения.

  Пусть расширенная матрица коэффициентов СЛУ приведена к ступенчатому виду и в ней нет экзотических строк. Тогда главными неизвестными будем считать те, которым соответствуют столбцы, содержащие лидеров ненулевых строк этой матрицы. Остальные неизвестные будем считать свободными. Опять же, возможно 2 ситуации:
  \begin{enumerate}
    \item Все неизвестные\index{неизвестные!главные} -- главные. Тогда рассмотрим последнюю ненулевую строку расширенной матрицы коэффициентов. В терминах СЛУ оно имеет следующий вид: $a_{nn}x_n = b_n$. Отсюда единственным образом выражается $x_n$. Подставляя его значение в предыдущее уравнение, получаем единственное выражение для $x_{n-1}$ и т.д. В таком случае система является определённой.
    \item Не все неизвестные -- главные. Придадим свободным неизвестным произвольные значения и выражаем главные неизвестные через свободные.\index{неизвестные!свободные}
  \end{enumerate}

  \begin{stm}
    Если в расширенной матрице коэффициентов некоторой СЛУ, приведённой к ступенчатому виду нет экзотических строк, то СЛУ совместна. Если  при этом нет свободных неизвестных, то она определена.
  \end{stm}

  Описанный алгоритм решения СЛУ называется \emph{методом Гаусса} или \emph{методом последовательного исключения неизвестных}.

  \subsection{Однородные СЛУ}\index{системы линейных уравнений!однородные}
  \label{oslu}

  \begin{df}
    СЛУ называется \emph{однородной}, если все её свободные члены равны 0. Очевидно, что однородная СЛУ всегда совместна.
  \end{df}

  \begin{theorem}
    Однородная СЛУ, в которой число уравнений меньше числа неизвестных является неопределённой.
  \end{theorem}
  \begin{proof}
    Пусть число уравнений равно $m$ и оно меньше числа неизвестных $n$. Тогда в ступенчатом виде матрицы коэффициентов число ненулевых строк меньше $n$, оно же равно числу главных неизвестных, тогда есть и свободные неизвестные, система неопределена (<<экзотических>> строк, понятно, нет)
  \end{proof}

  \begin{stm}
    Все решения неоднородной системы уравнений получаются из её одного фиксированного решения прибавлением всевозможных решений ассоциированной с ней однородной системы.

    Если придавать этому геометрический смысл, то решение системы уравнений есть плоскость, полученная сдвигом подпространства решений ассоциированной ОСЛУ на не\-сущий вектор.
  \end{stm}

%====================================================
  \paragraph{Фундаментальная система решений}
  \index{фундаментальная система решений}

\begin{df}
	Пусть есть следующая ОСЛУ:

	$$
		\left\{\begin{array}{rcl}
			a_{11}x_1+a_{12}x_2+\cdots+a_{1n}x_n&=&0 \\
			a_{21}x_1+a_{22}x_2+\cdots+a_{2n}x_n&=&0 \\
			\dots&& \\
			a_{m1}x_1+a_{m2}x_2+\cdots+a_{mn}x_n&=&0
		\end{array}\right.\eqno(*)
	$$

	$U$~--- множество ее решений. Оно образует подпространство в $\R^n$ ($\dim U=r$).
	Тогда всякий базис $U$ называется \emph{фундаментальной системой
	решений}\index{фундаментальная система решений} данной определенной системы линейных
	уравнений.
\end{df}

\begin{theorem}[о ФСР ОСЛУ]
	\label{le:fss}
	Пусть дана система $(*)$ и $r<n$. Тогда у нее существует фундаментальная система
	решений и она содержит $(n-r)$ элементов.
\end{theorem}

\begin{proof}
	Приведем ОСЛУ к ступенчатому виду. Матрица содержит $r$ ненулевых строк, а значит есть
	$r$ независимых и $(n-r)$ свободных неизвестных.
	Для удобства возьмем, что $x_1,\cdots,x_r$~--- главные неизвестные, а
	$x_{r+1},\cdots,x_n$~--- свободные. Тогда возьмем, например, следующую систему
	решений:

\newcommand{\varrow}[1]{\overrightarrow{\mathstrut#1}}

	$$
		\begin{array}{r|c|c|c|c|c|c|l}
			\hline
			{} & \multicolumn{1}{|c|}{x_1} & \dots & x_r & x_{r+1} & \dots & \multicolumn{1}{c|}{x_n} & \\
			\cline{2-7}
			\alpha_{1\phm\phm}\colon     & *   & \dots & *   & 1       & 0      & 0 &
			\multirow{3}{*}{
				\hspace{-1em}
				$\left.\begin{array}{c}\mathstrut \\ \mathstrut \\ \mathstrut\end{array}\right\}
				\text{$(n-r)$ решений}$
			} \\
			\cline{2-7}
			\alpha_{i\phm\phm}\colon     & *   & \dots & *   & 0       & \dots & 0 \\
			\cline{2-7}
			\alpha_{n-r}\colon & *   & \dots & *   & 0       & \dots & 1 \\
			\hline
		\end{array}
	$$

	Надо доказать, что $(\alpha_1,\cdots,\alpha_{n-r})$ является
        фундаментальной системой решений. Тогда, так как любая линейно
        независимая подсистема векторов может быть дополнена до базиса
        системы, все другие ФСР будут иметь то же количество решений.

	\begin{enumerate}
		\item $(\alpha_1,\cdots,\alpha_{n-r})$~--- линейно независимы.
			Вычеркнем первые $r$ компонент из каждого решения: полученная укороченная
			система векторов~--- единичная, а значит линейно независимая. Таким образом,
			вектора $(\alpha_1,\cdots,\alpha_{n-r})$~--- линейно независимы.

		\item Докажем, что любое решение выражается через полученную систему. Пусть есть
			некоторое решение $\beta(\beta_1,\cdots,\beta_n)$. Рассмотрим тогда следующий
			вектор:

			$$
				x=\beta
					-\beta_{r+1}\alpha_{1}
					-\beta_{r+2}\alpha_{2}
					-\cdots
					-\beta_{n}\alpha_{n-r}
					=(\underbrace{*,*,\cdots,*}_{r},\underbrace{0,0,\cdots,0}_{n-r})
			$$

			$x$ является нулевым решением исходной ОСЛУ: значения
			свободных неизвестных равны нулю; главные неизвестные по методу Гаусса
			выражаются через свободные члены и свободные неизвестные, а и те, и другие
			равны нулю.

			Тогда:

			$$
				\beta=
					\beta_{r+1}\alpha_1+
					\beta_{r+2}\alpha_2+
					\cdots+
					\beta_{n}\alpha_{n-r}
			$$

			То есть получили, что любое решение ОСЛУ выражается через систему решений.
	\end{enumerate}

	Таким образом, $(\alpha_1,\cdots,\alpha_{n-r})$~--- фундаментальная система решений.
\end{proof}
%====================================================

  \subsection{Критерии совместности и определённости}
  \index{системы линейных уравнений!совместные}\index{системы линейных уравнений!определённые}
    \paragraph{Теорема Кронеккера-Капелли}\index{теорема!Кронеккера-Капелли}

    \begin{theorem}
      СЛУ совместна тогда и только тогда, когда $\rk A = \rk\tilde A$. СЛУ определённа тогда и только тогда, когда $\rk A=\rk\tilde A$ и равен числу неизвестных.
    \end{theorem}
    %\begin{proof}$$ $$
    %   \begin{itemize}
    %     \item[$\ra$] Если система совместна, то $B$ (столбец свободных членов) выражается через вектора-столбцы. Тем самым $B\in<\! A^{(1)},\dots A^{(n)}\!>\ra\rk\Ab=\rk(\Ab\,\cup B)$
    %     \item[$\la$] Если $\rk\Ab=\rk(\Ab\,\cup B)$ и $\Cb$ -- какая-то максимальная линейно независимая система, то $\Cb\,\cup B$ будет линейно зависимой и $\rk\Cb=\rk(\Cb\,\cup B)$, что означает, что $B$ -- линейная комбинация базисных ($\!\Cb$), то есть система совместна.
    %   \end{itemize}
    %\end{proof}
    \begin{proof}
      Основано на приведении к ступенчатому виду и на теореме о ранге матрицы.
    \end{proof}
    \paragraph{Теорема Крамера}\index{теорема!Крамера}
    \begin{theorem}
      Квадратная система линейных уравнений является определённой в том и только том случае, если определитель её матрицы коэффициентов отличен от 0.
    \end{theorem}
    \paragraph{Формулы Крамера}
    \label{sle:cramer}

Пусть дана СЛУ:
$$
AX=B,\quad
A=
\begin{pmatrix}
a_{11} & \cdots & a_{1n} \\
\vdots & \ddots & \vdots \\
a_{n1} & \cdots & a_{nn}
\end{pmatrix}
,\quad
X=\begin{pmatrix}
x_1 \\ \vdots \\ x_n
\end{pmatrix}
,\quad
B=\begin{pmatrix}
b_1 \\ \vdots \\ b_n
\end{pmatrix}
$$

Можно считать, что $\det A\ne0$. Нулевой определитель матрицы
коэффициентов обозначает, что система либо не имеет решений, либо их
бесконечно много. Этот случай нужно рассматривать отдельно каждый раз.

Если же $\Delta=\det A\ne0$, то СЛУ имеет единственное решение:

$$
X=\underbrace{\frac{\adj A}{\det A}}_{=A^{-1}}
\begin{pmatrix}
  b_1 \\ \vdots \\ b_n
\end{pmatrix}
$$

\begin{note}
	$\adj A$~--- дополнительная матрица к $A$; транспонированная матрица
	алгебраических дополнений к элементам матрицы $A$.
	\begin{center}
	\scalebox{0.7}{
	$
	\adj A=
        \begin{pmatrix}
	A_{11} & \cdots & A_{n1} \\
	\vdots & \ddots & \vdots \\
	A_{1n} & \cdots & A_{nn}
        \end{pmatrix}
	$
  }
  \end{center}
\end{note}

Найдем $i$-ый элемент этой матрицы:

$$
x_i = \frac1{\det A}\left(A_{1i}b_1+A_{2i}b_2+\cdots+A_{ni}b_n\right)
$$

Выражение, стоящее в скобках, является разложением определителя матрицы
$A$ по $i$-ому столбцу, только вместо элементов этого столбца стоят
элементы матрицы $B$. То есть, это определитель матрицы $A$ с $i$-ым
столбцом, замененным на матрицу $B$.

Правило Крамера формулируется следующим образом:

$$
x_i = \frac{\Delta_i}{\Delta_{\phantom{i}}},\quad
\Delta=
\begin{pmatrix}
a_{11} & \cdots & a_{1i} & \cdots & a_{1n} \\
\vdots & \ddots & \vdots & \ddots & \vdots \\
a_{n1} & \cdots & a_{ni} & \cdots & a_{nn}
\end{pmatrix}
,\quad
\Delta_i=\begin{pmatrix}
a_{11} & \cdots & b_1    & \cdots & a_{1n} \\
\vdots & \ddots & \vdots & \ddots & \vdots \\
a_{n1} & \cdots & b_n    & \cdots & a_{nn}
\end{pmatrix}
$$
