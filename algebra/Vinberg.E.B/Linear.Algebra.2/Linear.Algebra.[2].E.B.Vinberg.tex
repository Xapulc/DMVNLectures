%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WARNING. A LOT OF LEGACY MACROS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[a4paper]{article}%
\usepackage[utf8]{inputenc}%
\usepackage[russian]{babel}%
\usepackage{graphicx}%
\usepackage{amsmath}%
\usepackage{amssymb}%
\usepackage{latexsym}%
\usepackage{dmvn}

% Standard page layout
\textheight=250mm
\textwidth=180mm
\oddsidemargin=-10.4mm
\topmargin=-20.4mm

\renewcommand{\c}{\mathbb{C}}
\newcommand{\eps}{\varepsilon}
\newcommand{\pr}{{\rm pr\,}}%
\renewcommand{\rk}{{\rm rk\,}}%
\renewcommand{\de}{\par\noindent\underline{Def}.\ }%
\renewcommand{\ab}{\par\noindent}%
\newcommand{\te}{\par\noindent{\bf Теорема.}\ }%
\newcommand{\dok}{\par\noindent{\textsl{Доказательство}.}\ }%
\newcommand{\qed}{\quad${{\bf Q.E.D.}}$}
\renewcommand{\phi}{\varphi}
\newcommand{\sled}{\par\noindent{\bf Следствие.}\ }%
\newcommand{\baz}[1]{\left(#1_1,\dots,#1_n\right)}%
\newcommand{\lr}{\Leftrightarrow}%
\renewcommand{\nn}[1]{#1_1,#1_2,\dots,#1_n}%
\newcommand{\lob}[1]{\left\langle#1\right\rangle}%
\newcommand{\ps}{\oplus}
\newcommand{\rom}[1]{{\rm#1\,}}
\newcommand{\op}[1]{$\mathcal{#1}$}
\renewcommand{\om}[1]{\mathcal{#1}}
\newcommand{\oi}[1]{\overrightarrow{#1}}%
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
\newcommand{\we}[1]{\widehat{#1}}
\newcommand{\ty}{\otimes}

\begin{document}
\dmvntitle{Курс лекций}{
  по линейной алгебре}{
  Лектор -- Э.Б.Винберг}{
  II курс, 4й семестр}{2003}
\section{Базис и размерность векторного пространства.}%
\label{q1}%
\par\de Векторным пространством над полем $K$ называется аддитивная абелева группа $V$, в которой определена
операция умножения на элементы поля $K$ так, что выполнены следующие условия:
\begin{enumerate}
    \item $\lambda(a+b)=\lambda a+\lambda b \qquad \mbox{для всех } \lambda\in K \mbox{ и }a, b\in V;$
    \item $(\lambda+\mu)a=\lambda a+\mu a \qquad\mbox{для всех }\lambda, \mu\in K\mbox{ и }a\in V;$
    \item $(\lambda\mu)a=\lambda(\mu a) \qquad\mbox{для всех }\lambda, \mu\in K\mbox{ и }a\in V;$
    \item $1\cdot a=a\qquad\mbox{для любого }a\in V.$
\end{enumerate}
\abЭлементы поля $K$ называются скалярами (числами).%
\ab\underline{Простейшие следствия из аксиом}:
\begin{enumerate}
    \item $\lambda\cdot 0=0\qquad\mbox{для всех }\lambda\in K;$
    \item $\lambda(a-b)=\lambda a-\lambda b\qquad\mbox{для всех }\lambda\in K \mbox{ и }a, b\in V;$
    \item $0\cdot a=0\qquad\mbox{для любого }a\in V;$
    \item $(\lambda-\mu)a=\lambda a-\mu a\qquad\mbox{для всех }\lambda,\mu\in K\mbox{ и }a\in V.$
\end{enumerate}
\de Пусть есть система векторов $\{a_i\} _{i\in I}$ (не обязательно конечная). Линейной комбинацией этой
системы векторов называется выражение $\sum\limits_{i\in I} \lambda_i a_i$, где $\lambda_i\in K$, причем лишь
конечное
число $\lambda_i$ отлично от нуля. %

\de Система векторов $\{a_i\}_{i\in I}$ называется линейно зависимой, если существует их нетривиальная линейная
комбинация, равная нулю. %

\de Базисом векторного пространства называется максимальная линейно независимая система его векторов
($\Leftrightarrow$ линейно независимая система векторов, через которую любой вектор линейно выражается
$\Leftrightarrow$ система векторов, через которую всякий вектор линейно выражается \\ единственным образом). %
\ab Коэффициенты этого выражения называются координатами вектора в базисе $\{e_i\}_{i\in I}$\,: %
\ab если $x=\sum\limits_{i\in I} x_i e_i$\,, то $x_i$ - координаты вектора $x$. %
\de Векторное пространство называется конечномерным, если в нём существует конечный базис. %
\te В конечномерном векторном пространстве все базисы равномощны. %
\dok Первый семестр: доказывается, что конечные эквивалентные линейно независимые системы строк
равномощны, что
следует из основной леммы о линейной зависимости. \qed %
\de Число векторов базиса пространства $V$ называется размерностью данного пространства и обозначается $\dim V$.
\de Отображение векторных пространств $\varphi :V_1\rightarrow V_2$ (над одним и тем же полем $K$) называется
изоморфизмом, если:
\begin{enumerate}
    \item $\varphi$ биективно;
    \item $\varphi$ сохраняет операции, то есть:
    \begin{itemize}
        \item $\varphi(a+b)=\varphi(a)+\varphi(b)\qquad\mbox{для всех }a,b\in V;$
        \item $\phi(\lambda a)=\lambda\phi(a)\qquad\mbox{для всех }\lambda\in K\mbox{ и }a\in V.$
    \end{itemize}
\end{enumerate}
\ab Если $\phi$ - изоморфизм, то $\phi(0)=0$ и $\phi\left(\sum\limits_{i\in I}\lambda_i
a_i\right)=\sum\limits_{i\in I}\lambda_i\phi\left(a_i\right)$, и поэтому $\phi$ сохраняет линейную зависимость
систем векторов и переводит базис $V_1$ в базис $V_2$. %
\de Векторные пространства называются изоморфными, если между ними существует хотя бы один изоморфизм. %
\te Векторные пространства конечной размерности изоморфны тогда и только тогда, когда
их размерности равны. %
\dok 1) Если $\varphi :V_1\rightarrow V_2$ - изоморфизм и $(e_1,\dots,e_n)$ - базис $V_1$, то
$\left(\phi(e_1),\dots,\phi(e_n)\right)$ - базис $V_2$; %
\ab 2) Пусть $\dim V_1=\dim V_2$, $(e_1,\dots,e_n)$ - базис $V_1$, $(f_1,\dots,f_n)$ - базис $V_2$. Определим
$\varphi :V_1\rightarrow V_2$ по формуле\ \ $\phi\left(\sum\limits_{i}\lambda_i
e_i\right)=\sum\limits_{i}\lambda_i f_i$. Очевидно, что $\phi$ - изоморфизм $V_1$ и $V_2$. \qed %
\sled Всякое $n$-мерное векторное пространство над $K$ изоморфно $K^n$ (изоморфизм осуществляется сопоставлением
каждому вектору строки из его координат в каком-либо фиксированном базисе). %
\section{Преобразования координат в векторном пространстве.}%
\label{q2}%
\ab Пусть есть $(e_1,\dots,e_n)$ - базис пространства $V$ и $(e'_1,\dots,e'_n)$ - система $n$ векторов
пространства $V$. Пусть эти вектора выражаются через базисные следующим образом:
$$
e'_j=\sum_{i=1}^nc_{ij}e_i\qquad(j=1,2,\dots,n)
$$
\ab Матрица, составленная из чисел $c_{ij}$ называется матрицей перехода $C=(c_{ij})$ от базиса $\baz{e}$ к
системе векторов $\baz{e'}$. Матричная запись: \ \ $\baz{e'}=\baz{e}\cdot C$. %
\te $\baz{e'}$ - базис $\lr$ матрица $C$ невырождена. %
\dok Установим изоморфизм между пространствами $V$ и $K^n$, поставив в соответствие каждому вектору столбец его
координат в базисе $\baz{e}$. При этом изоморфизме векторам $\nn{e'}$ будут соответствовать столбцы матрицы $C$.
Система $\baz{e'}$ линейно независима $\lr$ столбцы матрицы $C$ линейно независимы $\lr$ $C$ невырождена. \qed %
\ab Если $C$ невырождена, то $\baz{e}=\baz{e'}C^{-1}$. Выведем формулы преобразования координат. Пусть $
x=\sum_ix_ie_i;\quad x'=\sum_j x'_j e'_j. $ \ab Тогда $x=\sum\limits_j x'_j
e'_j=\sum\limits_{i,j}x'_jc_{ij}e_i=\sum\limits_i\left(\sum\limits_jc_{ij}x'_j\right)e_i$, значит
$$
x_i=\sum_{j=1}^nc_{ij}x'_j\qquad(i=1,2,\dots,n)
$$
\ab В матричной форме: пусть $X=\baz{x}^{\top},\ X'=(x'_1,x'_2,\dots,x'_n)^{\top}$. Тогда $x=\baz{e}X=\baz{e'}X'$,
значит $\baz{e}X=\baz{e}CX'\ \Rightarrow \ X=CX'$, таким образом
$$
X'=C^{-1}X.
$$

\section{Подпространства как множества решений систем однородных линейных уравнений.}
\label{q3} %
\de Подмножество $U$ векторного пространства $V$ называется подпространством, если:
\begin{enumerate}
    \item $a,b\in U\ \Rightarrow\ a+b\in U;$
    \item $a\in U\ \Rightarrow\ \lambda a\in U\qquad \forall\lambda\in K;$
    \item $0\in U\qquad\mbox{(непустота $U$)}.$
\end{enumerate}
\de Пусть $S\subset V$. Линейной оболочкой $S$ называется множество
$$
\left\langle S\right\rangle=\left\{ \sum_{i}\lambda_ix_i\ :\  x_i\in S, \lambda_i\in K \right\}.
$$
\ab Очевидно, что $\lob{S}$ - подпространство.\\ Более того, это наименьшее подпространство, содержащее $S$
({в том смысле, что любое подпространство, содержащее }$S${, должно содержать и }$\lob{S}$), приём
$\dim S=\rk S,$ и любая максимальная линейно независимая подсистема в $S$ является базисом $\lob{S}$. %
\de Базис $\baz{e}$ пространства $V$ называется согласованным с подпространством $U$, если $U$ натянуто на
какие-то из базисных векторов. %
\te Для любого подпространства $U$ существует согласованный с ним базис пространства $V$. %
\dok Пусть $(e_1,\dots,e_k)$ - базис $U$. Дополним его до базиса $\baz{e}$ всего пространства. Это и будет
искомый
базис пространства $V$. \qed %
\sled $\dim U\leq \dim V$, причём $\dim U=\dim V \ \Rightarrow\ U=V$. %
\te Всякое подпространство $U\subset K^n$ есть множество решений некоторой системы однородных линейных
уравнений. \dok Пусть $\baz{e}$ - стандартный базис пространства $K^n$, $\baz{e'}$ - такой базис, что
$U=\lob{e'_1,\dots,e'_k}$. Тогда в базисе $\baz{e'}$ $U$ задаётся так:
$$
U=\left\{x=\sum_jx'_je'_j, \quad x'_{k+1}=\dots=x'_n=0\right\}.
$$
\ab Пусть $\baz{e'}=\baz{e}C$, тогда
$
\left(%
\begin{array}{c}
  x'_1 \\
  \vdots \\
  x'_n \\
\end{array}%
\right) =C^{-1}\left(%
\begin{array}{c}
  x_1 \\
  \vdots \\
  x_n \\
\end{array}%
\right).$ Подставляя в уравнения, задающие подпространство $U$ в базисе $\baz{e'}$ выражения координат
$\nn{x'}$ через координаты \\ $\nn{x}$, получим систему однородных линейных уравнений относительно $\nn{x}$, \\
задающую $U$ в
стандартном базисе $\baz{e}$ пространства $V$. \qed %
\section{Связь между размерностями суммы и пересечения \\ двух подпространств.}
\label{q4} %
\te Для любых двух подпространств $U,W\subset V$ существует базис пространства $V$, согласованный с ними обоими.
\dok Рассмотрим $U\cap W$ - также подпространство в $V$. Пусть $(e_1,\dots,e_p)$ - базис $U\cap W$. Дополним его
до базиса $(e_1,\dots,e_p,e_{p+1},\dots,e_k)$ подпространства $U$ и его же - до базиса
$(e_1,\dots,e_p,\\e_{k+1},\dots,e_{k+l-p})$ подпространства $W$ (здесь $\dim U=k,\ \dim W=l$). Докажем, что
система векторов $e_1,\dots,e_{k+l-p}$ линейно независима (тогда дополним её до базиса пространства $V$, он и
будет искомым).\\ Предположим, что $\sum\limits_{i=1}^{k+l-p}\lambda_i e_i=0$. Тогда $
\sum\limits_{i=1}^{k}\lambda_ie_i=-\sum\limits_{j=1}^{k+l-p}\lambda_je_j$. Правая часть равенства - это линейная
комбинация базисных векторов подпространства $U$, левая - подпространства $W$. Значит
\\ $x=\sum\limits_{i=1}^{k}\lambda_ie_i\in U\cap W$, поэтому $x=\sum\limits_{i=1}^p\mu_ie_i=-\sum
\limits_{j=k+1}^{k+l-p}\lambda_je_j$ (разложение вектора $\in U\cap W$ по базису этого подпространства). Перенося
всё в одну часть, получим $\sum\limits_{i=1}^p\mu_ie_i+\sum\limits_{j=k+1}^{k+l-p}\lambda_je_j=0$. Значит,
$\mu_i=\lambda_j=0\ (i=1,\dots,p\,; j=k+1,\dots,k+l-p)\ \Rightarrow\ x=0\ \Rightarrow\ \lambda_i=0\
(i=1,\dots,k).$ Поэтому векторы $(e_1,\dots,e_{k+l-p})$ линейно независимы. \qed %
\de Суммой подпространств $U$ и $W\in V$ называется подпространство $U+W=\lob{U\cup W}$ - наименьшее
подпространство, содержащее $U$ и $W$. Ясно, что $U+W=\left\{u+w\ :\ u\in U, w\in W\right\}$ (такие векторы должны
быть в $U+W$, но и сами они уже образуют подпространство). %
\sled $\dim(U+W)=\dim U+\dim W-\dim(U\cap W).$ %
\dok $\dim(U+W)=k+l-p=\dim U+\dim W-\dim(U\cap W)$ - в обозначениях предыдущей теоремы: $k+l-p$ линейно
независимых векторов составляют базис $U+W$. \qed %
\ab Для трёх подпространств, вообще говоря, не существует согласованного с ними базиса \\
(рассмотреть 3 одномерных подпространства в $\mathbb{R}^2$).
\section{Линейная независимость подпространств.\\ Базис и размерность прямой суммы}
\label{q5} %
\de Подпространства $U_1,\dots,U_k\subset V$ называются линейно независимыми, если \\$u_1+\dots+u_k=0\ (u_i\in
U_i)\ \Rightarrow\ u_1=u_2=\dots=u_k=0.$ %

\te Два подпространства $U$ и $W$ линейно независимы $\lr\ U\cap W=0.$ %
\dok $u+w=0\ \lr\ u=-w\in U\cap W.$ Если $U\cap W=0$, то $u=w=0.$ Обратно, если существует ненулевой вектор $z\in
U\cap W$, то, сложив его с противоположным, получим $z+(-z)=0$, где $z\in U, \ -z\in W$. \qed %
\\Для трёх подпространств если их попарные пересечения равны $\{0\}$, то это не означает их линейной
независимости. %
\te Если подпространства $U_1,\dots,U_k$ линейно независимы, то размерность их суммы равна сумме их размерностей:
$\dim(U_1+\dots+U_k)=\dim U_1+\dots+\dim U_k.$ %
\dok Пусть $\left(e_{i1},\dots,e_{i{n_i}}\right)$ - базис в $U_i\ (i=1,\dots,k),$ $\dim U_i=n_i.$ Докажем, что \\
$(e)=(e_{ij}\ :\ i=1,\dots,k;\ j=1,\dots,n_i)$ - базис $U_1+\dots+U_k$: %
\ab 1) Каждый вектор $u\in U_1+\dots+U_k$ имеет вид $u=u_1+\dots+u_k\ (u_i\in U_i)\Rightarrow$ выражается через $(e);$%
\ab 2)Векторы $(e)$ линейно независимы. Действительно, предположим, что $\sum\limits_{i,j}\lambda_{ij}e_{ij}=0.$
Тогда \\
$\sum\limits_i\left(\sum\limits_j\lambda_{ij}e_{ij}\right)=0$; но $\forall i\ \sum\limits_j\lambda_{ij}e_{ij} \in
U_i\ \Rightarrow\ \sum\limits_j\lambda_{ij}e_{ij}=0\ \Rightarrow\ \forall i\ \forall j\ \lambda_{ij}=0$ (так
как мы имеем линейную комбинацию базисных векторов каждого из подпространств). \qed%
\de Сумма линейно независимых подпространств называется прямой суммой. Обозначается:\\ $U_1\oplus
U_2\oplus\dots\oplus U_k$. Если $U_1\ps\dots\ps U_k=V$, то говорят, что пространство $V$ разложено в прямую сумму
подпространств $U_1,\dots,U_k$. В этом случае $\dim V=\dim U_1+\dots+\dim U_k$. Каждый вектор из $V$ единственным
образом представляется в виде $x=x_1+\dots+x_k, \mbox{ где }x_i\in U_i.$ Вектор $x_i$ называется проекцией
$x\mbox{ на }U_i$ и обозначается $x_i=\pr_{U_i}x$ что зависит от всего разложения пространства $V$ в прямую сумму.
\section{Линейные отображения, их запись в координатах.\\ Образ и ядро линейного отображения,\\ связь между их размерностями.}
\label{q6} %
\de Отображение $\phi :V\rightarrow U$ векторных пространств над полем $K$ называется линейным, если:
\begin{enumerate}
    \item $\phi(x+y)=\phi(x)+\phi(y)\qquad\mbox{для любых }x,y\in V;$
    \item $\phi(\lambda x)=\lambda\phi(x)\qquad\mbox{для любых }\lambda\in K\mbox{ и }x\in V.$
\end{enumerate}
\ab \underline{Свойства}: %
\ab $\phi(0)=0$ %
\ab $\phi\left(\lambda_1x_1+\dots+\lambda_kx_k\right)=\lambda_1\phi(x_1)+\dots+\lambda_k\phi(x_k);$ %
\ab Линейно зависимая система векторов переходит в линейно зависимую. %
Линейное отображение конечномерных векторных пространств полностью определяется образами базисных векторов: %
\ab Пусть $\baz{e}$ - базис пространства $V$. Линейное отображение $\phi :V\rightarrow U$ однозначно
определяется векторами $\phi(e_j)=u_j.$ Действительно, $x=\sum\limits_jx_je_j\ \Rightarrow\
\phi(x)=\sum\limits_jx_ju_j.$ Обратно, если заданы любые векторы $u_j\in U$, то можно определить линейное
отображение $\phi :V\rightarrow U$ по формуле $x=\sum\limits_jx_je_j\ \Rightarrow\ \phi(x)=\sum\limits_jx_ju_j.$
Оно будет линейным и $\phi(e_j)=u_j.$%
\ab Если в пространстве $U$ выбран базис $(f_1,\dots,f_m)$, то $u_j$ можно разложить по этому базису:\\%
$u_j=\sum\limits_ia_{ij}f_i$. Матрица $A=\left(a_{ij}\right)$ называется матрицей линейного отображения $\phi$
относительно выбранных базисов пространств $V$ и $U$. Координаты образов базисных векторов пишутся по столбцам,
$(\phi(e_1),\dots,\phi(e_n))=(f_1,\dots,f_m)A.$ %
\ab $$x=\sum\limits_jx_je_j\in V\ \Rightarrow\ \phi(x)=\sum\limits_jx_ju_j=\sum\limits_{i,j}x_ja_{ij}f_i=%
\sum\limits_i\left(\sum\limits_jx_ja_{ij}\right)f_i,$$ значит, если обозначить $\phi(x)=y=\sum\limits_iy_if_i$, \
\ то\ \  $y_i=\sum\limits_ja_{ij}x_j\quad(i=1,\dots,m)$. \\ В матричной форме $Y=AX$, где $X=(\nn{x})^\top,
Y=(\nn{y})^\top$. %
\de Пусть $\phi :V\rightarrow U$. Образом $\phi$ называется подмножество ${\rm Im\,}\phi=\left\{\phi(x)\ :\ x\in V
\right\}\subset U;$\\ ядром $\phi$ - подмножество ${\rm Ker\,}\phi=\left\{x\in V\ :\ \phi(x)=0\right\}\subset V.$
\te \begin{enumerate}
    \item $\rom{Im}\phi$ - подпространство в $U$, $\dim\rom{Im}\phi=\rk A$, где $A$ - матрица $\phi$;
    \item $\rom{Ker}\phi$ - подпространство в $V$, $\dim\rom{Ker}\phi=\dim V-\rk A;$
    \item $\forall\ b=\phi(a)\in\rom{Im}\phi\quad \phi^{-1}(b)=a+\rom{Ker}\phi$ (полный прообраз равен смежному классу по
    ядру,\\ в частности, $\phi$ инъективно $\lr$ $\rom{Ker}\phi=0$).
\end{enumerate}
\dok \begin{enumerate}
    \item $\phi(x)+\phi(y)=\phi(x+y)\in\rom{Im}\phi;\\
    \lambda\phi(x)=\phi(\lambda x)\in\rom{Im}\phi;\\
    0=\phi(0)\in\rom{Im}\phi\Rightarrow\rom{Im}\phi$ - подпространство.
    \ab
    $\rom{Im}\phi=\lob{\phi(e_1),\dots,\phi(e_n)}\Rightarrow\dim\rom{Im}\phi=\rk(\phi(e_1),\dots,\phi(e_n)).$\\
    Но система векторов $(\phi(e_1),\dots,\phi(e_n))$ - это система столбцов матрицы $A$.
    \item $\phi(x)=\phi(y)=0\Rightarrow\phi(x+y)=\phi(x)+\phi(y)=0;\\
    \phi(x)=0\Rightarrow\phi(\lambda x)=\lambda\phi(x)=0;\\
    \phi(0)=0\Rightarrow\rom{Ker}\phi$ - подпространство.
    \ab Пусть $(e_1,\dots,e_k)$ - базис $\rom{Ker}\phi$, $\baz{e}$ - базис $V$.
    Тогда $\rom{Im}\phi=\lob{\phi(e_{k+1}),\dots,\phi(e_n)}$. Докажем, что $\phi(e_{k+1}),\dots,\phi(e_n)$ линейно
    независимы. Пусть $\lambda_{k+1}\phi(e_{k+1})+\dots+\lambda_n\phi(e_n)=0.$ Тогда
    $$\phi\left(
    \lambda_{k+1}{e_{k+1}}+\dots+\lambda_ne_n\right)=0,$$
    значит $ \lambda_{k+1}{e_{k+1}}+\dots+
    \lambda_ne_n\in\rom{Ker}\phi\Rightarrow \lambda_{k+1}=\dots=\lambda_n=0$ (иначе базис $V$ линейно зависим).
    Таким образом $\dim\rom{Im}\phi=n-k=\dim V-\dim\rom{Ker}\phi.$
    \item Пусть $b=\phi(a)\in\rom{Im}\phi$.\\ $\forall\ y\in\rom{Ker}\phi\quad\phi(a+y)=\phi(a)+\phi(y)=b.$
    \ab Обратно, $\phi(x)=b\Rightarrow \phi(x-a)=\phi(x)-\phi(a)=0\Rightarrow x-a=y\in\rom{Ker}\phi\Rightarrow x=a+y,
    \ y\in\rom{Ker}\phi.$ Значит, $\phi^{-1}(b)=a+\rom{Ker}\phi.$ В частности, $\phi$ - инъективно $\lr |\phi^{-1}(a)|=1
    \lr \rom{Ker}\phi=0.$ \qed
\end{enumerate}

\section{Линейные функции, их запись в координатах. \\Сопряжённое пространство и сопряжённые базисы.}
\label{q7} %
\de Функция $\alpha$ на векторном пространстве $V$ со значениями в поле $K$ называется линейной, если:
\begin{enumerate}
    \item $\alpha(x+y)=\alpha(x)+\alpha(y)\qquad\forall\ x,y\in V;$
    \item $\alpha(\lambda x)=\lambda\alpha(x)\qquad\forall\ \lambda\in K,\ \forall\ x\in V.$
\end{enumerate}
Это специальный случай линейного отображения - отображение из $V$ в поле $K$, рассматриваемое как векторное
пространство над самим собой ($\dim=1$).%
\ab Запись линейной функции в координатах: %
\ab Пусть $\baz{e}$ - базис $V$,\ \  $x=\sum\limits_{i=1}^nx_ie_i\Rightarrow
\alpha(x)=\sum\limits_{i=1}^nx_i\alpha(e_i).$ Положим $a_i=\alpha(e_i)$, тогда $$\alpha(x)=\sum\limits_ia_ie_i.$$
Числа $a_i$ называются координатами линейной функции $\alpha$ в базисе $\baz{e}$. %
\ab Преобразования координат при переходе к другому базису:
$$
\baz{e'}=\baz{e}C\ \  \Rightarrow \ \ \baz{a'}=\baz{a}C.
$$
\ab Если $\alpha\neq 0$, то можно выбрать базис, в котором $\alpha(x)=x_1$. Действительно,
$\dim\rom{Ker}\alpha=n-1$, пусть $(e_2,\dots,e_n)$ - базис $\rom{Ker}\alpha$. Возьмём $e_1{\notin}\
\rom{Ker}\alpha$, такой, что $\alpha(e_1)=1$. Тогда $\baz{e}$ - базис $V$, и в нём $\alpha(x)=x_1$. %
\ab Пространство линейных функций $L(V,K)$ образует линейное (векторное) пространство над $K$.\\ Оно обозначается
$V^*$ и называется сопряжённым к $V$ пространством. %
\ab Пусть $\baz{e}$ - базис $V$. Рассмотрим координатные функции $\eps_i(x)=x_i$. %
\te $\baz{\eps}$ - базис $V^*$. %
\dok $\alpha(x)=\sum\limits_ia_ix_i\Rightarrow \alpha=\sum\limits_ia_i\eps_i.$ С другой стороны, если $\sum
a_i\eps_i=0$, то \\
$\left(\sum\limits_i a_i\eps_i\right)\left(e_j\right)=a_j=0\ \Rightarrow\  a_1=\dots=a_n=0.$ \qed %
\sled Для конечномерного пространства $\dim V^*=\dim V.$ %
\de Базис $\baz{\eps}$ называется сопряжённым к базису $\baz{e}$.
\section{Канонический изоморфизм конечномерного векторного \\ пространства и второго сопряжённого пространства.}
\label{q8} %
Рассмотрим отображение $f:V\rightarrow V^{**}$, $x\mapsto f_x$, такое, что $f_x(\alpha)=\alpha(x).$ %
\te $f$ - изоморфизм. %
\dok
\begin{enumerate}
    \item $f$ линейно:
    \ab $f_{x+y}(\alpha)=\alpha(x+y)=\alpha(x)+\alpha(y)=f_x(\alpha)+f_y(\alpha),$ то есть $f_{x+y}=f_x+f_y;$
    \ab $f_{\lambda x}(\alpha)=\alpha(\lambda x)=\lambda \alpha(x)=\lambda f_x(\alpha),$ то есть $f_{\lambda x}=\lambda f_x.$
    \item $\dim V=\dim V^{**},$ поэтому достаточно доказать, что $\rom{Ker}f=0.$
    \ab $x\in\rom{Ker}f\Rightarrow f_x(\alpha)=0\ \forall\ \alpha\in V^*\lr \alpha(x)=0\ \forall\ \alpha\in V^*\lr
    x=0$ \qed
\end{enumerate}
\sled Всякий базис пространства $V^*$ сопряжён некоторому базису пространства $V$. %
\ab{\bf Замечание. } Если $\nn{e}\in V,\ \nn{\eps}\in V^*$, причём $\eps_i(e_j)=\delta_{ij}$, то $\baz{e}$ и
$\baz{\eps}$ - сопряжённые базисы. %
\ab Действительно, если $\sum\limits_i\lambda_ie_i=0,$ то рассмотрев значение $\eps_j$ от обеих частей равенства,
получим $\lambda_j=0\ \forall\ j\Rightarrow \baz{e}$ - базис в $V\ \Rightarrow\ \baz{\eps}$ - сопряжённый ему
базис $V^*$.

%============================================================================================

\section{Билинейные функции, их запись в координатах.\ab Изменение матрицы билинейной функции при переходе\\ к другому базису.}
\label{q9}%
\de Билинейной функцией $\alpha$ на векторном пространстве $V$ над полем $K$ называется отображение
$\alpha:V\times
V\rightarrow K$, линейное по каждому аргументу. %
\ab Запись в координатах: %
\ab Пусть $\baz{e}$ - базис пространства $V$, $x=\sum\limits_ix_ie_i,\ y=\sum\limits_jy_je_j$.\ab %
$\alpha(x,y)=\sum\limits_{i,j}x_iy_j\cdot\alpha(e_i,e_j)$. Положим $a_{ij}=\alpha(e_i,e_j),$ тогда
$\alpha(x,y)=\sum\limits_{i,j}a_{ij}x_iy_j.$ %
\ab Матрица $A=(a_{ij})$ называется матрицей билинейной функции $\alpha$ в базисе $\baz{e}$. В матричной форме:
$$
X=\left(%
\begin{array}{c}
  x_1 \\
  \vdots \\
  x_n \\
\end{array}%
\right),\ Y=\left(%
\begin{array}{c}
  y_1 \\
  \vdots \\
  y_n \\
\end{array}%
\right)\quad\Rightarrow\quad\alpha(x,y)=X^\top AY.
$$
При переходе к другому базису $\baz{e'}$: %
\ab $\baz{e'}=\baz{e}C\quad\Rightarrow\quad X=CX',\ Y=CY'.$ Тогда $\alpha(x, y)=X^\top AY=X'^\top C^\top ACY'.$
Таким образом,
$$
A'=C^\top AC.
$$
\de Ядром билинейной функции $\alpha$ называется (очевидно, подпространство)
$$
\rom{Ker}\alpha=\left\{y\in V\  :\ \alpha(x, y)=0\ \forall\ x\in V\right\}.
$$
\te $\dim\rom{Ker}\alpha=\dim V-\rk A,$ где $A$ - матрица функции $\alpha$ в каком-либо базисе.%
\dok $\alpha(x,y)=0\  \forall\ x\ \lr\ \alpha(e_i, y)=0\quad(i=1,\dots,n).$ %
\ab Но $\alpha(e_i,y)=\sum\limits_ja_{ij}y_j$, значит $\rom{Ker}\alpha$ задаётся системой однородных линейных
уравнений
$$
\sum_{j=1}^na_{ij}y_j=0\quad(i=1,\dots,n).
$$
Следовательно, $\dim\rom{Ker}\alpha=n-\rk A$ \qed
\section{Ортогональное дополнение к подпространству\\ относительно симметрической или кососимметрической\\ билинейной функции.}
\label{q10} %
\de Билинейная функция $\alpha$ называется симметрической (кососимметрической), если \ab %
$\forall\ x,y\in V\ \  \alpha(x,y)=\alpha(y,x)\ \left(\alpha(x, y)=-\alpha(y,x),\ {\rm char}K\ne 2\right).$ %
\de Векторы $x$ и $y$ называются ортогональными относительно симметрической или кососимметрической билинейной
функции $\alpha$, если $\alpha(x,y)=0.$ \\Если $\alpha$ кососимметрическая, то каждый вектор ортогонален сам себе:
$\alpha(x,x)=-\alpha(x,x)=0.$ %
\de Ортогональным дополнением к подпространству $U\subset V$ относительно симметрической или
кососимметрической билинейной функции $\alpha$ называется подпространство\\ $U^\bot=\left\{y\in V\ :\
\alpha(x,y)=0\ \forall\ x\in U\right\}$. В частности, $V^\bot=\rom{Ker}\alpha.$ %
\te $\dim{U^\bot}\ge \dim V-\dim U.$ \\Если же $\alpha$ невырождена, то $\dim{U^\bot}=\dim V-\dim U$, и
$\left(U^\bot\right)^\bot=U.$ %
\dok Запишем уравнения $U$ в координатах. \\Заметим, что $U^\bot=\left\{y\in V\ :\ \alpha(e_i,y)=0\ \forall\
i\right\}$ (здесь $e_1,\dots,e_k$ - базис $U$). Дополним $(e_1,\dots,e_k)$ до базиса $\baz{e}$ всего пространства
$V$. В этом базисе $U^\bot$ задаётся уравнениями:
$$
\sum_ja_{ij}y_j=0\qquad(i=1,\dots,k).
$$
Значит, $\dim U^\bot\ge n-k=\dim V-\dim U.$\  Если же $\alpha$ невырождена, то $A=(a_{ij})$ - невырожденная
матрица, следовательно её первые $k$ строк линейно независимы, поэтому $$\dim U^\bot=n-k=\dim V-\dim U.$$ %
Для доказательства того, что $\left(U^\bot\right)^\bot=U$, достаточно заметить, что
$\left(U^\bot\right)^\bot\supset U$\\ и размерности $U$ и $\left(U^\bot\right)^\bot$ в случае невырожденности
$\alpha$ совпадают, поэтому $\left(U^\bot\right)^\bot=U$. \qed %

\de Подпространство $U\subset V$ называется невырожденным относительно билинейной функции $\alpha$, если функция
$\alpha\,\vrule\, _U$ невырождена. %
\te $V=U\ps U^\bot\ \lr\ U$ невырождено относительно $\alpha$.%
\dok \begin{enumerate}
    \item $U$ невырождено $\lr$ $U\cap U^\bot=0$ - ядро $\alpha\,\vrule\, _U$ нулевое;
    \item $V=U\ps U^\bot\ \Rightarrow\ U\cap U^\bot=0\ \Rightarrow\ U$ невырождено;
    \item $U$ невырождено $\Rightarrow$ $U\cap U^\bot=0\ \Rightarrow\ $сумма $U+U^\bot$ прямая.
    \ab $\dim(U\ps U^\bot)=\dim U+\dim U^\bot\ge\dim V\ \Rightarrow\ U\ps U^\bot=V$ \qed
\end{enumerate}

\section{Связь между симметрическими билинейными и \\квадратичными функциями.
 Существование ортогонального базиса для симметрической билинейной функции.}
\label{q11}%
\de Базис $\baz{e}$ называется ортогональным относительно билинейной функции $\alpha$, если в этом базисе матрица
её имеет диагональный вид. В ортогональном базисе билинейная функция записывается как
$\alpha(x,y)=\sum\limits_ia_{i}x_iy_i=a_1x_1y_1+\dots+a_nx_ny_n$. %
\de Квадратичной функцией, ассоциированной с симметрической билинейной функцией $\alpha$, называется функция
$q(x)=\alpha(x,x).$ В координатах: $q(x)=\sum\limits_{i,j}a_{ij}x_ix_j.$ Понятно, что $\alpha$ однозначно
восстанавливается по $q$: $\alpha(x,y)=\frac12(q(x+y)-q(x)-q(y)).$ %
\te Для всякой симметрической билинейной функции $\alpha$ существует ортогональный базис. %
\dok Индукцией по $n=\dim V. $ %
\ab При $n=1$ доказывать нечего - любой базис ортогональный. %
\ab При $n>1$ если $\alpha\equiv 0$, то доказывать нечего. %
\ab Пусть $n>1$ и $\alpha\ne 0$. Тогда и $q\ne 0$, то есть $\ \exists \ e_1\in V\ :\ q(e_1)\ne 0$. Подпространство
$\lob{e_1}$ невырождено относительно $\alpha$ $\ \Rightarrow\ V=\lob{e_1}\ps\lob{e_1}^\bot,$ %
$\dim\lob{e_1}^\bot=n-1$. По предположению индукции в $\lob{e_1}^\bot$ существует ортогональный базис
$(e_2,\dots,e_n).$ Значит $\baz{e}$ - ортогональный базис $V$. \qed
\section{Нормальный вид вещественной квадратичной функции.\\ Закон инерции.}
\label{q12} %
В ортогональном базисе матрица симметрической билинейной функции имеет вид:\ab%
$$A=\left(%
\begin{array}{cccc}
  a_1 & 0 & \dots & 0 \\
  0 & a_2 & \dots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \dots & a_n \\
\end{array}%
\right).$$
\begin{enumerate}
    \item За счёт перестановки базисных векторов можно переставлять числа $a_i$;
    \item За счёт умножения базисных векторов на ненулевые элементы поля $K$, можно умножить $a_i$ на квадраты
    элементов поля.
\end{enumerate}
\ab Число ненулевых коэффициентов $a_i$ равно рангу $\rk q$ билинейной формы (и не зависит от базиса). %
\ab Если $K=\mathbb{C}$, то можно добиться того, чтобы $a_i\in\{0,1\}$. Получим нормальный вид
$$q(x)=x_1^2+\dots+x_{\rk q}^2.$$
\ab Если $K=\mathbb{R}$, то можно добиться того, чтобы $a_i\in\{0, \pm 1\}.$ Получим нормальный вид
$$
q(x)=x_1^2+x_2^2+\dots+x_k^2-x_{k+1}^2-\dots-x_{k+l}^2\qquad(k+l=\rk q).
$$
\de Квадратичная функция $q$ называется положительно определённой, если $\ \forall\ x\ne 0\ \ q(x)>0.$
Квадратичная положительно определена $\ \lr\ $ её нормальный вид есть $x_1^2+\dots+x_n^2.$ То есть для
положительно определённой квадратичной функции её нормальный вид определяется однозначно. Понятно, что если
$q$ положительно определена, то $\det q>0$ в любом базисе (потому что в нормальном виде $\det q=1$). %
\ab{\bf Теорема} (Закон инерции). Числа $k$ и $l$ в нормальном виде квадратичной функции не зависят от выбора
базиса, в котором эта функция имеет нормальный вид. %
\dok Достаточно доказать, что $k$ не зависит от базиса. Докажем, что $k$ есть максимальная размерность
подпространства, на котором данная квадратичная функция $q$ положительно определена. %
Пусть $q(x)=x_1^2+x_2^2+\dots+x_k^2-x_{k+1}^2-\dots-x_{k+l}^2$ в базисе $\baz{e}$. На подпространстве
$\lob{e_1,\dots,e_k}$ $q$ положительно определена. %
\ab Пусть теперь $q$ положительно определена на каком-то подпространстве $U$ и $\dim U>k$. Рассмотрим
подпространство $W=\lob{e_{k+1},\dots,e_n}$, $\dim W=n-k$. Но так как $\dim U+\dim W>n,\ \ U\cap W\ne 0.$ %
\ab Пусть $0\ne x\in U\cap W.$ Тогда $q(x)>0$ с одной стороны и $q(x)=-x_{k+1}^2-\dots-x_{k+l}^2\le 0$. \qed %
\de Число $k$ называется положительным индексом инерции квадратичной функции $q$, \\число $l$ - отрицательным. %
\section{Процесс ортогонализации. Нахождение индексов\\ инерции квадратичной функции методом Якоби.}
\label{q13}%
Положим $V_k=\lob{e_1,\dots,e_k}$. Матрица функции $\alpha\,\vrule\,  _{V_k}$ в базисе $(e_1,\dots,e_k)$ - это
левый
верхний угол порядка $k$ матрицы $A$. Обозначим эту матрицу через $A_k$, её определитель - через $\delta_k$.%
\ab{\bf Теорема} (Процесс ортогонализации Грама - Шмидта). Предположим, что $\alpha\,\vrule\, _{V_k}$ -
невырождена, то есть $\delta_k\ne 0\quad(k=1,\dots,n).$ Тогда существует единственный ортогональный базис
$\baz{f}$ пространства $V$, для которого $f_k\in e_k+V_{k-1}\quad(k=1,\dots,n)$, при этом
$q(f_k)={\delta_k}/{\delta_{k-1}}$, \\если
считать $\delta_0=1\mbox{ и }V_0=0$. %
\dok Положим $f_1=e_1,$ тогда $q(f_1)=q(e_1)=\delta_1.$ %
\ab Далее, пусть $f_1,\dots,f_{k-1}$, удовлетворяющие всем требуемым условиям, уже построены. Будем искать $f_k$
в виде
$$
f_k=e_k+\lambda_1f_1+\lambda_2f_2+\dots+\lambda_{k-1}f_{k-1}\ \in\ e_{k}+V_{k-1}.
$$
\ab Условия ортогональности: $\alpha(f_k,f_i)=\alpha(e_k,f_i)+\lambda_iq(f_i)=0\quad(i=1,\dots,k-1).\ \\ \mbox{Так
как }q(f_i)=\alpha(f_i,f_i)=\delta_i/\delta_{i-1}\ne 0,$ то уравнение имеет единственное решение
$\lambda_i=-\frac{\alpha(e_k,f_i)}{q(f_i)}.$ %
\ab Остаётся доказать, что $q(f_k)=\delta_k/\delta_{k-1}.$%
\ab Рассмотрим базисы $(e_1,e_2,\dots,e_k)$ и $(f_1,f_2,\dots,f_k)$ пространства $V_k.$ Матрица перехода имеет
вид%
$$
C=\left(%
\begin{array}{cccc}
  1 & * & \dots & * \\
  0 & 1 & \dots & * \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \dots & 1 \\
\end{array}%
\right).
$$
$\det C=1.$\ \ Значит, матрица $\alpha\,\vrule\, _{V_k}$ в обоих базисах имеет одинаковый определитель, то есть
$$
\delta_k=\det A_k=\left|%
\begin{array}{ccc}
  q(f_1) & \dots & 0 \\
  \vdots & \ddots & \vdots \\
  0 & \dots & q(f_k) \\
\end{array}%
\right|=q(f_1)\cdot \dots \cdot q(f_k),\quad\mbox{но}\quad q(f_1)\cdot\dots\cdot
q(f_{k-1})=\delta_{k-1},\quad{\mathcal{Q.E.D.}}
$$
\ab{\bf Теорема} (Метод Якоби). Пусть квадратичная функция $q$ в каком-то базисе имеет матрицу $A$, все угловые
миноры $\nn{\delta}$ которой отличны от нуля. Тогда отрицательный индекс инерции квадратичной функции $q$ равен
числу перемен знака в последовательности $(1,\nn{\delta})$. %
\dok По предыдущей теореме, функцию можно привести к виду
$$
\delta_1x_1^2+\frac{\delta_2}{\delta_1}x_2^2+\dots+\frac{\delta_n}{\delta_{n-1}}x_n^2.
$$
Коэффициент при $x_i^2$ отрицателен тогда и только тогда, когда на $i$-м месте в последовательности
$(1,\nn{\delta})$ имеет место перемена знака. \qed %
\section{Критерий Сильвестра.}
\label{q14}%
\ab{\bf Теорема} (Критерий Сильвестра). Пусть квадратичная функция $q$ в каком-то базисе имеет матрицу $A$. Тогда
$q$ положительно определена тогда и только тогда, когда все угловые миноры матрицы $A$ положительны. %
\dok Если $\nn{\delta}$ положительны, то в силу Метода Якоби отрицательный индекс инерции $q$ равен нулю, и $\det
q\ne 0$,
 значит $q$ положительно определена. %
\ab Обратно, пусть $q$ положительно определена. Положим $V_k=\lob{e_1,e_2,\dots,e_k}$. Тогда матрица ограничения
$\alpha\,\vrule\, _{V_k}$ есть $A_k$ - левый верхний угол порядка $k$ матрицы $A$. Ясно, что $\alpha\,\vrule\,
_{V_k}$ - положительно определённая квадратичная функция. Значит,  $\det \alpha\,\vrule\, _{V_k}=\det
A_k=\delta_k>0\quad(k=1,2,\dots,n)$ \qed
\section{Существование симплектического базиса\\ для кососимметрической билинейной функции.}
\label{q15} %
\de Базис $\baz{e}$ называется симплектическим относительно кососимметрической билинейной функции $\alpha$, если
$\alpha(e_1,e_2)=-\alpha(e_2,e_1)=1,\
\alpha(e_3,e_4)=-\alpha(e_4,e_3)=1,\dots,\alpha(e_{2m-1},e_{2m})=\\=-\alpha(e_{2m},e_{2m-1})=1\mbox{ и
}\alpha(e_i,e_j)=0\mbox{ в остальных случаях.}$ Иными словами, если матрица $\alpha$ в этом базисе имеет вид:
$$
\left(%
\begin{array}{cccccccccc}
  0 & 1 &  &  &  & & &  &  &  \\
  -1 & 0 &  &  &  &  &  &  &  &  \\
   &  & 0 & 1 &  &  &  &  &  &  \\
   &  & -1 & 0 &  &  &  &  &  &  \\
   &  &  &  & \ddots & & &  &  &  \\
   &  &  &  &  & 0 & 1 &  &  &  \\
   &  &  &  &  & -1 & 0 &  &  &  \\
   &  &  &  &  &  &  & 0 &  &  \\
   & &  &  &  &  &  &  & \ddots &  \\
   & &  &  &  &  &  &  &  & 0 \\
\end{array}%
\right).
$$%
\te Для любой кососимметрической билинейной функции $\alpha$ существует симплектический базис. %
\dok Индукцией по $n=\dim V.$ %
\ab Если $n=0\mbox{ или }1,$ то доказывать нечего. %
\ab Если $n\ge 2,$  но $\alpha\equiv 0$, то тоже доказывать нечего. %
\ab Если $n\ge 2,$  и $\alpha\ne 0$, то $\ \exists\ e_1, e_2$  такие, что $\alpha(e_1,e_2)\ne 0.$ Нормируя,
добьёмся того, чтобы $\alpha(e_1,e_2)=1.$ Матрица $\alpha\,\vrule\, _{\lob{e_1,e_2}^\bot}$ имеет вид $$\left(%
\begin{array}{cc}
  0 & 1 \\
  -1 & 0 \\
\end{array}%
\right),$$ значит, $U=\lob{e_1,e_2}^\bot$ - невырожденное подпространство, поэтому $V=U\ps U^\bot$. По
предположению индукции, в $U^\bot$ существует симплектический базис $(e_3,e_4,\dots,e_n)$. Тогда $\baz{e}$ -
искомый симплектический базис всего пространства. \qed

% ===========================================================================================
\section{Евклидовы пространства.\\ Длина вектора и угол между векторами.}
\label{q16} %
\de Евклидовым векторным пространством называется вещественное векторное пространство, в котором фиксирована
некоторая положительно определённая билинейная функция, называемая скалярным умножением и обозначаемая $(\ ,\
).$%
\de Длиной вектора $x$ в евклидовом векторном пространстве называется арифметическое значение квадратного корня из
его скалярного квадрата: $|x|=\sqrt{(x,x)}.$%
\ab Свойство длины: $|\lambda x|=|\lambda|\cdot|x|.$
%
\de Углом между ненулевыми векторами $x$ и $y$ в евклидовом векторном пространстве называется такой угол $\alpha$
($0\le\alpha\le\pi$), косинус которого равен $\cos\alpha=\frac{\displaystyle (x,y)}{\displaystyle |x|\cdot|y|}$.
Корректность этого определения вытекает из следующей теоремы:%
\ab{\bf Теорема} (Неравенство Коши-Буняковского). Для любых векторов $x,y\in V$ выполняется неравенство
$|(x,y)|\le|x|\cdot|y|,$ причём равенство достигается $\lr$ $x$ и $y$ пропорциональны.
\dok Если $y=\lambda x,$ то $|(x,y)|=|\lambda|\cdot|x|^2=|x|\cdot|y|.$%
\ab Пусть теперь $x$ и $y$ непропорциональны. Тогда они составляют базис подпространства $U=\lob{x,y}.$
Ограничение $(\ ,\ )\,\vrule\,_U$ является положительно определённой симметрической билинейной функцией, значит
$$
\left|%
\begin{array}{cc}
  (x,x) & (x,y) \\
  (y,x) & (y,y) \\
\end{array}%
\right|>0,\quad\Rightarrow\quad |x|^2\cdot|y|^2-(x,y)^2>0\quad\Rightarrow\quad
|(x,y)|\le|x|\cdot|y|,\qquad\mathcal{Q.E.D}
$$%
\ab Верно неравенство треугольника $|x+y|\le|x|+|y|.$%
\ab Из общей теории следует, что в любом конечномерном евклидовом векторном пространстве существует
ортонормированный базис. В этом базисе скалярное умножение принимает вид:
$$(x,y)=x_1y_1+x_2y_2+\dots+x_ny_n.$$
\de Изоморфизмом евклидовых пространств называется отображение, которое является изоморфизмом векторных
пространств и сохраняет скалярное умножение. Понятно, что евклидовы пространства одинаковой конечной размерности
изоморфны (возьмём два ортонормированных базиса, установим изоморфизм, ассоциированный с ними, тогда и
скалярное произведение будет сохраняться). %
\section{Матрица и определитель Грама \\ системы векторов евклидова пространства.}
\label{q17} %
\de Пусть $V$ - евклидово пространство и $a_1,a_2,\dots,a_k\in V$. Матрицей Грама этой системы векторов называется
матрица
$$
G(a_1,a_2,\dots,a_k)=\left(%
\begin{array}{cccc}
  (a_1,a_1) & (a_1,a_2) & \dots & (a_1,a_k) \\
  (a_2,a_1) & (a_2,a_2) & \dots & (a_2,a_k) \\
  \vdots & \vdots & \ddots & \vdots \\
  (a_k,a_1) & (a_k,a_2) & \dots & (a_k,a_k) \\
\end{array}%
\right).
$$
\te $\det G(a_1,a_2,\dots,a_k)\ge 0,$ причём равенство достигается $\lr$ \\ $\lr$ векторы $a_1,a_2,\dots,a_k$
линейно зависимы. %
\dok \begin{enumerate}
    \item Пусть $a_1,a_2,\dots,a_k$ линейно зависимы, то есть $\sum\limits_{i=1}^k\lambda_ia_i=0$, тогда для
    каждого $j$\\ $\sum\limits_i\lambda_i(a_i,a_j)=0$, значит, строки матрицы Грама линейно зависимы с теми же
    коэффициентами, значит $\det G(a_1,a_2,\dots,a_k)=0$;
    \item Пусть $a_1,a_2,\dots,a_k$ линейно независимы. Тогда они составляют базис подпространства $U=\lob{a_1,a_2,\dots,a_k}.$
    $G(a_1,a_2,\dots,a_k)$ - это матрица ограничения $(\ ,\ )\,\vrule\,_U$ в этом базисе, значит $\det
    G(a_1,a_2,\dots,a_k)>0.$\qed
\end{enumerate}
\section{Ортонормированные базисы евклидова пространства\\ и ортогональные матрицы.}
\label{q18} %
\te Пусть $\baz{e}$ - ортонормированный базис пространства $V$, и пусть $\baz{e'}=\baz{e}C.$ Тогда $\baz{e'}$ -
также
ортонормированный базис $\lr$ $C^{-1}=C^\top$ (такие матрицы называются ортогональными). %
\dok $G(\nn{e'})=C^\top G(\nn{e})C=C^\top C$, как матрицы скалярного умножения в двух базисах. Поэтому базис
$\baz{e'}$ является ортонормированным $\lr$ $G(\nn{e'})=E$ $\lr$ $C^\top=C^{-1}$ \qed
\section{Расстояние от вектора до подпространства, его выражение через определители Грама.}
\label{q19} %
\ab Для всякого подпространства $U\in V$ евклидова векторного пространства $U\ps U^\bot=V$, так как \\
$U$ - невырождено относительно скалярного умножения. Значит, $\forall\ x\in V$ единственным образом представим в
виде $x=y+z$, где $y\in U, z\in U^\bot$. Вектор $y$ называется ортогональной проекцией вектора $x$ на
подпространство
$U$, вектор $z$ - ортогональной составляющей вектора $x$:\\ $y=\pr_U x,\ z={\rm ort\,}_U x.$ %
\ab Если $(e_1,e_2,\dots,e_k)$ - ортонормированный базис в $U$, то $\pr_U x=\sum\limits_{i=1}^k(x,e_i)e_i.$
\\Действительно, $\left(x-\sum\limits_{i=1}^k(x,e_i)e_i\ ;\ e_j\right)=0\ \forall\ j,$ значит, разность принадлежит $U^\bot$. \\%
Если же $(e_1,e_2,\dots,e_k)$ - ортогональный базис подпространства $U$, то $\pr_U
x=\sum\limits_{i=1}^k\frac{\displaystyle (x,e_i)}{\displaystyle (e_i,e_i)}e_i$.\\ (действительно, рассмотрим
$e_i'=\frac{\displaystyle e_i}{\displaystyle \sqrt{(e_i,e_i)}}$ и воспользуемся предыдущим). %
\de Расстояние между векторами: $\rho(x,y)=|x-y|,$ расстояние между подмножествами:\\ $\rho(X,Y)=\inf\limits_{x\in
X,y\in Y}\rho(x,y).$ %
\te Пусть $U\subset V$ - подпространство, $x\in V$. Тогда $\rho(x,U)=|{\rm ort\,}_U x|$, причём единственный
ближайший к вектору $x$ вектор подпространства $U$ есть $\pr_U x.$%
\dok Пусть $x=y+z,\mbox{ где }y\in U,z\in U^\bot.$ Пусть $y'\in U,\ y'\ne y.$\\ Надо доказать, что
$\rho(x,y')>\rho(x,y).$ \\
$x-y'=(x-y)+(y-y')=z+u,\mbox{ где }u\in U,\  {\rm ort\,}_U x=z\bot u.\ \Rightarrow\ |x-y'|=\sqrt{|z|^2+|u|^2}>|z|$
\qed%
\sled Из процесса ортогонализации вытекает, что если $(e_1,e_2,\dots,e_{k-1})$ - произвольный базис в $U$, то
$$
\left(\rho(x,U)\right)^2=\frac{\displaystyle \det G(e_1,\dots,e_{k-1},x)}{\displaystyle \det
G(e_1,\dots,e_{k-1})}.
$$
\dok Действительно, рассмотрим процесс ортогонализации произвольного базиса\\ $\baz{e}$ пространства $V$ (можно
ортогонализовать, так как все угловые миноры положительны). Пусть получается базис $\baz{f}$. Понятно, что
$f_k={\rm ort\,}_{V_{k-1}} e_k,$ где $V_{k-1}=\lob{e_1,\dots,e_{k-1}}=\lob{f_1,\dots,f_{k-1}}.$ Тогда
$f_k=e_k-\pr_{V_{k-1}} e_k=e_k-\sum\limits_{i=1}^{k-1}\frac{\displaystyle (e_k,f_i)}{\displaystyle(f_i,f_i)}f_i,$
и $(f_k,f_k)^2=\frac{\displaystyle \det G(e_1,\dots,e_k)}{\displaystyle \det G(e_1,\dots,e_{k-1})}.$ Теперь,
полагая $e_k=x,$ (в случае $x\in U$ всё и так очевидно) получаем то, что надо. \qed
\section{Объём параллелепипеда в евклидовом пространстве\\ (две формулы).}
\label{q20} %
\de Параллелепипедом, натянутым на базис $\baz{a}$ называется множество
$$
P\baz{a}=\left\{\sum\limits_{i}\lambda_ia_i\ :\ 0\le\lambda_i\le 1\right\}
$$
\de Объёмом $n$-мерного параллелепипеда $P\baz{a}$ называется произведение объёма\\ ''основания''
$P(a_1,a_2,\dots,a_{n-1})$ на ''высоту'' $h=\left|{\rm ort\,}_{\lob{a_1,a_2,\dots,a_{n-1}}}a_n\right|$, при
$n=1$\quad ${\rm vol\,} P(a_1)=|a_1|.$ %
\te $\left({\rm vol\,}P\baz{a}\right)^2=\det G\baz{a}.$ %
\dok Индукцией по $n$.%
\ab $n=1\ :\ ({\rm vol\,}P(a_1))^2=|a_1|^2=(a_1,a_1)=\det G(a_1);$ %
\ab $n>1\ :\ \left({\rm vol\,}P\baz{a}\right)^2=\left({\rm
vol\,}P(a_1,a_2,\dots,a_{n-1})\right)^2\cdot\rho(a_n;\lob{a_1,a_2,\dots,a_{n-1}})^2=\\\det
G(a_1,a_2,\dots,a_{n-1})\cdot\frac{\displaystyle \det G\baz{a}}{\displaystyle \det G(a_1,a_2,\dots,a_{n-1})}=\det
G\baz{a}.$ \qed %
\sled ${\rm vol\,}P\baz{a}$ не зависит от нумерации векторов $\nn{a}$.%
%
\te Пусть $\baz{e}$ - ортонормированный базис пространства $V$,\\ $\baz{a}=\baz{e}A.$ Тогда ${\rm vol\,}P\baz{a}=|\det A|.$%
\dok $G\baz{a}$ - матрица скалярного умножения в базисе $\baz{a}.$ %
\ab $G\baz{a}=A^\top G\baz{e}A=A^\top A. \quad \det G\baz{a}=(\det A)^2\ \Rightarrow\\\Rightarrow\  {\rm
vol\,}P\baz{a}=|\det A|$\qed
\section{Полуторалинейные функции, их запись в координатах.\\ Изменение матрицы полуторалинейной функции\\ при переходе к другому базису.
Эрмитовы и косоэрмитовы\\ полуторалинейные функции, связь между ними.} %
\label{q21}%
\de Полуторалинейной функцией на комплексном пространстве $V$ называется функция\\ $\alpha: V\times V\rightarrow
\mathbb{C}$, обладающая линейностью по второму аргументу\\ и антилинейностью по первому, то есть:
\begin{enumerate}
    \item $\alpha(x_1+x_2, y)=\alpha(x_1,y)+\alpha(x_2,y);$
    \item $\alpha(\lambda x, y)=\overline{\lambda}\alpha(x,y).$
\end{enumerate}
\ab Пусть $\baz{e}$ - базис пространства $V$. Тогда если $x=\sum\limits_ix_ie_i,\quad y=\sum\limits_jy_je_j,$ то
$$
\alpha(x,y)=\sum_{i,j}a_{ij}\overline{x}_iy_j,\quad\mbox{где }a_{ij}=\alpha(e_i,e_j).
$$
Матрица $A=(a_{ij})$ называется матрицей полуторалинейной функции $\alpha$ в базисе $\baz{e}$\\ (понятно, что
любой комплексной матрице соответствует полуторалинейная функция).
$$
\alpha(x,y)=X^* AY,\quad\mbox{где }X=(\nn{x})^\top,\ Y=(\nn{y})^\top,\ X^*=\overline{X}^\top .
$$
\ab Свойства:
\begin{enumerate}
    \item $(C+D)^*=C^*+D^*$;
    \item $(\lambda C)^*=\overline{\lambda}C^*$;
    \item $(CD)^*=D^*C^*.$
\end{enumerate}
\ab Рассмотрим переход к другому базису: $\baz{e'}=\baz{e}C.$ Преобразования координат:\\ $X=CX',\ Y=CY'.$
$$
\alpha(x,y)=X^*AY=(CX')^*A(CY')=X'^*(C^*AC)Y'.
$$
\de Ядром полуторалинейной функции $\alpha$ называется подпространство $$\rom{Ker}\alpha=\{y\in V\ :\
\alpha(x,y)=0\ \forall\ x\in V\}=\{y\in V\ :\ \alpha(e_i,y)=0\ \forall\ i=1,\dots ,n\}$$ %
\te $\dim\rom{Ker}\alpha=\dim V-\rk A$\qed\ (доказательство аналогично)%
\de Полуторалинейная функция называется эрмитовой (косоэрмитовой), если
$\alpha(x,y)=\overline{\alpha(y,x)}$\\
(соответственно, $\alpha(x,y)=-\overline{\alpha(y,x)}$). %
\ab Очевидно, что полуторалинейная функция $\alpha$ эрмитова $\lr$ функция $i\alpha$ косоэрмитова. %
\section{Нормальный вид эрмитовой функции. Закон инерции.}
\label{q22}%
Будем рассматривать только эрмитовы полуторалинейные функции.%
\de Векторы $x$ и $y$ называются ортогональными относительно эрмитовой полуторалинейной\\ функции $\alpha$, если
$\alpha(x,y)=0$. Ортогональным дополнением к подпространству $U$ называется подпространство $U^\bot=\{y\in V\
:\ \alpha(x,y)=0\ \forall\ x\in U\}.$ %
\te $V=U\ps U^\bot\ \lr\ U$ - невырожденное подпространство (относительно $\alpha$). \qed%
\de Квадратичной эрмитовой функцией, ассоциированной с эрмитовой полуторалинейной\\ функцией $\alpha$ называется
$q(x)=\alpha(x,x)$. Понятно, что $\overline{q(x)}=\overline{\alpha(x,x)}=\alpha(x,x)=q(x)\ \rightarrow\
q(x)\in\mathbb{R}$. %
\te Эрмитова полуторалинейная функция $\alpha$ однозначно восстанавливается по своей квадратичной функции $q$.
\dok $q(x+y)=\alpha(x+y,x+y)=q(x)+q(y)+\alpha(x,y)+\overline{\alpha(x,y)}.$
\ab$q(x+iy)=\alpha(x+iy,x+iy)=q(x)+q(y)+i\alpha(x,y)-i\alpha(y,x).$ %
\ab Для $\alpha(x,y)$ и $\alpha(y,x)$ получаем систему линейных уравнений с ненулевым определителем, значит
восстанавливается однозначно\qed %
\sled $q\equiv 0\ \Rightarrow\ \alpha\equiv 0.$ %
\te Для всякой эрмитовой полуторалинейной функции существует ортогональный базис. %
\dok Аналогично.\qed%
\ab В этом базисе $\alpha(x,y)=a_1\overline{x}_1y_1+\dots+a_n\overline{x}_ny_n,$ где $a_i=q(e_i)\in\mathbb{R}.$
\ab Нормируя базисные векторы можно добиться того, чтобы $a_i\in\{\pm 1,0\}$. Получим нормальный вид:
$$
\alpha(x,y)=\overline{x}_1y_1+\dots+\overline{x}_ky_k-\overline{x}_{k+1}y_{k+1}-\dots-\overline{x}_{k+l}y_{k+l};$$
$$
q(x)=|x_1|^2+\dots+|x_k|^2-|x_{k+1}|^2-\dots-|x_{k+l}|^2.
$$
\de Эрмитова квадратичная функция $q$ называется положительно определённой, если
$$q(x)>0\ \forall\ x\ne 0.$$
\ab{\bf Теорема} (закон инерции). Числа $k$ и $l$ в нормальном виде эрмитовой квадратичной функции не зависят от
базиса, в котором она имеет нормальный вид%
\dok Аналогично.\qed %
\ab Числа $k$ и $l$ называются соответственно положительным и отрицательным индексами инерции эрмитовой
квадратичной функции $q$. %
Аналогично для эрмитовых полуторалинейных функций имеют место процесс ортогонализации, метод Якоби и критерий
Сильвестра. %
\section{Эрмитовы пространства. Ортонормированные базисы эрмитова\\ пространства и унитарные матрицы.}
\label{q23} %
\de Эрмитовым пространством называется комплексное векторное пространство, в котором фиксирована некоторая
положительно определённая эрмитова полуторалинейная функция, называемая скалярным умножением и обозначаемая $(\
,\ ).$ %
\ab Можно определить по аналогии с евклидовым пространством длину вектора $|x|=\sqrt{(x,x)},$ угол между
векторами. Верно неравенство Коши-Буняковского $|(x,y)|\le |x|\cdot|y|,$ неравенство треугольника
$|x+y|\le|x|+|y|.$ Определено расстояние между векторами $\rho(x,y)=|x-y|.$ %
\ab В любом конечномерном эрмитовом пространстве существует ортонормированный базис, в котором
$$
(x,y)=\overline{x}_1y_1+\dots+\overline{x}_{n}y_{n};$$
$$
(x,x)=|x_1|^2+\dots+|x_{n}|^2.
$$
Пусть $\baz{e}$ - ортонормированный базис, $\baz{e'}=\baz{e}C.$\\ Тогда базис $\baz{e'}$ ортонормирован $\lr$ %
$C^*C=E$ (такие матрицы называются унитарными). %
Для любого подпространства $U\subset V$ эрмитова пространства $V=U\ps U^\bot.$

%\input linal3.tex
% ===========================================================================================
%\input linal4.tex
\section{Линейные операторы, их запись в координатах.\\
Изменение матрицы линейного оператора при переходе к другому базису. Ранг и определитель линейного оператора. %
Невырожденные линейные операторы.} %
\label{q24}%
\de Линейным оператором в векторном пространстве $V$ (или линейным преобразованием\\ пространства $V$) называется
линейное отображение пространства $V$ в себя\ \ $\om{A}:V\rightarrow V$. %
\de Подпространство $U\subset V$ называется инвариантным относительно оператора \op{A}, если\\ $\om{A}U\subset U$,
то есть $\ \forall\ x\in U\ \ \om{A}x\in U.$ В этом случае можно рассмотреть $\om{A}\,\vrule\,_U$ - линейный
оператор в подпространстве $U$. %
\ab Теперь пусть $\dim V<\infty$, и пусть \op{A} - линейный оператор в пространстве $V$.\\ Пусть $\baz{e}$ - базис
$V$.\\ Разложим $\om{A}e_j=\sum\limits_ia_{ij}e_i$ - в отличие от общих линейных отображений, в обоих случаях
используется один и тот же базис. Матрица $A=(a_{ij})$ называется матрицей линейного оператора \op{A} в
базисе $\baz{e}$ - в $j$-м столбце этой матрицы стоят координаты образа $e_j$ в этом же базисе.\\ В матричной
форме: $\baz{\om{A}e}=\baz{e}A.$\\ Запись линейного оператора в координатах:\\ $x=\sum\limits_ix_ie_i,\
\om{A}x=y=\sum\limits_jy_je_j$, $X=(\nn{x})^\top,\ Y=(\nn{y})^\top.$ Тогда $Y=AX.$ %
\ab Изменение матрицы линейного оператора при переходе к другому базису $\baz{e'}:$\\ Пусть $\baz{e'}=\baz{e}C.$
Тогда $\baz{\om{A} e'}=\mbox{(\it в силу линейности)}=\\=\baz{\om{A}e}C=\baz{e}AC=\baz{e'}C^{-1}AC,$ значит
$A'=C^{-1}AC.$ %
\ab Понятно, что ранг и определитель линейного оператора не зависят от базиса. %
\de Линейный оператор называется невырожденным, если его определитель отличен от нуля. %
\ab Из теории общих линейных отображений следует, что
\begin{itemize}
    \item $\dim\rom{Im}\om{A}=\rk\om{A};$
    \item $\dim\rom{Ker}\om{A}=\dim V-\rk\om{A}.$
\end{itemize}

\section{Собственные векторы и собственные значения\\ линейного оператора.}
\label{q25}%
\ab Если $V=V_1\ps\dots\ps V_s$, где $V_i\quad (i=1,\dots,s)$ - инвариантные подпространства, то в
соответствующем базисе пространства $V$ матрица \op{A} имеет блочно-диагональный вид. Рассмотрение одномерных
инвариантных подпространств приводит к понятию собственного вектора. %
\de Ненулевой вектор $e\in V$ называется собственным вектором оператора \op{A}, если $\om{A}e=\lambda e$\\ для
некоторого $\lambda \in K.$ Число $\lambda$ называется собственным значением оператора \op{A}. %
\ab Пусть \op{A} - линейный оператор в конечномерном векторном пространстве $V$. %
\ab Понятно, что если существуют собственные векторы с собственным значением $\lambda,$ то \\
$\det(\om{A}-\lambda\om{E})=0,$ и наоборот.%
\ab Вместе с нулевым вектором собственные вектора, отвечающие одному и тому же собственному значению $\lambda$,
образуют подпространство $V_\lambda(\om{A})=\rom{Ker}(\om{A}-\lambda\om{E}),$ называемое собственным
подпространством.%
\de Характеристическим многочленом оператора \op{A} называется многочлен ($n$-й степени)
$$
f_{\om{A}}(t)=\det(t\om{E-A})=(-1)^n\det(\om{A}-t\om{E})=(-1)^n\left|%
\begin{array}{cccc}
  a_{11}-t & a_{12} & \dots & a_{1n} \\
  a_{21} & a_{22}-t & \dots & a_{2n} \\
  \vdots & \vdots & \ddots & \vdots \\
  a_{n1} & a_{n2} & \dots & a_{nn}-t \\
\end{array}%
\right|.
$$
Непосредственно из определений вытекает, что %
\te Число $\lambda$ является собственным значением оператора \op{A} $\lr$ оно является корнем
характеристического многочлена $f_{\om{A}}.$ При этом
$V_\lambda(\om{A})=\rom{Ker}(\om{A}-\lambda\om{E}).$\qed %
\ab Чтобы получить собственные векторы, отвечающие собственному значению $\lambda$, надо взять ненулевые решения
системы уравнений $(\om{A}-\lambda\om{E})x=0.$ %
\section{Собственные подпространства линейного оператора,\\ их свойства. Достаточное условие\\ существования собственного базиса.}
\label{q26}
\te $\dim V_{\lambda}(\om{A})\le$ кратности корня $\lambda$ в $f_{\om{A}}.$%
\dok Пусть $(e_1,e_2,\dots,e_k)$ - базис $V_{\lambda}(\om{A}),$\ \ $\baz{e}$ - базис всего пространства.
В этом базисе запишем матрицу линейного оператора:
$$
A=\left(%
\begin{array}{cc}
  \begin{array}{ccc}
    \lambda &  & 0 \\
     & \ddots &  \\
    0 &  & \lambda \\
  \end{array} & \begin{array}{ccc}
     &  &  \\
     & \mbox{\Large $C$} &  \\
    &  &  \\
  \end{array} \\
  \begin{array}{ccc}
     &  &  \\
     &  &  \\
     & \mbox{\Large $0$} &  \\
  \end{array} & \begin{array}{ccc}
     &  &  \\
     &  &  \\
     & \mbox{\Large $B$} &  \\
  \end{array} \\
\end{array}%
\right);
$$
$$
f_{\om{A}}(t)=\det(tE-A)=\left|%
\begin{array}{cc}
  \begin{array}{ccc}
    t- \lambda &  & 0 \\
     & \ddots &  \\
    0 &  & t-\lambda \\
  \end{array} & \begin{array}{ccc}
     &  &  \\
     & \mbox{\Large $-C$} &  \\
    &  &  \\
  \end{array} \\
  \begin{array}{ccc}
     &  &  \\
     &  &  \\
     & \mbox{\Large $0$} &  \\
  \end{array} & \begin{array}{ccc}
     &  &  \\
     &  &  \\
     & \mbox{\Large $tE-B$} &  \\
  \end{array} \\
\end{array}%
\right|=(t-\lambda)^kf_{B}(t)\ \Rightarrow
$$
$\Rightarrow$\ кратность корня $\lambda$ в $f_{\om{A}}(t)$ больше либо равна
$k$.\hfill{\large \qed} %
\te Собственные подпространства, отвечающие различным собственным значениям,\\ линейно независимы. %
\dok Пусть $\lambda_1,\dots,\lambda_s$ - различные собственные значения \op{A}. Докажем, что\\
$V_{\lambda_1}(\om{A}),\dots,V_{\lambda_s}(\om{A})$ линейно независимы, индукцией по $s$. При $s=1$ доказывать нечего. %
\ab Предположим, что $V_{\lambda_1}(\om{A}),\dots,V_{\lambda_s}(\om{A})$ линейно зависимы (s>1). Тогда найдутся
такие $v_i\in V_{\lambda_i}({\om{A}})$ не все равные нулю, что $v_1+\dots+v_s=0.$ Применим к этому равенству
оператор \op{A}.\\ Получим $\lambda_1v_1+\dots+\lambda_sv_s=0$. Из второго равенства вычтем первое, умноженное на
$\lambda_s$:\\
$(\lambda_1-\lambda_s)v_1+\dots+(\lambda_{s-1}-\lambda_{s})v_{s-1}=0.$ По предположению индукции,
$(\lambda_i-\lambda_s)v_i=0\ \ (i=1,\dots,s-1).$ Но тогда $v_i=0\ \  (i=1,\dots,s-1)$ так как
$\lambda_i\ne\lambda_s.$ Но тогда $v_s$=0. Противоречие.\qed%
\sled Если $f_{\om{A}}$ имеет $n$ различных корней, то для \op{A} существует базис\\ из собственных векторов,
очевидно.
\section{Инвариантные подпространства линейного оператора.\\ Существование одномерного или двумерного инвариантного подпространства
для линейного оператора в вещественном векторном пространстве.} %
\label{q27}%
Пусть $V$ - вещественное векторное пространство. Определим комплексификацию \\
$V(\c)=\{x+iy\ :\ x,y\in V\}.$ %
\\Операции:\\ $(x_1+iy_1)+(x_2+iy_2)=(x_1+x_2)+i(y_1+y_2);$
\\
$(\lambda+\mu i)(x+iy)=(\lambda x-\mu y)+i(\lambda y+\mu x).$ %
\ab Понятно, что $V(\c)$ - векторное пространство, $V(\c)\supset V=\{x+0i\ :\ x\in V\}.$ %
\\Любой базис $V$ над $\mathbb{R}$ является базисом $V(\c)$ над $\c$:\\
$x=\sum\limits_kx_ke_k;\ y=\sum\limits_ky_ke_k\ \Rightarrow\ x+iy=\sum\limits_k(x_k+iy_k)e_k\,.$ %
\ab Всякий линейный оператор в $V$ единственным образом продолжается до линейного оператора в $V(\c)$:
$\om{A_{\c}}(x+iy)=\om{A}x+i\om{A}y.$ В вещественном базисе матрица $\om{A}_{\c}$ совпадает с матрицей \op{A}. %
\te Для любого линейного оператора в вещественном векторном пространстве существует одномерное или двумерное
инвариантное подпространство. %
\dok Если $f_{\om{A}}$ имеет вещественный корень, то есть одномерное инвариантное подпространство.
Предположим, что $f_{\om{A}}$ имеет мнимый корень (то есть комплексное число с ненулевой мнимой частью)\ \ $\lambda+\mu i.$%
Пусть $x+iy\in V(\c)$ - вектор, отвечающий этому собственному значению, то есть $\om{A}x+i\om{A}y=(\lambda+\mu
i)(x+iy).$ Это означает, что $\left\{%
\begin{array}{ll}
    \om{A}x=\lambda x-\mu y; &  \\
    \om{A}y=\mu x-\lambda y. &  \\
\end{array}%
\right.$ %
\\Мы видим, что $\lob{x,y}$ - не более чем двумерное инвариантное подпространство.\qed
\section{Связь между линейными операторами и билинейными\\ (полуторалинейными) функциями в евклидовом\\
(эрмитовом) пространстве. Сопряжённые операторы.} %
\label{q28} %
Пусть $V$ - евклидово пространство. Каждому линейному оператору поставим в соответствие билинейную функцию
$\phi_{\om{A}}(x,y)=(x,\om{A}y).$\\ В ортонормированном базисе матрица $\phi_{\om{A}}$ совпадает с матрицей
$\om{A}$: $\phi_{\om{A}}(e_i,e_j)=(e_i,\om{A}e_j)=a_{ij}.$ %
Отображение $\om{A}\mapsto\phi_{\om{A}}$ является изоморфизмом пространства линейных операторов на пространство
билинейных функций. Но каждой билинейной функции можно поставить в соответствие ''транспонированную''
билинейную функцию\ \ $\phi^\top(x,y)=\phi(y,x).$ Матрица такой функции есть транспозиция исходной. В
частности, можно рассмотреть $\phi_{\om{A}}^\top,$ по определению ей соответствует линейный оператор $\om{A}^*,$
называемый сопряжённым к оператору \op{A}:\ \  $(x,\om{A}^*y)=(y,\om{A}x)=(\om{A}x,y).$ В ортонормированном
базисе матрица \op{A^*} является транспонированной матрицей оператора \op{A}. %
\de Линейный оператор $\om{A}$ называется симметрическим (самосопряжённым), если $\om{A^*=A}.$ %
\de Линейный оператор $\om{A}$ называется кососимметрическим, если $\om{A^*=-A}.$ %
\de Линейный оператор $\om{A}$ называется ортогональным, если $\om{A^*A}=E,$ то есть $\om{A}$ сохраняет
скалярное произведение:\ \ $(\om{A}x,\om{A}y)=(\om{A^*A}x,y)=(x,y).$ %
\ab Теперь пусть $V$ - эрмитово пространство. Также определяется полуторалинейная функция \rule{0pt}{15pt}\\
$\phi_{\om{A}}(x,y)=(x,\om{A}).$ В ортонормированном базисе $\baz{e}$ матрица $\phi_{\om{A}}$ совпадает с матрицей
$\om{A}$. Введём $\phi^*$ - сопряжённую полуторалинейную функцию следующим образом:
$\phi^*(x,y)=\overline{\phi(y,x)}.$ %
\ab Как и в евклидовом пространстве, сопряжённый оператор \op{A^*} определяется из условия\ \
$\phi_{\om{A^*}}=\phi^*_{\om{A}}.$
$\phi_{\om{A^*}}(x,y)=(x,\om{A^*}y)=\phi^*_{\om{A}}(x,y)=\overline{\phi_{\om{A}}(y,x)}=\overline{(y,\om{A}x)}=(\om{A}x,y).$
\\Значит, $(x,\om{A^*}y)=(\om{A}x,y)$ - полностью аналогично евклидовому случаю.
\de Оператор $\om{A}$ в эрмитовом пространстве называется эрмитовым (косоэрмитовым),\\ если $\om{A^*=A}\
(\om{A^*=-A}).$ %
\de Оператор \op{A} в эрмитовом пространстве называется унитарным, если $\om{A^*=A}^{-1}.$
\section{Существование ортонормированного собственного\\ базиса для симметрического оператора.\\ Приведение
квадратичной функции в евклидовом\\ пространстве к каноническому виду.}%
\label{q29} %
\te Пусть $\om{A}$ - симметрический, кососимметрический или ортогональный оператор в евклидовом
пространстве, $U\subset V$ - инвариантное подпространство. Тогда $U^\bot$ - тоже инвариантное
подпространство.%
\dok \begin{enumerate}
    \item Пусть \op{A} - симметрический оператор. Пусть $y\in U^\bot,\ \ x\in U.$ Тогда $(x,\om{A}y)=(\om{A}x,y)=0,$
    \\ так как $\om{A}x\in U, y\in U^\bot.$
    \item Для кососимметрических операторов всё аналогично.
    \item Пусть \op{A} - ортогональный оператор. Тогда $\om{A}\,\vrule\,_U$ - тоже ортогональный оператор, значит
    является невырожденным. Пусть $y\in U^\bot,\ \ x\in U$. Надо доказать, что $\om{A}y\in U^\bot.$ Но \ $\exists\ z\in
    U$ такой, что $x=\om{A}z$. Тогда $(x,\om{A}y)=(\om{A}z,\om{A}y)=(z,y)=0$\qed
\end{enumerate}
\te Для любого симметрического оператора в евклидовом пространстве существует ортонормированный базис
из собственных векторов. %
\dok Индукция по $n=\dim V.$\\ При $n=1$ доказывать нечего.\\
Пусть $n=2$. В ортонормированном базисе $A=\left(%
\begin{array}{cc}
  a& b \\
  b & c \\
\end{array}%
\right)$. Запишем:
$$
f_{\om{A}}(t)=\left|\begin{array}{cc}
  t-a & -b \\
  -b & t-c \\
\end{array}\right|=t^2-(a+c)t+ac-b^2.\ \ t_{1,2}=\frac{\displaystyle a+c\pm\sqrt{(a-c)^2+4b^2}}{\displaystyle 2}\in
\mathbb{R}.
$$
Значит существует одномерное инвариантное подпространство $U\subset V$. Тогда $V=U\ps U^\bot,$ и $U^\bot$ тоже
инвариантно. Возьмём $e_1\in U,\ \ e_2\in U^\bot$ - единичные, собственные, ортогональные векторы. Тогда
$(e_1,e_2)$ - искомый базис. %
\\ Теперь пусть $n>2$. Существует одномерное или двумерное инвариантное подпространство,\rule{0pt}{15pt}%
\  но и в двумерном инвариантном подпространстве существует одномерное.\\ Пусть $U$ - одномерное инвариантное
подпространство, тогда $V=U\ps U^\bot.$ Но $\dim U^\bot=n-1$, значит по предположению индукции \qed %
\sled Если \op{A} - симметрический оператор, то $V=\bigoplus\limits_\lambda V_{\lambda}(\om{A}),$ причём
$V_\lambda(\om{A})\bot V_\mu(\om{A})\mbox{ при }\lambda\ne\mu.$ %
\dok Пусть $\baz{e}$ - ортонормированный базис из собственных векторов, $\om{A}e_i=\lambda_ie_i.$ Тогда
$V_\lambda(\om{A})=\lob{e_i\ :\ \lambda_i=\lambda}.$ - линейная оболочка всех векторов $e_i$ с собственным
значением $\lambda_i=\lambda.$\qed %
\te Для любой квадратичной функции $q$ в евклидовом пространстве $V$ существует ортонормированный
базис, в котором $q$ имеет вид $q(x)=\lambda_1x_1^2+\dots+\lambda_nx_n^2.$ При этом числа $\nn{\lambda}$
определяются однозначно с точностью до перестановки (приведение к главным осям). %
\dok $q(x)=(\om{A}x,x)$, где $\om{A}$ - симметрический оператор. В любом ортонормированном базисе матрица $q$
совпадает с матрицей $\om{A}$. В частности, $q(x)=\lambda_1x_1^2+\dots+\lambda_nx_n^2\ \lr\ $матрица \op{A} в этом
базисе диагональна$\ \lr\ $базис состоит из собственных векторов. По предыдущей теореме такой ортонормированный
базис существует, а $\nn{\lambda}$ - собственные значения оператора \op{A}, они не зависят от базиса. \qed
\section{Приведение к каноническому виду\\ матрицы ортогонального оператора.}
\label{q30} %
Каковы собственные значения ортогонального оператора? %
\ab $\om{A}x=\lambda x\ \Rightarrow\ (\om{A}x,\om{A}x)=\lambda^2(x,x)=(x,x)\ \Rightarrow\ \lambda=\pm 1.$ %
\te Для любого ортогонального оператора существует ортонормированный базис, в котором его матрица имеет вид:
$$
\left(%
\begin{array}{ccccccccc}
\Pi(\alpha_1)   &  &  &  &  &  &  &  &  \\
&      \ddots        &  &  &  &  &  & &  \\
&  &     \Pi(\alpha_m) &  &  &  &  &  &  \\
&  &  &     -1 &  &  &  &  &  \\
&  &  &  &    \ddots &  &  &  &  \\
&  &  &  &  &    -1 &  &  &  \\
&  &  &  &  &  &     1 &  & \\
&  &  &  &  &  &  &    \ddots &  \\
&  &  &  &  &  &  &  &    1 \\
\end{array}%
\right),\mbox{\ \ где\ \ }\Pi(\alpha)=\left(%
\begin{array}{cc}
  \cos\alpha & -\sin\alpha \\
  \sin\alpha & \cos\alpha \\
\end{array}%
\right).
$$
\dok Индукцией по $n=\dim V.$ %
\ab \underline{$n=1$}. Очевидно, что $A=(\pm 1)$ в любом базисе. %
\ab \underline{$n=2$}. Пусть $(e_1,e_2)$ - ортонормированный базис. Пусть $\om{A}e_1$ образует угол $\alpha$ с
$e_1$. Так как $\om{A}e_1\bot\om{A}e_2$, то возможно два случая:
\begin{enumerate}
    \item либо \op{A} есть поворот на угол $\alpha$, и тогда $A=\Pi(\alpha);$
    \item либо $\om{A}$ есть отражение относительно биссектрисы угла между $e_1\mbox{ и }\om{A}e_1,$ и тогда\\ $A=\left(%
\begin{array}{cc}
  -1 & 0 \\
  0 & 1 \\
\end{array}%
\right)$ в подходящем ортонормированном базисе.
\end{enumerate}
\underline{$n>2$}. Существует одномерное или двумерное инвариантное подпространство $U\subset V$,\\ тогда $V=U\ps
U^\bot,$ и $U^\bot$ инвариантно.\\ Далее стандартным рассуждением получаем что надо. \qed
\section{Существование ортонормированного собственного базиса\\ для эрмитова (унитарного) оператора.}
\label{q31}%
Всякий линейный оператор в эрмитовом пространстве имеет, очевидно, собственный вектор. %
\te Если $\om{A}$ - эрмитов или унитарный оператор и $U\subset V$ - инвариантное подпространство, то $U^\bot$ -
тоже инвариантное подпространство. %
\dok Аналогично вещественному случаю. \qed%
\te Собственные значения эрмитова (унитарного) оператора являются вещественными (соответственно, по модулю
равными единице). %
\dok \begin{enumerate}
    \item Если \op{A} - эрмитов, то $(\om{A}e,e)=\lambda(e,e)=(e,\om{A}e)=\overline{\lambda}(e,e)\ \Rightarrow\ \lambda\in\mathbb{R};\quad(e\ne 0)$
    \item Если \op{A} - унитарный, то $(\om{A}e,\om{A}e)=\lambda\overline{\lambda}(e,e)=(e,e)\ \Rightarrow\
    |\lambda|=1.\quad(e\ne 0)$\qed
\end{enumerate}
\sled Всякий симметрический оператор в евклидовом пространстве имеет собственный вектор. %
\dok Рассмотрим комплексификацию.\qed %
\te Для всякого эрмитова (унитарного) оператора в эрмитовом пространстве существует ортонормированный базис из
собственных векторов. %
\dok Аналогично евклидову случаю (без рассмотрения случая двумерного инвариантного подпространства.)\qed
\section{Полярное разложение невырожденного линейного\\ оператора в евклидовом (эрмитовом) пространстве.}
\label{q32}%
\de Симметрический оператор называется положительно определённым, если соответствующая квадратичная функция
положительно определена, то есть все собственные значения оператора положительны. %
\ab{\bf Лемма.} Для любого положительно определённого симметрического оператора \op{B} существует
единственный
положительно определённый симметрический оператор \op{S}, такой, что $\om{S}^2=\om{B}$.%
\dok \begin{enumerate}
    \item В некотором ортонормированном базисе оператор $\om{B}$ записывается диагональной матрицей
    $$\left(%
\begin{array}{ccc}
  \lambda_1 &  & 0 \\
   & \ddots &  \\
  0 &  & \lambda_n \\
\end{array}%
\right),\  \ \lambda_i>0.$$ Рассмотрим оператор \op{S},\\ который в том же базисе записывается матрицей
$$\left(%
\begin{array}{ccc}
  \sqrt{\lambda_1} &  & 0 \\
   & \ddots &  \\
  0 &  & \sqrt{\lambda_n} \\
\end{array}%
\right),\ \ \sqrt{\lambda_i}>0.$$
Очевидно, что $\om{S}^2=\om{B},$ и \op{S} - положительно определённый симметрический оператор.
    \item Пусть $\om{S}^2=\om{B},$ и \op{S} - положительно определённый симметрический оператор.\\
    Пусть $\mu_1,\dots,\mu_m$ - различные собственные значения оператора \op{S}.\\
    Тогда $V=V_{\mu_1}(\om{S})\ps\dots\ps V_{\mu_{m}}(\om{S}),$
    причём различные слагаемые ортогональны.\\ Оператор \op{B} действует на $V_{\mu_i}(\om{S})$ как умножение на
    $\mu_i^2$. Значит $V_{\mu_i}(\om{S})=V_{\mu_i^2}(\om{B}).$\\ Поэтому $\mu_i$ и $V_{\mu_i}(\om{S})$ определены
    однозначно как корни из собственных значений оператора $\om{B}$ и собственные подпространства оператора
    $\om{B}$. \qed
\end{enumerate}
\ab{\bf Теорема} (Полярное разложение). Всякий невырожденный линейный оператор $\om{A}$ в евклидовом пространстве
единственным образом представим в виде $\om{A=SO},$ где \op{S} - положительно определённый
симметрический
оператор, а \op{O} - ортогональный оператор.%
\dok \begin{enumerate}
    \item Пусть $\om{A=SO}.$ Тогда $\om{AA^*=SOO^*S^*=SS^*=S}^2.$
    Заметим, что $\om{AA^*}$ для невырожденного оператора есть положительно определённый симметрический
    оператор:\\
    $\om{(AA^*)^*=A^{**}A^*=AA^*};$\\
    $(\om{AA^*}x,x)=(\om{A^*}x,\om{A^*}x)>0\mbox{\ \ при }x\ne 0.$\\
    По лемме \op{S} определён однозначно, но тогда и $\om{O}=\om{S}^{-1}\om{A}$ тоже определён однозначно.
    \item Рассмотрим $\om{AA^*}$ - по лемме существует невырожденный положительно определённый симметрический
    оператор $\om S$ такой, что $\om{AA^*=S}^2.$ Положим $\om{O}=\om{S}^{-1}\om{A}$, тогда $\om{A=SO}$.\\ Но \op{O}
    - ортогональный оператор: $\om{OO^*}=\om{S}^{-1}\om{AA^*}\om{S^*}^{-1}=\om S^{-1}\om S^2\om S^{-1}=\om E,$ \qed
\end{enumerate}
\ab Полярное разложение невырожденного линейного оператора в эрмитовом пространстве доказывается
абсолютно аналогично.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\input linal5.tex
\section{Корневые подпространства линейного оператора.\\ Разложение пространства в прямую\\ сумму корневых подпространств.}
\label{q33} %
\de Вектор $e\in V$ называется корневым вектором оператора \op{A}, если существует такое
$m\in\mathcal{N}\cup\{0\}$, что $(\om{A-\lambda E})^me=0.$ Наименьшее такое $m$ называется высотой корневого
вектора $e$. Собственные векторы - это корневые векторы высоты $1$, нулевой вектор имеет высоту $0$.\ab Если
$(\om{A-\lambda E})^me=0$, то $(\om{A-\lambda E}^{m-1}e)$ - собственный вектор с собственным значением $\lambda$.
\\Значит, корневые векторы могут существовать только для собственных значений оператора $\om{A}$. %
\ab Совокупность всех корневых векторов, отвечающих одному и тому же $\lambda$, образует подпространство. Оно
называется корневым подпространством и обозначается $V^\lambda(\om{A})$. Понятно, что  если $e$ - корневой
вектор высоты $m$, то $(\om{A-\lambda E})e$ - корневой вектор высоты $m-1$. Значит, $(\om{A-\lambda
E})V^\lambda(\om{A})\subset V^\lambda(\om{A}).$ Поэтому $V^\lambda(\om{A})$ инвариантно относительно \op{A-\lambda
E}, значит, и относительно \op{A}. %
\ab{\bf Лемма}. В корневом подпространстве $V^\lambda(\om{A})$ существует базис, в котором матрица $\om{A}$ имеет
вид:
$$
\left(%
\begin{array}{ccc}
  \lambda &  & * \\
   & \ddots &  \\
 0 &  & \lambda \\
\end{array}%
\right).
$$
\dok $V^\lambda(\om{A})=\bigcup\limits_{m=0}^\infty\rom{Ker}(\om{A-\lambda E})^m$, поэтому
$$\rom{Ker}(\om{A-\lambda E})\subset\rom{Ker}(\om{A-\lambda E})^2\subset\dots\subset\rom{Ker}(\om{A-\lambda
E})^p=V^\lambda(\om{A}).$$ %
Выберем базис в $\rom{Ker}(\om{A-\lambda E})$, дополним его до базиса $\rom{Ker}(\om{A-\lambda E})^2$, и так
далее.\\ Получим базис в $V^\lambda(\om{A}),$ в котором матрица $\om{A-\lambda E}$ имеет вид\\ $\left(%
\begin{array}{ccc}
  0 &  & * \\
   & \ddots &  \\
 0 &  & 0 \\
\end{array}%
\right),$ а матрица $\om{A}$ - вид $\left(%
\begin{array}{ccc}
  \lambda &  & * \\
   & \ddots &  \\
 0 &  & \lambda \\
\end{array}%
\right).\qquad\om{Q.E.D.}$ %
\smallskip%
\sled Характеристический многочлен оператора $\om{A}\,\vrule\,_{V^\lambda(\om{A})}$\\ имеет вид $(t-\lambda)^q,$
где
$q=\dim V^\lambda(\om{A}).$ %
\sled При $\lambda\ne\mu$ оператор $\om{A-\mu E}$ невырожден на $V^\lambda(\om{A}).$
\medskip\te $\dim V^\lambda(\om{A})=$ кратности корня $\lambda$ в $f_\om{A}(t).$
\dok Пусть $(e_1,\dots,e_q)$ - базис в $V^\lambda(\om{A}).$\\ Дополним его до базиса $\baz{e}$ пространства $V$. В
этом базисе матрица \op{A} имеет вид:
$$
A=\left(%
\begin{array}{cc}
  B & D \\
  0 & C \\
\end{array}%
\right),
$$
где $B$ - матрица $\om{A}\,\vrule\,_{V^\lambda(\om{A})}$. Тогда $$f_\om{A}(t)=\left|%
\begin{array}{cc}
  tE-B & -D \\
  0 & tE-C \\
\end{array}%
\right|=(t-\lambda)^q\cdot\det (tE-C).$$ %
Докажем, что $\det (tE-C)$ не делится на $t-\lambda,$ то есть $\det (\lambda E-C)\ne 0.$ Рассмотрим оператор
\op{C} в пространстве $\lob{e_{q+1},\dots,e_n}$, задаваемый матрицей $C$. Если $\det (\lambda E-C)=0$, то
$\lambda$ - собственное значение \op{C}, то есть $\ \exists\ e\in\lob{e_{q+1},\dots,e_n},\ e\ne 0,$ такой что
$\om{C}e=\lambda e$. Но тогда $\om{A}e=\lambda e+u$ для некоторого $u\in\lob{e_1,\dots,e_q}=V^\lambda(\om{A}).$
Таким образом $(\om{A-\lambda E})e\in V^\lambda(\om{A})\ \Rightarrow\ e\in V^\lambda(\om{A}).$ Противоречие.\qed
\te Корневые подпространства, отвечающие различным собственным значениям $\lambda$,\\ линейно независимы. %
\dok Пусть $(\lambda_1,\dots,\lambda_s)$ - различные собственные значения.\ab Будем рассуждать индукцией по $s$.
\ab При $s=1$ доказывать нечего. %
\ab Пусть $s>1.$ Предположим, что $v_1+\dots+v_s=0,$ где $v_i\in V^{\lambda_i}(\om{A})$. Применим к этому
равенству $(\om{A}-\lambda_s\om{E})^m,$ где $m$ выбрано так, что $(\om A-\lambda_s\om E)^mv_s=0$. Тогда
$$
(\om{A}-\lambda_s\om{E})^mv_1+\dots+(\om{A}-\lambda_s\om{E})^mv_{s-1}=0.
$$
Заметим, что $(\om{A}-\lambda_s\om{E})^mv_i\in V^{\lambda_i}(\om{A}).$ По предположению, все слагаемые равны
нулю:\\ $(\om{A}-\lambda_s\om{E})^mv_i=0\quad i=1,\dots,s-1.$ Но это значит, в силу невырожденности
$(\om{A}-\lambda_s\om{E})^m$ на $V^{\lambda_i}(\om{A})$ при $s\ne i$, что $v_i=0\quad i=1,\dots,s-1$. Но тогда и
$v_s=0$.\qed %
\te Если $f_\om{A}(t)=(t-\lambda_1)^{k_1}\dots(t-\lambda_s)^{k_s}$, где $\lambda_1,\dots,\lambda_s$ различны, то
$V=V^{\lambda_1}(\om{A})\ps\dots\ps V^{\lambda_s}(\om{A}).$ %
\dok По двум предыдущим теоремам, эти подпространства линейно независимы, и сумма их размерностей равна
размерности всего пространства, поэтому\qed
\section{Нильпотентные операторы. Разложение пространства\\ в прямую сумму циклических подпространств\\ нильпотентного оператора.}
\label{q34} %
$V^\lambda(\om{A})=\rom{Ker}(\om{A-\lambda E})^m$ для некоторого $m$. Значит, если обозначить
$\om{N}=\om{A-\lambda E}\,\vrule\,_{V^\lambda(\om{A})}$, то $\om N^m=0$, поэтому \op{N} - нильпотентный оператор.
Изучим нильпотентные операторы.\ab Пусть \op{N} - нильпотентный оператор в пространстве $V$. Высотой вектора $v$
назовём наименьшее $m$, для которого $\om{N}^mv=0.$ Обозначается $\rom{ht}v.$%
\ab{\bf Лемма 1}. Пусть $e$ - вектор высоты $m$. Тогда векторы $e,\om{N}e,\dots,\om{N}^{m-1}e$ линейно независимы.
\dok Пусть $\lambda_0e+\lambda_1\om{N}e+\dots+\lambda_{m-1}\om{N}^{m-1}e=0$ - нетривиальная линейная зависимость.
Пусть $\lambda_k$ - первый ненулевой коэффициент. Применим $\om{N}^{m-k-1}$, получим $\lambda_k\om{N}^{m-1}e=0.$
\\Противоречие.\qed
\de Подпространство $\lob{e,\om{N}e,\dots,\om{N}^{m-1}e}$ называется циклическим подпространством,
порождённым вектором $e$. Это подпространство инвариантно относительно $\om{N}$, причём в базисе\\
$(e,\om{N}e,\dots,\om{N}^{m-1}e)$ матрица ограничения $\om{N}$ на это подпространство имеет вид:
$$
\left(%
\begin{array}{cccc}
  0 & 1 &  & 0 \\
   & 0 &  &  \\
   &  & \ddots & 1 \\
  0 &  &  & 0 \\
\end{array}%
\right).
$$
Такая матрица называется нильпотентной жордановой клеткой. %
\ab{\bf Лемма 2}. Пусть $e$ - вектор высоты $m$, $U=\lob{e,\om{N}e,\dots,\om{N}^{m-1}e}.$ Если $e'\in
U\backslash\om{N}U,$ то $e'$ порождает то же циклическое подпространство $U$. %
\dok $e'=\lambda_0e+\lambda_1\om{N}e+\dots+\lambda_{m-1}\om{N}^{m-1}e,\  \lambda_0\ne 0$, значит
$\om{N}^{m-1}e'=\lambda_0\om{N}^{m-1}e\ne 0\ \Rightarrow\ \rom{ht}e'=m\ \Rightarrow\
\lob{e',\om{N}e',\dots,\om{N}^{m-1}e'}=U.$\qed %
\te Для всякого нильпотентного оператора $\om{N}$ всё пространство может быть разложено в прямую сумму
циклических подпространств, а число слагаемых в разложении равно $\dim\rom{Ker}\om{N}.$ %
\dok Индукцией по $n=\dim V.$ %
\ab При $n=1$ доказывать нечего. %
\ab Пусть $n>1$. Так как \op{N} вырожден, то $\om{N}V\ne V.$ Пусть $U$ - любое пространство размерности $n-1$,
содержащее $\om{N}V.$ Очевидно, что $U$ инвариантно, так как $\om{N}V\subset U\ \Rightarrow\ \om{N}U\subset U.$ %
По предположению, $U$ разложимо в прямую сумму циклических подпространств $U=U_1\ps\dots\ps U_k.$ Пусть $e\in
V\backslash U.$ Тогда $\om{N}e\in U\ \Rightarrow\ \om{N}e=u_1+\dots+u_k\quad u_i\in U_i.$ Если $u_i\in\om{N}U_i,$
то есть $u=\om{N}v_i\quad v_i\in U_i,$ то, заменив $e$ на $e-v_i,$ получим $u_i=0.$ Так что будем считать, что
для каждого $i$ либо $u_i\notin\om{N}U_i,$ либо $u_i=0.$
\begin{enumerate}
    \item Пусть все $u_i=0,$ то есть $\om{N}e=0.$ Тогда $\lob{e}$ - одномерное циклическое подпространство, $V=\lob{e}\ps U_1
    \ps\dots\ps U_k.$
    \item Если не все $u_i=0,$ то $\rom{ht}\om{N}e=\max\limits_{i\ :\ u_i\ne 0}\rom{ht}u_i=m.$ Без ограничения
    общности считаем, что $\rom{ht}u_1=m.$ Тогда $\rom{ht}e=m+1.$ Докажем, что $V=\lob{e,\om{N}e,\dots,\om{N}^me}\ps U_2\ps\dots\ps U_k.$
    Надо доказать, что сумма прямая, ведь так как $u_i\notin\om{N}U_i,$ $\dim U_1=m$, поэтому сумма размерностей
    уже равна $\dim V.$ Так как $U_2,\dots,U_k$ линейно независимы, достаточно доказать, что\\ $\lob{e,\om{N}e,\dots,\om{N}^me}\cap(U_2\ps\dots\ps U_k)=0.$
    Пусть $\lambda_0e+\lambda_1\om{N}e+\dots+\lambda_m\om{N}^me\in U_2\ps\dots\ps U_k.$ Так как $e\notin U$, то $\lambda_0=0.$
    Проектируя на $U_1$, получаем, что (так как $\om{N}e=u_1+\dots+u_k$) $\lambda_1u_1+\lambda_2\om{N}u_1+\dots+\lambda_m\om{N}^{m-1}u_1=0.$
    Но тогда по Лемме 1, $\lambda_1=\dots=\lambda_m=0.$
\end{enumerate}
\ab Теперь докажем про число подпространств. Пусть $V=U_1\ps\dots\ps U_k$ - разложение $V$ в прямую сумму
циклических подпространств. Поэтому
$\rom{Ker}\om{N}=\rom{Ker}\om{N}\,\vrule\,_{U_1}\ps\dots\ps\rom{Ker}\om{N}\,\vrule\,_{U_k}.$ Но
$\dim\rom{Ker}\om{N}\,\vrule\,_{U_i}=1$, поэтому $\dim\rom{Ker}\om{N}=k.$\qed
\section{Приведение матрицы линейного оператора к жордановой форме. Минимальный многочлен.\\ Теорема Гамильтона-Кэли. Критерий существования\\ собственного базиса.}
\label{q35} %
\ab Пусть \op{A} - линейный оператор, характеристический многочлен которого раскладывается на линейные
множители. Тогда $V=V^{\lambda_1}(\om{A})\ps\dots\ps V^{\lambda_s}(\om{A}).$ Для каждого $i$ подпространство
$V^{\lambda_i}(\om{A})$ может быть разложено в прямую сумму циклических подпространств относительно
нильпотентного оператора $\om{N}_i=\om{A-\lambda E}\,\vrule\,_{V^{\lambda_i}(\om{A})}.$ В базисе
пространства $V$, составленном из базисов всех этих подпространств, матрица \op{A} будет иметь вид:
$$
A=\left(%
\begin{array}{ccc}
  J_1 &  & 0 \\
   & \ddots &  \\
  0 &  & J_p \\
\end{array}%
\right),\mbox{\ где\ }J_1,\dots,J_p - \mbox{\ матрицы вида\ } \left(%
\begin{array}{cccc}
  \lambda & 1 &  & 0 \\
   & \lambda &  &  \\
   &  & \ddots & 1 \\
  0 &  &  & \lambda \\
\end{array}%
\right).
$$
\ab --- так называемые жордановы клетки (для каждого собственного значения $\lambda$ может быть несколько
жордановых клеток с этим значением - столько, сколько циклических подпространств). Сама матрица такого вида
называется жордановой. Таким образом, доказана следующая теорема: %
\te Если характеристический многочлен линейного оператора раскладывается на линейные множители, то существует
базис, в котором матрица этого оператора жорданова (такой базис называется жордановым). \qed%
\ab Можно также доказать, что жорданова форма матрицы линейного оператора единственна с точностью до
перестановки клеток, хотя сам жорданов базис далеко не единствен. %
\ab Сумма порядков жордановых клеток с одним и тем же $\lambda$ на диагонали равна $\dim V^\lambda(\om{A}),$\\ то
есть кратности корня $\lambda$ в $f_\om{A}(t),$ а количество этих клеток равно $\dim V_\lambda(\om{A}).$ %
\ab Максимальный порядок этих клеток равен высоте оператора $(\om{A-\lambda E})\,\vrule\,_{V^\lambda(\om{A})}.$
\de Пусть $f(t)=a_0t^n+\dots+a_{n-1}t+a_n,$ \op{A} - линейный оператор. Тогда можно определить\\
$f(\om{A})=a_0\om{A}^n+\dots+a_{n-1}\om{A}+a_n\om{E}.$ Аналогично можно определить $f(A)$ для матриц.\\ Если в
каком-то базисе оператор \op{A} имеет матрицу $A$, то оператор $f(\om{A})$ имеет матрицу $f(A).$ Понятно,
что:\begin{enumerate}
    \item $(f+g)(\om{A})=f(\om{A})+g(\om{A})$;
    \item $(fg)(\om{A})=f(A)\cdot g(\om{A})$.
\end{enumerate}
\de Многочлен $f$ называется аннулирующим многочленом оператора \op{A}, если $f(\om{A})=0.$ %
\ab{\bf Лемма}. Для любого линейного оператора \op{A} существует ненулевой аннулирующий многочлен. %
\dok Так как $\dim L(V)=n^2<\infty$ ($L(V)$ - пространство линейных операторов), то система
$$\om{E,A,A}^2\om{,\dots,A}^{n^2}$$
линейно зависима. Значит, существует аннулирующий многочлен с коэффициентами
линейной зависимости этой системы операторов. Степень этого многочлена равна $n^2$. \qed %
\ab Любой многочлен, кратный аннулирующему, тоже является аннулирующим. %
\ab{\bf Лемма}. Пусть $m$ - аннулирующий многочлен оператора \op{A} минимальной степени. Тогда всякий аннулирующий
многочлен кратен $m$. %
\dok Пусть $f$ - аннулирующий многочлен. Поделим: $f=qm+r$.\\ Но тогда $r=f-qm$ - тоже аннулирующий многочлен. Но
тогда $r=0$, потому что его степень меньше степени $m$.\qed %
\de Аннулирующий многочлен минимальной степени со старшим коэффициентом $1$ называется минимальным многочленом
оператора \op{A}. Обозначается $m_{\om{A}}.$ Всякий другой аннулирующий многочлен кратен ему.%
\ab{\bf Лемма 1}. Пусть $J$ - жорданова клетка порядка $m$ с собственным значением $\lambda$. Тогда
$m_J=(t-\lambda)^m.$ %
\dok $(J-\lambda E)^m=0\ \Rightarrow\ (t-\lambda)^m$ - аннулирующий многочлен.\\ Значит, $m_J=(t-\lambda)^k,\ k\le
m.$ Но $(J-\lambda E)^{m-1}\ne 0\ \Rightarrow\ k=m.$\qed %
\ab{\bf Лемма 2}. Если $$A=\left(%
\begin{array}{ccc}
  A_1 &  & 0 \\
   & \ddots &  \\
  0 &  & A_k \\
\end{array}%
\right),$$ то $m_A={\rm HOK}(m_{A_1},\dots,m_{A_k}).$ %
\dok Вытекает из того, что операции над клеточно-диагональной матрицей сводятся к тем же самым операциям над
клетками. Поэтому $f(A)=0\ \lr\ f(A_i)=0\ \forall\ i\ \Rightarrow\ \\\Rightarrow\ m_A={\rm
HOK}(m_{A_1},\dots,m_{A_k}).$\qed %
\te Пусть характеристический многочлен оператора \op{A} раскладывается на линейные множители:\ \
$f_{\om{A}}(t)=(t-\lambda_1)^{k_1}\dots(t-\lambda_s)^{k_s}$, где $\lambda_1,\dots,\lambda_s$ различны. Тогда
$m_\om{A}(t)=(t-\lambda_1)^{m_1}\dots(t-\lambda_s)^{m_s}$, где $m_i$ - максимальный порядок жордановых клеток с
собственным значением $\lambda$ в жордановой форме матрицы оператора \op{A}. %
\dok Пусть $$J=\left(%
\begin{array}{ccc}
  J_1 &  & 0 \\
   & \ddots &  \\
  0 &  & J_p \\
\end{array}%
\right)$$ - жорданова форма матрицы оператора \op{A}.\\ Тогда по Лемме 2 $m_\om{A}={\rm
HOK}(m_{J_1},\dots,m_{J_k})$,  значит по Лемме 1\qed %
\ab{\bf Следствие} (Теорема Гамильтона-Кэли). $f_\om{A}(\om A)=0.$ %
\dok Из теоремы вытекает, что $m_\om A\,\vrule\,f_\om A$ - действительно, $k_i\ge m_i.$\\ Значит, $f_\om{A}(\om
A)=0.$\qed %
\ab Таким образом, видно, что есть аннулирующие многочлены степени не выше $n$. %
\ab{\bf Следствие} (Критерий диагонализируемости). Матрица $A$ диагонализируема $\ \lr\ $ её
характеристический многочлен разлагается на линейные множители, а минимальный не имеет кратных корней.
\dok Матрица приводится к диагональному виду $\ \lr\ $ её жорданова форма диагональна $\ \lr\ $ все
$m_i$ в обозначениях теоремы равны 1, то есть $m_\om A$ раскладывается на линейные множители $\ \lr\ $ не
имеет кратных корней.\qed

%\input linal6.tex
\section{Аффинные пространства. Векторизация.\\ Аффинные системы координат.\\ Барицентрические линейные комбинации точек.}
\label{q36} %
Пусть $V$ - векторное пространство над полем $K$. %
\de Аффинным пространством, ассоциированным с векторным пространством $V$, называется множество $S$, элементы
которого называются точками, вместе с операцией сложения точек и векторов $V\times S\rightarrow S,$
$(p,x)\mapsto p+x$, удовлетворяющей следующим условиям:
\begin{enumerate}
    \item $p+(x+y)=(p+x)+y;$
    \item $p+0=p;$
    \item $\forall\ p,q\in S \ \exists !\ x\in V\ :\ p+x=q,$ обозначается: $x=\oi{pq}.$
\end{enumerate}
\ab Само векторное пространство $V$ можно рассматривать как аффинное пространство, ассоциированное с
самим собой
(тогда сложение точек и векторов - это сложение векторов). При этом $\oi{pq}=q-p.$ %
\ab Каждое аффинное пространство $S$, ассоциированное с $V$, можно отождествить с $V$, если фиксировать начало
отсчёта $o\in S.$ При этом каждую точку $p\in S$ можно отождествить с её радиус-вектором $\oi{op}.$ При этом
операции сложения точек и векторов будет соответствовать операция сложения векторов:
$\oi{o(p+x)}=\oi{op}+\oi{px},$ так как $o+(p+x)=(o+p)+x.$ Операция выбора
точки $o$ и отождествления аффинного пространства $S$ с векторным пространством называется векторизацией. %
\ab Свойство: $\oi{pq}+\oi{qr}=\oi{pr}.$  %
\ab Действительно, обозначим $\oi{pq}=x,\ \oi{qr}=y$, тогда $p+(x+y)=(p+x)+y=q+y=r\ \Rightarrow\ x+y=\oi{pr}$. %
\de Размерностью аффинного пространства называется размерность соответствующего ему векторного пространства.
\ab В аффинном пространстве можно ввести систему координат. Репером в пространстве $S$ называется система
$(o;\nn{e})$, где $o$ - точка (начало отсчёта), а $\baz{e}$ - базис пространства $V$. %
\ab В репере каждая точка имеет свои координаты: $\forall\ p\in S\ \ \oi{op}=\sum x_ie_i;$ тогда $\baz{x}$ -
координаты точки $p$ относительно репера $(o;\nn{e})$. Свойства:
\begin{enumerate}
    \item Координаты точки $p+x$ суть суммы соответствующих координат точки $p$ и вектора $x$;
    \item Координаты вектора $\oi{pq}$ суть разности соответствующих координат точек $p$ и $q$.
\end{enumerate}
\de Выберем начало отсчёта $o$ и положим $p=\sum\limits_{i=1}^k\lambda_ip_i,$ где
$\oi{op}=\sum\limits_{i=1}^k\lambda_i\oi{op_i}.$ Получим линейную комбинацию точек. Барицентрическими
линейными комбинациями точек называются такие линейные комбинации, в которых сумма коэффициентов равна единице:
$\sum\limits_{i=1}^k\lambda_i=1.$ %
\ab Докажем, что точка $p=\sum\limits_{i=1}^k\lambda_ip_i,$ где $\sum\limits_{i=1}^k\lambda_i=1,$ не зависит от
выбора точки $o$.\\ Пусть $o'$ - другая точка. Тогда имеем: \
$\sum\lambda_i\oi{o'p_i}=\sum\lambda_i(\oi{o'o}+\oi{op_i})=\sum\lambda_i\oi{o'o}+\sum\lambda_i\oi{op_i}=\oi{o'o}+\sum\lambda_i\oi{op_i}.$
Значит\ \  $o'+\sum\lambda_i\oi{o'p_i}=o+\oi{o'o}+\sum\lambda_i\oi{op_i}=o+\sum\lambda_i\oi{op_i}.$\qquad\qed %
\ab Имеет смысл центр масс системы точек $p_1,\dots,p_k$ с массами $m_1,\dots,m_k$ - это точка
$$
\rom{cent}(p_1,\dots,p_k;\ m_1,\dots,m_k)=\frac{1}{\sum m_i}\sum m_ip_i.
$$
Центр тяжести можно брать по частям, имеет место теорема Архимеда о медианах треугольника.
\section{Плоскости аффинного пространства, их задание системами линейных уравнений. Аффинная оболочка системы точек.}
\label{q37} %
\de Пусть $S$ - аффинное пространство, ассоциированное с векторным пространством $V$.\\ Плоскостью в $S$
называется подмножество вида $P=p_0+U$, где $p_0\in S$, а $U\subset V$ - подпространство. %
\ab{\bf Предложение 1}. $p_0\in P\ \Rightarrow\ p_0'+U=P.$ %
\dok $p_0'=p_0+u_0$ для некоторого $u_0\in U$. Значит $p_0'+U=p_0+u_0+U=p_0+U$. %
\ab{\bf Предложение 2}. $p_0+U=p_0'+U'\ \Rightarrow\ U=U'.$ %
\dok $p'_0\in p_0+U\ \Rightarrow\ p_0+U=p_0'+U=p_0'+U'\ \Rightarrow\ U=U'.$ %
\de Подпространство $U$ называется направляющим подпространством плоскости $P$.%
\ab{\bf Предложение 3}. Плоскость $P\subset S$ является аффинным пространством, ассоциированным с $U$,
относительно той же операции сложения точек и векторов, которая определена в пространстве $S.$ %
\dok \begin{enumerate}
    \item $p\in P,\ u\in U\ \Rightarrow\ p+u\in p+U=P$ - замкнутость относительно операции сложения\\ точек и
    векторов.
    \item Свойства $p+(x+y)=(p+x)+y$ и $p+0=p$ выполнены, так как они выполнены в $S$.
    \item $p,q\in P\ \Rightarrow\ P=p+U,\ q=p+u$ для некоторого $u\in U.\ \Rightarrow\ \oi{pq}=u\in U,$ причём
    вектор $\oi{pq}$ единствен, так как он единствен во всём пространстве. \qed
\end{enumerate}
\sled Любая барицентрическая линейная комбинация точек из $P$ лежит в $P$. %
\ab Плоскость можно определить как подмножество, замкнутое относительно взятия барицентрических линейных
комбинаций. %
\de Размерность плоскости - это размерность её направляющего подпространства: $\dim P=\dim U.$ %
\ab Нульмерные  плоскости - это точки, одномерные плоскости называются прямыми, $(n-1)-$мерные плоскости называются
гиперплоскостями. %
\ab Фиксируем в $S$ аффинную систему координат.%
\te Множество всех решений совместной системы линейных уравнений является плоскостью в $S$, и обратно, любая
плоскость является множеством решений некоторой системы линейных уравнений.%
\dok \begin{enumerate}
    \item Пусть есть совместная система линейных уравнений
    $$
    \sum_{j=1}^na_{ij}x_j=b_i\qquad(i=1,\dots,m).
    $$
    Пусть $p_0\in S$ - какое-либо её решение. Тогда множество всех её решений получается так: $p_0+U$, где
    $U$ - множество решений присоединённой однородной системы линейных уравнений. Но $U$ - подпространство в
    $V$, если интерпретировать решения как векторы, значит множество всех решений исходной системы линейных
    уравнений есть плоскость.
    \item Пусть $P=p_0+U$ - плоскость в $S$. Существует система линейных однородных уравнений, задающая
    направляющее подпространство $U$: $\sum\limits_{j=1}^na_{ij}x_j=0\quad(i=1,\dots,m)$. Подставим в левые части
    координаты точки $p_0.$ Получим какие-то числа $b_1,\dots,b_m.$\\ Рассмотрим систему линейных уравнений
    $\sum\limits_{j=1}^na_{ij}x_j=b_i\quad(i=1,\dots,m),$ она и будет искомой, её множество решений - это и есть $p_0+U.$\qed
\end{enumerate}
Если $\dim P=k,$ то $P$ задаётся $n-k$ линейно независимыми уравнениями. В частности, одно уравнение
$a_1x_1+\dots+a_nx_n=b$, где не все $a_i=0$, задаёт гиперплоскость, и обратно, всякая гиперплоскость задаётся
одним линейным уравнением. %
\te Через любые $k+1$ точку $p_0,p_1,\dots,p_k\in S$ проходит плоскость размерности $\le k,$ если же эти точки не
лежат в плоскости размерности меньше $k$, то через них проходит единственная $k-$мерная плоскость. %
\dok \begin{enumerate}
    \item Рассмотрим плоскость $P=p_0+\lob{\oi{p_0p_1},\dots,\oi{p_0p_k}}$. $p_0,p_1,\dots,p_k\in P,\\\ \dim P=\rom{rk}\left
    \{\oi{p_0p_1},\dots,\oi{p_0p_k}\right\}\le k.$
    \item Предположим, что $p_0,p_1,\dots,p_k$ не лежат в плоскости размерности меньше чем $k$. Тогда векторы
    $$\oi{p_0p_1},\dots,\oi{p_0p_k}$$ линейно независимы, и плоскость $P=p_0+\lob{\oi{p_0p_1},\dots,\oi{p_0p_k}}$
    является единственной плоскостью, содержащей все точки $p_0,p_1,\dots,p_k$. Действительно, пусть $P'=p_0+U'$ -
    другая $k-$мерная плоскость, содержащая точки $p_0,p_1,\dots,p_k$. Тогда $\oi{p_0p_1},\dots,\oi{p_0p_k}\in U\ \Rightarrow\\
    \Rightarrow\ U=\lob{\oi{p_0p_1},\dots,\oi{p_0p_k}}.$\qed
\end{enumerate}
\de Точки $p_0,p_1,\dots,p_k$ называются аффинно независимыми, если они не содержатся в плоскости размерности
меньше чем $k$, то есть если векторы $\oi{p_0p_1},\dots,\oi{p_0p_k}$ линейно независимы.\\%
Пусть $M\subset S$ - произвольное непустое подмножество, $p_0\in M.$ Плоскость $P=p_0+\lob{\oi{p_0p}\ :\ p\in M}$
является наименьшей плоскостью, содержащей $M$. Она называется аффинной оболочкой множества $M$ и
обозначается $\rom{aff}M.$%
\section{Взаимное расположение\\ плоскостей в аффинном пространстве.}
\label{q38}%
Рассмотрим две плоскости: $P_1=p_1+U_1$ и $P_2=p_2+U_2.$ Если их пересечение непусто, то оно является плоскостью:
$p_0\in P_1\cap P_2\ \Rightarrow\ P_1=p_0+U_1;\ P_2=p_0+U_2\ \Rightarrow\ P_1\cap P_2=p_0+(U_1\cap U_2).$ %
\te $P_1\cap P_2\ne \varnothing \lr\ \oi{p_1p_2}\in U_1+U_2.$%
\dok $P_1\cap P_2\ne \varnothing \lr\ \exists\ u_1\in U_1,\ u_2\in U_2\ :\ p_1+u_1=p_2+u_2.$ Но $p_1+u_1=p_2+u_2\ \lr\
\oi{p_1p_2}=u_1+(-u_2).$ Поэтому существование таких векторов $u_1$ и $u_2$ равносильно тому, что $\oi{p_1p_2}\in
U_1+U_2.$\qed %
\de Плоскости $P_1$ и $P_2$ называются параллельными, если $U_1\subset U_2$ или $U_2\subset U_1$. Плоскости $P_1$
и $P_2$ называются скрещивающимися, если $P_1\cap P_2=\varnothing$ и $U_1\cap U_2=0.$
\section{Выпуклые множества.\\ Выпуклая оболочка системы точек. Симплексы.}
\label{q39}%
Пусть $S$ - аффинное пространство над полем $\mathbb{R}.$ Отрезком, соединяющим точки $p,q\in S$, называется
множество $pq=\left\{\lambda p+(1-\lambda)q\ :\ 0\le\lambda\le 1\right\}.$\ Множество $M\subset S$ называется
выпуклым, если вместе с любыми двумя точками оно содержит и весь отрезок, их соединяющий: $\ \forall\ p,q\in M \ \
pq\subset M.$ %
\ab Пересечение выпуклых множеств является выпуклым множеством, всякая плоскость является выпуклым множеством.%
\de Выпуклой комбинацией точек пространства $S$ называется их барицентрическая линейная комбинация с
неотрицательными коэффициентами.%
\te Выпуклое множество $M$ вместе с любыми точками $p_0,\dots,p_k$ содержит любую их выпуклую оболочку.%
\dok Индукцией по $k$%
\ab При $k=0$ доказывать нечего. При $k=1$ по определению любая выпуклая оболочка двух точек лежит на отрезке, их
соединяющем, который, в свою очередь, содержится в множестве $M$.\ab%
При $k>1$ пусть $p=\lambda_0p_0+\dots+\lambda_kp_k,\quad\sum\limits_i\lambda_i=1,\ \lambda_i\ge 0\ \forall\ i.$
\\Рассмотрим $p'=\frac{\displaystyle 1}{\sum\limits_{i=0}^{k-1}\lambda_i}\left(\lambda_0p_0+\dots+\lambda_{k-1}p_{k-1}\right)\in
M$ по предположению индукции.\\ Но тогда $p=\left(\sum\limits_{i=0}^{k-1}\lambda_i\right)\cdot p'+\lambda_kp_k\in
M$ по определению.\qed%
\ab Пусть $M\subset S$ - произвольное подмножество. %
\te Совокупность всех выпуклых линейных комбинаций точек множества $M$ есть выпуклое множество.%
\dok Пусть $p'=\sum\limits_{i=0}^k\lambda'_ip_i,\ p''=\sum\limits_{i=0}^k\lambda''_ip_i$ - две линейных комбинации
точек\\ $p_0,p_1,\dots,p_k\in M$ (без ограничения общности можно считать, что это линейные комбинации
одинакового набора точек). Пусть $\mu',\mu''\ge 0,\ \mu'+\mu''=1$. Тогда надо доказать, что
$\mu'p'+\mu''p''\in M.$\\ Но\  \ $\mu'p'+\mu''p''=\sum\limits_{i=0}^k(\mu'\lambda'+\mu''\lambda'')p_i$ - выпуклая
комбинация точек\marginpar{\footnotesize векторизация!}
$p_0,p_1,\dots,p_k\in M.$\qed %
\de Совокупность выпуклых линейных комбинаций точек из $M$ называется выпуклой оболочкой множества $M$.
Обозначается $\rom{conv}M.$ Это наименьшее выпуклое множество, содержащее $M$. %
\de Выпуклая оболочка аффинно независимых точек $p_0,p_1,\dots,p_k$ называется $k-$мерным симплексом, натянутым
на $p_0,p_1,\dots,p_k.$ Нульмерный симплекс - это точка, одномерный - это отрезок. Двухмерный симплекс называется
треугольником, трёхмерный - тетраэдром.
\section{Полупространства. Выпуклые многогранники, их грани.\\ Грани симплекса и параллелепипеда.}
\label{q40}%
\de Полупространством называется множество, задаваемое линейным неравенством $a_1x_1+\dots++\,a_nx_n\ge b,$ где не
все $a_i=0.$ При этом гиперплоскость, задаваемая соответствующим равенством $a_1x_1+\dots+a_nx_n=b$, называется
граничной гиперплоскостью данного полупространства. Полупространство $a_1x_1+\dots+a_nx_n\le b$ называется
противоположным полупространством. %
\ab С каждой гиперплоскостью связаны два полупространства.%
\ab{\bf Утверждение}. Полупространство является выпуклым множеством.%
\dok Линейное неравенство, задающее полупространство, на любой прямой превращается в неравенство вида $\alpha
t+\beta\ge 0$ (если прямая имеет вид $\oi{x}=\oi{x_0}+\oi{a}t$). Пересечение полупространства с любой прямой есть
либо вся прямая, либо луч, либо оно пусто; то есть в любом случае это выпуклое множество. Значит, полуплоскость
является выпуклым множеством.\qed %
\de Выпуклым многогранником называется пересечение конечного числа полупространств.\\ Иначе говоря, выпуклый
многогранник есть множество решений системы линейных неравенств:
$$\left\{%
\begin{array}{ll}
    a_{11}x_1+\dots+a_{1n}x_n\ge b_1;\\
    \vdots\\
    a_{m1}x_1+\dots+a_{mn}x_n\ge b_m.\\
\end{array}%
\right.$$
\ab(здесь и все $a_{ij}$ могут быть нулями!).
\de Функция вида $l(x)=a_1x_1+\dots+a_nx_n+b$ называется аффинно-линейной функцией (здесь $\nn{x}$ - координаты точки $x$).
\ab Можно переписать систему неравенств, задающую выпуклый многогранник:
$$\left\{%
\begin{array}{ll}
    l_1(x)\ge 0\,;\\
    \vdots\\
    l_m(x)\ge 0.\\
\end{array}%
\right.
$$
\de Гранью выпуклого многогранника $M$ называется любое непустое подмножество $\Gamma\subset M$, которое может быть получено
заменой некоторых из неравенств, задающих многогранник $M$, на равенства.
\ab{\bf !} Может оказаться, что какие-то из оставшихся неравенств выполняются всюду на этой грани как равенства.
\ab{\bf !} Грань грани $\Gamma$ - это то же самое, что грань многогранника $M$, содержащаяся в $\Gamma.$ Таким образом,
выпуклый многогранник сам является своей гранью.
\ab Нульмерные грани называются вершинами, одномерные - рёбрами, $(\dim M-1)$-мерные грани называются гипергранями.
\ab{\bf Грани симплекса}. Рассмотрим симплекс $T$, натянутый на репер $(p_0;\,\oi{p_0p_1},\dots,\oi{p_0p_n}).$\\ Тогда
$T=\left\{x=x_1p_1+\dots+x_1p_1\ :\ x_i\ge 0, \sum x_i=1\right\}$. Значит, неравенства:
$$
\left\{%
\begin{array}{ll}
    x_i\ge 0\qquad i=1,\dots,n;\\
    \sum\limits_{j=1}^nx_i\le 1\\
\end{array}%
\right.
$$
задают симплекс $T$ относительно репера $(p_0;\,\oi{p_0p_1},\dots,\oi{p_0p_n}).$
\ab Грани симплекса $T$, проходящие через $p_0$, суть пересечения координатных плоскостей с симплексом. Это будут симплексы,
натянутые на точку $p_0$ и какие-то из точек $p_1,p_2,\dots,p_n.$ Таким образом, все грани симплекса - это симплексы, натянутые
на всевозможные непустые подмножества множества $\{p_0,p_1,\dots,p_n\}.$ Их число $2^{n+1}-1$. Вершины этих симплексов~--- это
какие-то из вершин исходного симплекса.
\ab{\bf Грани параллелепипеда}. Пусть $\baz{e}$ - базис пространства $V$. Параллелепипед - это множество
$$P(p_0;\,\nn{e})= p_0+P(\nn{e})=\left\{p_0+\sum\limits_{i}x_ie_i\ :\ 0\le x_i\le 1\right\}.$$
Таким образом, параллелепипед задаётся неравенствами:
\ $0\le x_i\le 1\quad(i=1,\dots,n).$
\\Найдем его грани. С точностью до нумерации координат, всякая грань размерности $k$ задаётся соотношениями:
$$\left\{%
\begin{array}{ll}
    0\le x_i\le 1, & \hbox{$i=1,\dots,k;$} \\
    x_j=\eps_j, & \hbox{$j=k+1,\dots,n;\,\eps_j\in\{0,1\}$.} \\
\end{array}%
\right.
$$
Число $k-$мерных граней равно $C_n^k\cdot 2^{n-k}.$ В частности, число вершин равно $2^n.$
\section{Теорема о том, что всякий ограниченный выпуклый\\ многогранник есть выпуклая оболочка своих вершин.\\ Задача линейного программирования.}
\label{q41}
\de Выпуклое множество $M\subset S$ называется телесным (или выпуклым телом), если его аффинная оболочка совпадает
со всем пространством: $\rom{aff}M=S.$%
\ab{\bf Лемма}. Выпуклое тело содержит внутренние точки.%
\dok Пусть $p_0\in M.$ Тогда $\ \rom{aff}M=p_0+\lob{\oi{p_0p}\ :\ p\in M}=S.$\\ Значит, $\rom{rk}\left\{\oi{p_0p}\
:\ p\in M\right\}=\dim S=n\ \Rightarrow\ \exists\ p_1,\dots,p_n\in M,$ такие, что
$(\oi{p_0p_1},\dots,\oi{p_0p_n})$ - базис пространства $V$. Точки $p_0,p_1,\dots,p_n$ аффинно независимы, и
натянутый на них симплекс (в силу выпуклости $M$) содержится в $M$. Но симплекс, очевидно, содержит внутренние
точки.\qed %
\de $\dim M\doteqdot\dim\rom{aff}M.$ %
\ab Всякое выпуклое множество $M$ является телом в $\rom{aff}M.$ Допуская вольность речи, будем называть
внутренними точками множества $M$ точки, внутренние по отношению к $\rom{aff}M.$ %
\ab{\bf Теорема }(Минковского-Вейля). Всякий ограниченный выпуклый многогранник $M$ совпадает с выпуклой оболочкой множества своих вершин.
\dok Индукцией по $n=\dim M.$
\ab При $n=0$ доказывать нечего: $M$ - это точка.
\ab Пусть $n>0.$ Заменив $S$ на $\rom{aff}M$, можно считать, что $M$ - телесный выпуклый многогранник. Пусть $p$ - какая-либо
внутренняя точка $M$. Все определяющие $M$ неравенства в точке $p$ выполняются как строгие (иначе в любой окрестности точки $p$
есть точки, в которых какое-либо из неравенств неверно). Проведём через $p$ произвольную прямую $l$. Её пересечение с $M$
есть ограниченное выпуклое множество - отрезок $qr$. В точках $q$ и $r$ какие-то из неравенств выполняются как равенства,
значит, эти точки принадлежат собственным граням многогранника $M$. По предположению индукции, точки $q$ и $r$
принадлежат выпуклой оболочке множества вершин многогранника $M\ \Rightarrow\ \\\Rightarrow\ $ значит и $qr,$ и точка $p$ тоже принадлежат
этой выпуклой оболочке.\qed
\ab{\bf ! }На самом деле, верно и обратное (выпуклая оболочка конечного числа точек есть выпуклый многогранник) - без доказательства.
\ab{\bf Задача линейного программирования}. Требуется найти максимум аффинно-линейной функции на ограниченном выпуклом многограннике.
\te Максимум аффинно-линейной функции $l$ на ограниченном выпуклом многограннике $M$ достигается хотя бы в одной из вершин (на
самом деле, множество всех точек максимума аффинно-линейной функции есть грань многогранника $M$ - без доказательства).
\dok Воспользуемся тем, что $l(\sum\limits_i\lambda_ip_i)=\sum\limits_i\lambda_il(p_i)\quad(\sum\limits_i\lambda_i=1)$ - это
очевидно.\\
Пусть $p_1,\dots,p_k$ - все вершины $M$. Тогда $\ \forall\ p\in M\ :\ p=\sum\limits_i\lambda_ip_i\quad(\sum\lambda_i=1;\,\lambda_i\ge 0\ \forall\ i).$
\\Значит, $\ l(p)=\sum\limits_i\lambda_il(p_i)\le \max\limits_il(p_i).$\qed
\ab Метод решения задачи линейного программирования - ''симплекс-метод'': Возьмём одну вершину, посмотрим, как
изменяется функция по рёбрам, выходящим из этой вершины. Если по всем уменьшается, то это - вершина максимума.
Если где-то увеличивается, то пойдём по этому ребру.

%\input linal7.tex
%\renewcommand{\c}{\mathbb{C}}
%\newcommand{\eps}{\varepsilon}
%\newcommand{\pr}{{\rm pr\,}}%
%\newcommand{\rk}{{\rm rk\,}}%
%\newcommand{\de}{\par\noindent\underline{Def}.\ }%
%\newcommand{\ab}{\par\noindent}%
%\newcommand{\te}{\par\noindent{\bf Теорема.}\ }%
%\newcommand{\dok}{\par\noindent{\bf Доказательство.}\ }%
%\newcommand{\qed}{\quad${{\bf Q.E.D.}}$}
%\renewcommand{\phi}{\varphi}
%\newcommand{\sled}{\par\noindent{\bf Следстсвие.}\ }%
%\newcommand{\baz}[1]{\left(#1_1,\dots,#1_n\right)}%
%\newcommand{\lr}{\Leftrightarrow}%
%\newcommand{\nn}[1]{#1_1,#1_2,\dots,#1_n}%
%\newcommand{\lob}[1]{\left\langle#1\right\rangle}%
%\newcommand{\ps}{\oplus}
%\newcommand{\rom}[1]{{\rm#1\,}}
%\newcommand{\op}[1]{$\mathcal{#1}$}
%\newcommand{\om}[1]{\mathcal{#1}}
%\newcommand{\oi}[1]{\overrightarrow{#1}}%
\section{Аффинные отображения, их свойства. Аффинные\\ преобразования. Существование и единственность\\ аффинного преобразования, переводящего один\\ заданный репер в другой.
Координатный признак\\ равенства фигур в аффинной геометрии.} %
\label{q42}%
\de Пусть $S$ и $S'$ - аффинные пространства, ассоциированные соответственно с векторными пространствами $V$ и $V'$. Отображение
$f:S\rightarrow S'$ называется аффинным, если существует такое линейное отображение $\phi:V\rightarrow V',$ что
$f(p+x)=f(p)+\phi(x)\quad\forall\ p\in S,\, x\in V.$
\ab Свойство: $\phi(\oi{pq})=\oi{f(p)f(q)}\quad\forall p,q\in S.$
\ab Действительно, $f(q)=f(p+\oi{pq})=f(p)+\phi(\oi{pq}).$
\ab Значит, $\phi$ однозначно определяется по $f$. Линейное отображение $\phi$ называется дифференциалом аффинного отображения $f$
и обозначается $df$.
\ab Если выбрать в $S$ и $S'$ начала отсчёта $o$ и $o',$ то получим $f(o+x)=f(o)+\phi(x)=o'+\oi{o'f(o)}+\phi(x).$ Положим $\oi{o'f(o)}=b\in V'.$
Тогда в векторизованной форме отображение $f$ записывается в виде $f(o+x)=f(x)=\phi(x)+b.$ В координатной форме: если $f(x)=y,$ то
$y_i=\sum\limits_ja_{ij}x_j+b_i$ в некоторых базисах $V$ и $V'$. В частности, аффинно-линейные функции - это аффинные отображения
из $S$ в $K$. В случае $K=\mathbb{R}$ понятие дифференциала аффинного отображения согласуется с общим понятием дифференциала
гладкого отображения.
\ab{\bf Свойства аффинного отображения}:
\begin{enumerate}
    \item Если $P\subset S$ - плоскость, то $f(P)\subset S'$ - тоже плоскость, причём если аффинное отображение $f$ биективно, то $\dim f(P)=\dim P.$
    \ab Действительно, $P=p_0+U\ \Rightarrow\ f(P)=f(p_0)+df(U)$ - плоскость в $S'.$\\ Если $f$ биективно, то $df$ тоже биективно
    (выберем согласованные начала отсчёта в $S$ и $S'$, где $f=df$)\ $\Rightarrow$\ $\dim df(U)=\dim U.$
    \item $f\left(\sum\limits_i\lambda_ip_i\right)=\sum\limits_i\lambda_if(p_i),$ где $\sum\lambda_i=1.$
    \ab По определению, $\sum\limits_i\lambda_ip_i=o+\sum\limits_i\lambda_i\oi{op_i}.$ Значит,\\ $f\left(\sum\limits_i\lambda_ip_i\right)=f(o)+
    \sum\limits_i\lambda_idf(\oi{op_i})=f(o)+\sum\limits_i\lambda_i\oi(f(o)f(p_i))=\sum\limits_i\lambda_if(p_i)$\\ по определению
    барицентрических линейных комбинаций в $S'.$
\end{enumerate}
\de Простое отношение трёх точек на прямой в аффинном пространстве. Пусть точки $p,q$ и $r$ лежат на одной прямой.
$q\ne r\ \Rightarrow\ \oi{pr}=c\cdot\oi{rq}.$ Число $c$ называется простым отношением $(p,q;r).$ Если $q=r,$ но $p\ne q,$ то
можно считать $(p,q;r)=\infty.$ Простое отношение сохраняется при аффинном отображении (если данная прямая не переходит в точку):
\ \ $\left(f(p),f(q);f(r)\right)=(p,q;r).$
\de Аффинным преобразованием пространства $S$ называется аффинное отображение $f:S\rightarrow S.$
\ab $f(p+x)=f(p)+\om{A}x,$ где $\om{A}=df$ - линейный оператор в пространстве $V$. В векторизованной форме $f(x)=\om{A}x+b,$ где
$b=\oi{of(o)}.$
\te Пусть $\{p_0,p_1,\dots,p_n\}$ и $\{q_0,q_1,\dots,q_n\}$ - две аффинно независимые системы точек в $n-$мерном аффинном пространстве $S$.
Тогда существует единственное аффинное преобразование $f$, переводящее первую систему точек во вторую:\ \ $f(p_i)=q_i\quad i=0,1,\dots,n.$
\dok Если такое $f$ существует, то $f(p_0+x)=q_0+\phi(x),$ где $\phi$ - такое линейное преобразование, что $\phi(\oi{p_0p_i})=\oi{q_0q_i}\quad
(i=1,\dots,n).$ Так как векторы $\oi{p_0p_1},\dots,\oi{p_0p_n}$ образуют базис пространства $V$, то существует единственное
линейное преобразование $\phi$, для которого $$\phi(\oi{p_0p_i})=\oi{q_0q_i}\quad(i=1,\dots,n).$$Значит, $f$ единственно.
\ab Обратно, если определить аффинное преобразование $f$ по формуле $f(p_0+x)=q_0+\phi(x),$ где $\phi$ определено выше, то
$f(p_i)=q_i\quad(i=0,1,\dots,n).$\qed
\ab Группа аффинных преобразований пространства $S$ определяет аффинную геометрию. Две фигуры (то есть подмножества $S$)
$F_1$ и $F_2$ называются равными (или конгруэнтными), если существует такое аффинное преобразование $g$, что $gF_1=F_2.$
\ab{\bf Координатный признак равенства фигур в аффинной геометрии}.
\te Фигуры $F$ и $F'$ равны в аффинной геометрии $\ \lr\ $ существуют такие реперы $(o;\,e_1,\dots,e_n)$ и
$$(o';\,e'_1,\dots,e'_n),$$ что
$$o+\sum\limits_ix_ie_i\in F\ \lr\ o'+\sum\limits_ix_ie_i'\in F',$$
то есть $F$ и $F'$ одинаково выглядят по отношению к этим реперам.
\dok Пусть $F'=f(F),\ f\in {\rm GA}(S).$ Пусть $(o;\,e_1,\dots,e_n)$ - любой репер и рассмотрим репер
$$\left(f(o);df(e_1),\dots,df(e_n)\right).$$
Тогда $p=o+\sum\limits_ix_ie_i\in F\ \lr\ f(p)=f(o)+\sum\limits_ix_idf(e_i)\in F'.$
\ab Обратно, пусть $(o;\,e_1,\dots,e_n)$ и $(o';\,e'_1,\dots,e'_n)$ - реперы, удовлетворяющие условиям теоремы. Рассмотрим $f\in{\rm GA}(S),$
определяемое условиями:
$$
f(o)=o';\qquad df(e_i)=e_i'\quad i=1,\dots,n.
$$
Докажем, что $f(F)=F'.$ Действительно, $p=o+\sum\limits_ix_ie_i\in F\ \lr\ f(p)=o'+\sum\limits_ix_ie_i'\in F'.$\qed


\section{Дифференциал как гомоморфизм аффинной группы\\ в линейную. Параллельные переносы и гомотетии.}
\label{q43}
\te Пусть $f:S\rightarrow S'$ и $g:S'\rightarrow S''$ - аффинные отображения. Тогда отображение $gf:S\rightarrow S''$ также аффинно,
причём $d(gf)=dg\cdot df.$
\dok Действительно,\\ $gf(p+x)=g\left(f(p+x)\right)=g\left(f(p)+df(x)\right)=g\left(f(p)\right)+dg\left(df(x)\right)=(gf)(p)+(dg\cdot df)(x).$\qed
\te Аффинное отображение $f:S\rightarrow S'$ биективно $\ \lr\ $ $df$ биективно.\\ При этом $f^{-1}$ также аффинно, и $d\left(f^{-1}\right)=\left(df\right)^{-1}.$
\dok Выберем согласованные начала отсчёта в $S$ и $S'$ таким образом, чтобы $o'=f(o).$ Тогда в векторизованной форме $f=df.$\qed
\ab Биективные аффинные преобразования образуют группу ${\rm GA}(S),$ а невырожденные линейные преобразования - группу ${\rm GL}(V).$
Дифференциал есть гомоморфизм групп\ \ $d:{\rm GA}(S)\rightarrow{\rm GL}(V).$
\de Параллельным переносом на вектор $a\in V$ называется аффинное преобразование $t_a:p\mapsto p+a.$
Параллельные переносы образуют подгруппу, так как $t_at_b=t_{a+b};\ (t_a)^{-1}=t_{-a};\ id=t_0.$
Эта подгруппа изоморфна группе $V$.
\te Аффинное преобразование $f$ является параллельным переносом $\ \lr\ $ $df=\om{E}.$
\dok $t_a(p+x)=p+x+a=t_ap+x=t_ap+\om{E}x\ \Rightarrow\ dt_a=\om{E}.$
\ab Обратно, если $df=\om{E},$ то $f(o+x)=f(o)+x=o+\oi{of(o)}+x=o+x+a,$ где $a=\oi{of(o)}.$\qed
\te Группа параллельных переносов является нормальной подгруппой в ${\rm GA}(S).$
\dok Подгруппа $H\subset G$ нормальна $\ \lr\ $ $\forall\ g\in G\ gHg^{-1}=H.$ Докажем, что\\ $\forall\ f\in{\rm GA}(S)\ \
ft_af^{-1}=t_{df(a)}.$ Действительно, $(ft_af^{-1})(p)=f(f^{-1}(p)+a)=p+df(a).$\qed
\de Гомотетией с центром $o\in S$ и коэффициентом $\lambda\in K^*$ называется аффинное преобразование, определяемое по следующему правилу:
$$
f(o+x)=o+\lambda x.
$$
Гомотетия с коэффициентом $-1$ называется центральной симметрией относительно точки $o$.
\te Аффинное преобразование $f$ является нетождественной гомотетией $\ \lr\ $ $df=\lambda\om{E},\ \lambda\ne 0,1.$
\dok Дифференциал гомотетии с коэффициентом $\lambda$ равен $\lambda\om{E}.$
\ab Обратно, пусть $df=\lambda\om{E}.$ Достаточно доказать, что $f$ имеет неподвижную точку.\\ В векторизованной форме:
$f(x)=\lambda x+b.$ Уравнение $\lambda x+b=x$ имеет единственное решение при $\lambda \ne 0,1.$
Это и будет центр гомотетии.\qed
\section{Квадрики в аффинном пространстве.\\ Центральные, конические и цилиндрические квадрики.}
\label{q44}
Будем далее считать, что $\rom{char}K\ne 2.$
\de Аффинно-квадратичной функцией в пространстве $S$ называется функция, которая в векторизованной форме записывается
в виде $Q(x)=q(x)+l(x)+c,$ где $q$ - квадратичная функция, $l$ - линейная функция, $c\in K.$
\ab В координатах: $Q(p)=\sum\limits_{i,j}a_{ij}x_ix_j+\sum\limits_ib_i+c,$ где $a_{ij}=a_{ji},$ а $(x_1,\dots,x_n)$ -
координаты точки $p$.\\ Очевидно, что $c=Q(o),\ b_i=\frac{\displaystyle \partial Q}{\displaystyle \partial x_i}(o),$ где $o$ -
начало координат.
\de Квадрикой (или гиперповерхностью второго порядка) в пространстве $S$ называется множество, задаваемое уравнением $Q(p)=0,$
где $Q$ - аффинно-квадратичная функция; при условии, что оно непусто и не является плоскостью
(в частности, $q\ne 0$).
\ab Введём обозначение: $X(Q)$ - множество точек, удовлетворяющее уравнению $Q(p)=0.$
\de Точка $o$ называется центром квадрики $X$, если $o+x\in X\ \Rightarrow\ o-x\in X,$ то есть $s_oX=X.$
\de Вершиной квадрики называется принадлежащий ей центр.
\te Если $X(Q_1)$ и $X(Q_2)$ - совпадающие квадрики, то уравнения $Q_1$ и $Q_2$ пропорциональны.
\dok Возьмём в качестве точки $o$ какую-нибудь точку квадрики $X$, не являющуюся её вершиной (такие точки есть, иначе
квадрика была бы плоскостью). Тогда в
векторизованной форме: $Q_1(x)=q_1(x)+l_1(x),$\ \  $Q_2(x)=q_2(x)+l_2(x),$ где $l_1,l_2\ne 0.$ Точки пересечения прямой $o+\lob{x}$
с квадрикой $X$ определяются любым из уравнений $t^2q_1(x)+tl_1(x)=0$ или $t^2q_2(x)+tl_2(x)=0.$ Так как относительно $t$
эти уравнения должны иметь одинаковые решения, то при $l_1(x),\,l_2(x)\ne 0$ получаем, что
$$
\frac{q_1(x)}{l_1(x)}=\frac{q_2(x)}{l_2(x)}.
$$
Поэтому $q_1(x)l_2(x)=q_2(x)l_1(x).$ Умножая на $l_1(x)l_2(x),$ получаем, что $$q_1(x)l_2(x)l_1(x)l_2(x)=q_2(x)l_1(x)l_1(x)l_2(x)$$
верно уже для всех $x$.
Но так как в кольце многочленов нет делителей нуля, то можно сократить последнее равенство, поэтому можно считать, что
$q_1(x)l_2(x)=q_2(x)l_1(x)$ верно тоже для всех $x$. Пусть $l_1$ и $l_2$ не пропорциональны. Тогда в подходящем базисе
$l_1(x)=x_1,\ l_2(x)=x_2.$ Поэтому $q_1(x)x_2=q_2(x)x_1.$ Рассматривая левые и правые части, видим, что должно быть:
$$q_1(x)=l(x)x_1,\ q_2(x)=l(x)x_2$$ для некоторой линейной функции $l(x).$ Значит, $Q_1(x)=(l(x)+1)x_1,\ Q_2(x)=(l(x)+1)x_2.$
Так как $X=X(Q_1),$ то $X$ содержит гиперплоскость $x_1=0.$ Значит, $Q_2$ должна обращаться в ноль всюду на этой
гиперплоскости. Но ни один из множителей $x_2$ и $l(x)+1$ не обращается на ней в ноль. Так как в кольце многочленов нет
делителей нуля, то получаем противоречие. Поэтому линейные, а значит, и квадратичные части аффинно-квадратичных функций
пропорциональны.\qed
\de Квадрика называется центральной, если у неё есть хотя бы один центр.
\te Множество всех центров квадрики $X(Q)$ задаётся системой линейных уравнений
$$
\frac{\displaystyle\partial Q}{\displaystyle\partial x_i}=0;\qquad i=1,\dots,n.
$$
\dok Примем $o$ - центр квадрики - за начало координат. Тогда в векторизованной форме $Q(x)=q(x)+l(x)+c.$ Квадрика
$s_oX(Q)$ задаётся уравнением $Q(-x)=0,$ то есть $q(x)-l(x)+c=0$. Эти квадрики совпадают, значит, $Q(-x)=\lambda Q(x)$ для
некоторого $\lambda\in K^*.$ Сравнивая квадратичные части, видим, что $\lambda=1.$\\ Поэтому $s_oX=X\ \lr\ l(x)\equiv 0,$ то есть
$\frac{\displaystyle\partial Q}{\displaystyle\partial x_i}=0;\qquad i=1,\dots,n.$\qed
\sled Множество всех центров либо пусто, либо является плоскостью.
\sled Если $q$ невырожденна, то квадрика центральна, причём центр единствен.
\dok $Q(p)=\sum\limits_{i,j}a_{ij}x_ix_j+\sum\limits_ib_ix_i+c.$\ab $\frac{\displaystyle\partial Q}{\displaystyle\partial x_i}(p)=
2\sum\limits_ja_{ij}x_j+b_i.$ Таким образом, множество всех центров задаётся системой линейных уравнений, матрица
которой есть матрица квадратичной функции $q$. По теореме Крамера, центр существует и единствен.\qed
\te Точка $o$ является вершиной квадрики $X$ тогда и только тогда, когда $$o+x\in X\ \Rightarrow\ o+\lambda x\in X\ \ \forall\ \lambda\in K,$$
то есть квадрика инвариантна относительно всех гомотетий с центром в точке $o$.
\dok Пусть в векторизованной форме $X=X(Q).$ Запишем уравнение квадрики, приняв за начало отсчёта точку $o$:
$q(x)+c=0.$ Если $o$ - вершина, то $c=0.$
\ab Обратно, пусть $X$ инвариантна. Пусть $h_\lambda$ - гомотетия с центром $o$ и коэффициентом $\lambda.$\\ Если
$h_\lambda X=X,$ то уравнение квадрики $h_\lambda X$ имеет вид $\lambda^{-2}q(x)+c=0,$ так как $h_\lambda :x\mapsto \frac{\displaystyle x}{\displaystyle \lambda}$.
\\Это уравнение должно быть пропорционально уравнению квадрики $X$. Значит, $c=0.$\qquad\qed
\de Множество, которое вместе с каждой точкой $o+x$ содержит и точку $o+\lambda x\ \ \forall\ \lambda\in K,$ то есть
инвариантное относительно всех гомотетий с центром в точке $o$, называется конусом с вершиной в точке $o$. Квадрика,
являющаяся конусом (то есть имеющая вершину), называется конической.
\de Квадрика $X$ называется цилиндрической, если $\ \exists\ a\in V,\ a\ne 0,$ такой что $t_aX=X$,\\ значит,
$\ \forall\ \lambda\in K\ \ t_{\lambda a}X=X,\ \lambda\ne 0.$
\ab Пусть $\alpha$ - симметрическая билинейная функция, соответствующая квадратичной функции $q$.
\te Множество всех таких векторов $a$, что $t_aX=X,$ является подпространством $\rom{Ker}\alpha\cap\rom{Ker}l.$
\dok Пусть $Q(x)=q(x)+l(x)+c=0$ - уравнение квадрики $X$. Уравнение квадрики $t_aX$ имеет вид
$$Q(x-a)=\alpha(x-a,x-a)+l(x-a)+c=q(x)-2\alpha(x,a)+q(a)+l(x)+c-l(a)=0.$$ $t_aX=X\ \lr\ $ эти уравнения пропорциональны.
Сравнивая квадратичные части, видим, что коэффициент пропорциональности равен единице. Значит, $\alpha(x,a)=0\ \forall\
x\in V,$ и $l(a)=0$, так как $q(a)=\alpha(a,a)=0.$ Таким образом, $a\in \rom{Ker}\alpha\cap\rom{Ker}l.$\qed
\section{Аффинная классификация невырожденных\\ вещественных квадрик.}
\label{q45}
Выберем базис пространства $V$, согласованный с $U=\rom{Ker}\alpha\cap\rom{Ker}l.$ Пусть $U=\lob{e_{m+1},\dots,e_n}.$ Тогда
уравнение квадрики не будет содержать членов с\ \ $x_{m+1},\dots,x_n.$
\de Квадрики, не являющиеся цилиндрическими, называются невырожденными. Достаточно изучать только их, потому что
вырожденные квадрики сводятся к невырожденным меньших размерностей.
\ab
\centerline{\bf Типы невырожденных квадрик.}
\begin{enumerate}
    \item Неконические центральные квадрики.\ab Приняв центр за начало координат, приведём уравнение квадрики к виду
    $
    q(x_1,\dots,x_n)=1
    $, где $q$ - невырожденная квадратичная функция.
    \item Конические квадрики.\ab Приняв центр за начало координат, приведём уравнение квадрики к виду
    $
    q(x_1,\dots,x_n)=0
    $, где $q$ - невырожденная квадратичная функция.
    \item Нецентральные квадрики.\ab
    $\rom{Ker}q\ne 0,$ $\rom{Ker}\alpha\cap\rom{Ker}l=0.$ Значит, $\dim\rom{Ker}l=n-1,\ \dim\rom{Ker}q=1,$ и $V=\rom{Ker}l\ps\rom{Ker}q.$\\
    Выберем базис в $V$ так, чтобы $\rom{Ker}l=\lob{e_1,\dots,e_{n-1}},\ \rom{Ker}q=\lob{e_n}.$ Начало отсчёта выберем
    на квадрике. Тогда уравнение квадрики приводится к виду $q_1(x_1,\dots,x_{n-1})=x_n,$ где $q$ - невырожденная квадратичная
    функция в $\lob{e_1,\dots,e_{n-1}}.$
\end{enumerate}
Рассмотрим случай $K=\mathbb{R}.$
\ab За счёт выбора базиса в пространстве $V$ уравнение невырожденной квадрики приводится в одному из следующих видов:
\begin{enumerate}
    \item $x_1^2+\dots+x_k^2-x_{k+1}^2-\dots-x_n^2=1\quad(0<k\le n);$
    \item $x_1^2+\dots+x_k^2-x_{k+1}^2-\dots-x_n^2=0\quad\left(\left[\frac{\displaystyle n}{\displaystyle 2}\right]\le k<n\right);$
    \item $x_1^2+\dots+x_k^2-x_{k+1}^2-\dots-x_{n-1}^2=x_n\quad\left(\left[\frac{\displaystyle n-1}{\displaystyle 2}\right]\le k<n\right).$
\end{enumerate}
В случае $n=2$:\ab
\begin{tabular}{ccc}
  & & \\
  1 & $x_1^2+x_2^2=1$ & эллипс; \\

    & $x_1^2-x_2^2=1$ & гипербола; \\
  2 & $x_1^2-x_2^2=0$ & пара пересекающихся прямых; \\
  3 & $x_1^2=x_2$ & парабола. \\
   & & \\
\end{tabular}
\ab
В случае $n=3$:\ab
\begin{tabular}{ccc}

& & \\
  1 & $x_1^2+x_2^2+x_3^2=1$ & эллипсоид; \\

   & $x_1^2+x_2^2-x_3^2=1$ & однополостный гиперболоид; \\
   & $x_1^2-x_2^2-x_3^2=1$ & двуполостный гиперболоид; \\
  2 & $x_1^2+x_2^2-x_3^2=0$ & квадратичный конус;\\
  3 & $x_1^2+x_2^2=x_3$ & эллиптический параболоид; \\
   & $x_1^2-x_2^2=x_3$ & гиперболический параболоид. \\
& & \\
\end{tabular}
\ab
В силу координатного признака равенства фигур в аффинной геометрии, чтобы узнать, аффинно эквивалентны ли квадрики,
над $\mathbb{R}$ надо уравнения обеих квадрик привести к каноническому виду. Если уравнения совпадут, то и квадрики совпадут.

%\input linal8.tex
%\renewcommand{\c}{\mathbb{C}}
%\newcommand{\eps}{\varepsilon}
%\newcommand{\pr}{{\rm pr\,}}%
%\newcommand{\rk}{{\rm rk\,}}%
%\newcommand{\de}{\par\noindent\underline{Def}.\ }%
%\newcommand{\ab}{\par\noindent}%
%\newcommand{\te}{\par\noindent{\bf Теорема.}\ }%
%\newcommand{\dok}{\par\noindent{\bf Доказательство.}\ }%
%\newcommand{\qed}{\quad${{\bf Q.E.D.}}$}
%\renewcommand{\phi}{\varphi}
%\newcommand{\sled}{\par\noindent{\bf Следстсвие.}\ }%
%\newcommand{\baz}[1]{\left(#1_1,\dots,#1_n\right)}%
%\newcommand{\lr}{\Leftrightarrow}%
%\newcommand{\nn}[1]{#1_1,#1_2,\dots,#1_n}%
%\newcommand{\lob}[1]{\left\langle#1\right\rangle}%
%\newcommand{\ps}{\oplus}
%\newcommand{\rom}[1]{{\rm#1\,}}
%\newcommand{\op}[1]{$\mathcal{#1}$}
%\newcommand{\om}[1]{\mathcal{#1}}
%\newcommand{\oi}[1]{\overrightarrow{#1}}%
\section{Евклидовы аффинные пространства.\\ Расстояние между точками и между плоскостями.}
\label{q46} \de Евклидовым аффинным пространством называется вещественное аффинное пространство, ассоциированное с
евклидовым векторным пространством.
\de Расстояние между точками определяется по следующей формуле: $\rho(p,q)\doteqdot \left|\oi{pq}\right|.$
\ab Свойства:
\begin{enumerate}
    \item $\rho(p,q)>0$\ \ при $p\ne q,$\  \ $\rho(p,p)=0;$
    \item $\rho(p,q)+\rho(q,r)\ge \rho(p,r).$
    \ab Действительно, $|\oi{pq}+\oi{qr}|\le |\oi{pr}|,$\ \ что вытекает из неравенства Коши-Буняковского.
\end{enumerate}
Таким образом, евклидово аффинное пространство является метрическим.
\de Расстояние между подмножествами $P$ и $Q$ определяется следующим образом: $$\rho(P,Q)=\inf_{p\in P,\ q\in Q}\rho(p,q).$$
\te Для двух плоскостей $P_1$ и $P_2$ существует общий перпендикуляр, если $U_1\cap U_2=0,$ то он единствен. Его
длина равна $\rho(P_1,P_2)$\ \ (если плоскости пересекаются, то под общим перпендикуляром понимается точка).
\dok Отрезок $[p_1+u_1,p_2+u_2]$ есть общий перпендикуляр $\ \lr\ $ он ортогонален $U_1+U_2.$ Но этот отрезок равен\ \
$\oi{p_1p_2}-u_1+u_2$, то есть он является общим перпендикуляром $\ \lr\ $ $\oi{p_1p_2}=u_1-u_2+v,$ где $u_1-u_2\in U_1+U_2,$ а
значит, $v\in (U_1+U_2)^\bot.$
\ab Далее, $\rho(P_1,P_2)=\inf\limits_{u_1\in U_1,\ u_2\in U_2}\rho(p_1+u_1,p_2+u_2)=\inf \left|\oi{p_1p_2}-u_1+u_2\right|=
\rho(\oi{p_1p_2},U_1+U_2)=\\=|\rom{ort}_{U_1+U_2}\oi{p_1p_2}|=|v|$ - длина общего перпендикуляра.
\section{Движения. Дифференциал как гомоморфизм\\ группы движений в ортогональную группу.\\ Собственные и несобственные движения.}
\label{q47}
\de Движением аффинного пространства $S$ называется аффинное преобразование, дифференциал которого есть ортогональное преобразование.
\ab Так как $d(fg)=df\cdot dg,$ и так как ортогональные преобразования образуют группу ${\rm O}(V),$ то и движения образуют
группу ${\rm Isom}(S).$ Геометрия этой группы называется евклидовой геометрией.
\ab В векторизованной форме движения записываются так: $f(x)=\om{A}x+b,$ где $\om{A}=df\in{\rm O}(V),$ а вектор $b$
зависит от начала отсчёта.
\ab Значит, дифференциал осуществляет гомоморфизм $d:{\rm Isom}(S)\rightarrow{\rm O}(V).$\\ Отображение $\det d:{\rm Isom}(S)\rightarrow\{\pm 1\}$
\ - тоже гомоморфизм.
\de Движение $f$, для которого $\det df=1$, называется собственным, для которого $-1$ - несобственным.
Собственные движения образуют подгруппу ${\rm Isom}_+(S),$ несобственные - смежный класс по этой подгруппе.
Значит, $[{\rm Isom}(S);\ {\rm Isom}_+(S)]=2.$
\ab Классификация движений прямой:
\begin{enumerate}
    \item Если движение $f$ собственное, то $df=\om{E},$ и $f$ - параллельный перенос.
    \item Если $f$ - несобственное, то $df=\om{-E}.$ В векторизованной форме $f(x)=-x+b,$ значит,
    $b/2$ - неподвижная точка, то есть $f$ - центральная симметрия относительно этой неподвижной точки.
\end{enumerate}
\section{Ось движения. Геометрическое описание\\ движений плоскости и трёхмерного пространства.}
\label{q48}
\te Для любого движения $f$ существует однозначно определённая плоскость $P=p_0+U$ со следующими свойствами:
\begin{enumerate}
    \item $f(P)=P;$
    \item $f\,\vrule\,_P$ - параллельный перенос;
    \item $df$ не имеет неподвижных векторов в $U^\bot.$
\end{enumerate}
\dok Если искомая плоскость $P$ существует, то её направляющее пространство должно совпадать с пространством
неподвижных векторов оператора $\om{A}=df.$ Обозначим это подпространство за $U$. В векторизованной форме $f(x)=\om{A}x+b.$
Пусть $b=b_0+b_1;\ b_0\in U,\ b_1\in U^\bot.$ Так как оператор $\om{A-E}$ невырожден на $U^\bot,$ то существует единственный
вектор $x_0\in U,$ такой, что $\om{A}x_0+b_1=x_0.$ Пусть $p_0$ - соответствующая ему точка. Тогда $f(p_0)=p_0+b_0.$ Плоскость
$P=p_0+U$ и является той единственной плоскостью, удовлетворяющей условиям теоремы.\qed
\de Плоскость из теоремы называется осью движения.
\ab Из канонического вида матрицы ортогонального преобразования следует:\\ $\dim U^\bot$ чётно, если $f$ - собственное
движение, и нечётно в противном случае.
\ab\\ Геометрическое описание движений плоскости:
\begin{enumerate}
    \item $f$ - собственное $\ \Rightarrow\ $ $df$ - поворот на угол $\alpha.$ В векторизованной форме $f(x)=\om{A}x+b,$ где
    матрица $\om{A}$ есть $\Pi(\alpha).$
    \begin{enumerate}
        \item Если $\alpha=0,$ то $f$ - параллельный перенос.
        \item Если $0\le \alpha\le 2\pi$,\ \ то $\om{A}$ не имеет неподвижных векторов, значит, уравнение $\om{A}x+b=x$
    имеет единственное решение (поскольку оно равносильно уравнению $(\om{A-E})x=-b,$ и $\det(\om{A-E})\ne 0$). Если это
    решение взять за начало координат, то $f(x)=\om{A}x$, то есть $f$ - поворот.
    \end{enumerate}
    \item Если $f$ - несобственное, то $df$ - отражение относительно некоторого одномерного подпространства $l$. В векторизованной форме
    $f(x)=\om{A}x+b,$ и разложим: $b=b_0+b_1,\ b_0\in l,\ b_1\perp l.$ Рассмотрим прямую $\frac{b_1}{2}+l.$ Она инвариантна относительно $f$:
    \ \ действительно, \\
    $f(\frac{b_1}2+u)=\om{A}(\frac{b_1}2+u)+b=-\frac{b_1}2+u+b=(\frac{b_1}2+u)+b_0.$
    \ab Если $o'=o+\frac{b_1}2$ - начало отсчёта, то $f(x)=\om{A}x.$ Значит, $f$ - либо отражение, либо скользящая симметрия.
\end{enumerate}
\ab Геометрическое описание движений пространства:
\ab Пусть $P=p_0+U$ - ось движения $f$.
\begin{enumerate}
    \item Если $\dim P=3,$ то $f$ - параллельный перенос;
    \item Если $\dim P=2,$ то ортогональное дополнение одномерно, значит, $df\,\vrule\,_{U^\bot}=\om{-E}.$ Поэтому
    $f$ есть либо отражение относительно $P$, либо скользящее отражение относительно $P$;
    \item Если $\dim P=1,$ то $df\,\vrule\,_{U^\bot}$ - либо поворот относительно $P$, либо винтовое движение;
    \item Если $\dim P=0,$ то, взяв эту точку за начало отсчёта, имеем, что $f$ - ортогональное преобразование,
    не имеющее неподвижных векторов, то есть зеркальный поворот (поворот плюс отражение).
\end{enumerate}
\section{Прямоугольные системы координат в евклидовом\\ аффинном пространстве. Свойство максимальной\\ подвижности
и координатный признак равенства\\ фигур в евклидовой геометрии.}
\label{q49}
\de Репер $(o;\,e_1,\dots,e_n)$ называется ортонормированным, если базис $\baz{e}$ ортонормированный. Система координат,
связанная с таким репером, называется прямоугольной.
\te Для любых двух ортонормированных реперов существует единственное движение $f$, переводящее первый репер
во второй, то есть $f(o)=o';\ df(e_i)=e_i'\ \ \ (i=1,\dots,n).$
\dok Существует единственное аффинное преобразование, переводящее первый репер во второй, но поскольку
$df$ переводит ортонормированный базис векторного пространства в ортонормированный, то $df$ ортогонально,
значит, $f$ - движение.\qed
\ab{\bf Координатный признак равенства фигур}:
\te Фигуры $F$ и $F'$ равны $\ \lr\ $ существуют такие ортонормированные реперы
$$(o;\,e_1,\dots,e_n)\text{ и }(o';\,e'_1,\dots,e'_n),$$
что $o+\sum\limits_ix_ie_i\in F\ \lr\ o'+\sum\limits_ix_i'e_i'\in F'.$
\dok\begin{enumerate}
    \item Существует $f\in {\rm GA}(S),$ переводящее первый репер во второй, причём $f$ - движение, и\\ $f(F)=F'.$ Значит,
    фигуры $F$ и $F'$ равны.
    \item Пусть $f$ - движение, переводящее первый репер во второй. Возьмём любой ортонормированный репер
    $(o;\,e_1,\dots,e_n)$ и рассмотрим репер $\left(f(o);\,f(e_1),\dots,f(e_n)\right).$\\ Тогда
    $o+\sum\limits_ix_ie_i\in F\ \lr\ f(o)+\sum\limits_ix_idf(e_i)\in F'$.\qed
\end{enumerate}
%\input linal9.tex
%\renewcommand{\c}{\mathbb{C}}
%\newcommand{\eps}{\varepsilon}
%\newcommand{\pr}{{\rm pr\,}}%
%\newcommand{\rk}{{\rm rk\,}}%
%\newcommand{\de}{\par\noindent\underline{Def}.\ }%
%\newcommand{\ab}{\par\noindent}%
%\newcommand{\te}{\par\noindent{\bf Теорема.}\ }%
%\newcommand{\dok}{\par\noindent{\bf Доказательство.}\ }%
%\newcommand{\qed}{\quad${{\bf Q.E.D.}}$}
%\renewcommand{\phi}{\varphi}
%\newcommand{\sled}{\par\noindent{\bf Следстсвие.}\ }%
%\newcommand{\baz}[1]{\left(#1_1,\dots,#1_n\right)}%
%\newcommand{\lr}{\Leftrightarrow}%
%\newcommand{\nn}[1]{#1_1,#1_2,\dots,#1_n}%
%\newcommand{\lob}[1]{\left\langle#1\right\rangle}%
%\newcommand{\ps}{\oplus}
%\newcommand{\rom}[1]{{\rm#1\,}}
%\newcommand{\op}[1]{$\mathcal{#1}$}
%\newcommand{\om}[1]{\mathcal{#1}}
%\newcommand{\oi}[1]{\overrightarrow{#1}}%
%\newcommand{\we}[1]{\widehat{#1}}
%\renewcommand{\le}{\leqslant}
%\renewcommand{\ge}{\geqslant}

%\begin{document}
\section{Приведение уравнения невырожденной квадрики\\ в евклидовом пространстве к каноническому виду\\ (без
доказательства единственности\\ в случае параболоида).}
\label{q50}
Найдём канонический вид уравнения невырожденной квадрики в прямоугольной системе координат:
\begin{enumerate}
    \item Неконическая центральная квадрика.
    \ab Выберем начало координат в центре квадрики. Свободный член сделаем равным $-1$.\\
    Получим $\lambda_1x_1^2+\dots+\lambda_nx_n^2=1,$ где $\lambda_1,\dots,\lambda_n$ определены однозначно с
    точностью до перестановки и $\lambda_i\ne 0\ \ \forall\ i=1,\dots,n.$
    \item Конические квадрики.
    \ab $\lambda_1x_1^2+\dots+\lambda_nx_n^2=0,$ и $\lambda_1,\dots,\lambda_n$ определены однозначно с
    точностью до перестановки и умножения на одно и то же число.
    \item Нецентральные квадрики (параболоиды).
    \ab Квадратичная функция приводится к виду $\lambda_1x_1^2+\dots+\lambda_nx_(n-1)^2+b_1x_1+\dots+b_nx_n+c=0.$
    \\С помощью переноса начала координат можно получить $\lambda_1x_1^2+\dots+\lambda_nx_(n-1)^2+b_nx_n+c=0$, причём
    $b_n\ne 0,$ иначе квадрика вырождена. Сдвигая по $x_n,$ уберём свободный член и сделаем $b_n=-1.$ Получим уравнение
    вида $\lambda_1x_1^2+\dots+\lambda_nx_(n-1)^2=x_n.$\\ На самом деле, числа $\lambda_1,\dots,\lambda_{n-1}$ определены
    однозначно с точностью до перестановки и умножения на $-1$ --- без доказательства.
\end{enumerate}
\section{Проективные пространства, их аффинные карты.\\ Однородные и неоднородные координаты.}
\label{q51}
\de Проективным пространством, ассоциированным с векторным пространством $V$, называется множество $PV$ одномерных
подпространств пространства $V$. Множество $PU$ одномерных подпространств, содержащихся в $(k+1)-$мерном подпространстве
$U$, называется $k-$мерной плоскостью проективного пространства $PV.$
\ab Ясно, что нульмерные плоскости --- это точки, одномерные --- прямые, $(n-1)-$мерные --- гиперплоскости.
Если $\dim V=n+1,$ то положим $\dim PV\doteqdot n.$ Обозначим: если $0\ne x\in V$, то через $\we{x}$ обозначим $\lob{x}\in PV.$
\ab Рассмотрим $V$, точку $0$ и гиперплоскость $S$, не проходящую через 0. Пусть $V_S$ - направляющее подпространство
плоскости $S$. Любое одномерное подпространство, не лежащее в $V_S$, пересекает $S$ и $V_S$. Положим $\phi_S: PV\backslash PV_S\rightarrow S,$
тогда $\phi_S$ - биекция.
\de Гиперплоскость $S$ вместе с отображением $\phi_S$ называется аффинной картой пространства $PV.$
\de Точки гиперплоскости $PV_S$ называются бесконечно удалёнными по отношению к аффинной карте $S$.
\ab $k-$мерная плоскость пространства $PV$, не лежащая в бесконечно удалённой гиперплоскости, изображается на
карте $k-$мерной плоскостью. Точнее, изображается не вся $k-$мерная плоскость, а её $k-$мерная часть.
\ab\\ Пусть $(e_0,e_1,\dots,e_n)$ - базис пространства $V$.
\de Однородными координатами точки $\we{x}$ называются координаты вектора $x$. Они определены с точностью до одновременного
умножения на любое число из $K^*.$ Обозначение: $\we{x}\doteqdot (x_0:x_1:\dots:x_n),$
причём не все $x_i$ нули. \ab Неоднородные координаты точки $\we{x}\in PV$ - это аффинные координаты её изображения на
аффинной карте. Установим связь между однородными и неоднородными координатами.\\Пусть $S=e_0+\lob{\nn{e}}.$ Тогда
$\we{x}=(x_0:x_1:\dots:x_n),$ и $x_0\ne 0.$ $$x=x_0e_0+\dots+x_ne_n=x_0\left(e_0+\frac{\displaystyle x_1}{\displaystyle x_0}e_1+\dots+\frac{\displaystyle x_n}{\displaystyle x_0}e_n\right)$$
- та же точка. Вектор $e_0+\frac{\displaystyle x_1}{\displaystyle x_0}e_1+\dots+\frac{\displaystyle x_n}{\displaystyle x_0}e_n$
имеет координаты $\frac{\displaystyle x_0}{\displaystyle x_0},\dots,\frac{\displaystyle x_n}{\displaystyle x_0}$ относительно
репера $(e_0;\ e_1,\dots,e_n).$ Таким образом, неоднородными координатами точки $\we{x}$ служат отношения $\frac{\displaystyle x_0}{\displaystyle x_0},\dots,\frac{\displaystyle x_n}{\displaystyle x_0}.$
\de Аффинным атласом называется система аффинных карт $$S_i=e_i+\lob{e_1,\dots,e_{i-1},e_{i+1},\dots,e_n};\qquad i=0,1,\dots,n.$$
Аффинный атлас полностью покрывает пространство $PV.$
\section{Плоскости в проективном пространстве,\\ их взаимное расположение.}
\label{q52}
\te Через любые $k+1$ точку $p_0,p_1,\dots,p_k\in PV$ проходит плоскость размерности $\le k.$ Если эти точки не содержатся
в плоскости размерности меньше, чем $k$, то проходящая через них $k-$мерная плоскость единственна.
\dok На языке векторного пространства $V$ утверждение теоремы означает следующее: любые $k+1$ векторов $x_0,x_1,\dots,x_k\in V$
содержатся в подпространстве размерности не выше $k+1$, а если они не содержатся в подпространстве размерности меньше $k+1,$
то они содержатся в единственном $(k+1)-$мерном подпространстве. Это очевидно.\qed
\te Пусть $\pi_1,\pi_2$ - такие плоскости пространства $PV,$ что $\dim\pi_1+\dim\pi_2\ge n.$ Тогда $\pi_1\cap\pi_2$ непусто,
причём $\dim(\pi_1\cap\pi_2)\ge \dim\pi_1+\dim\pi_2-n.$
\dok Пусть $\pi_1=PU_1,\ \pi_2=PU_2.$ Тогда по условию, $\dim U_1+\dim U_2\ge n+2>n+1=\dim V.$ Значит, $U_1\cap U_2\ne 0,$ то
есть $\pi_1\cap\pi_2$ непусто. Более точно, $\dim(U_1\cap U_2)\ge \dim U_1+\dim U_2-(n+1),$ поэтому $\dim(\pi_1\cap\pi_2)\ge \dim\pi_1+\dim\pi_2-n.$\qed
\section{Проективные преобразования. Существование и единственность проективного преобразования $n$-мерного проективного
пространства, переводящего одну заданную систему $n+2$ точек общего положения в другую.}
\label{q53}
Пусть $\om{A}$ - невырожденный линейный оператор в пространстве $V$. Тогда $\om{A}$ переводит каждое
одномерное подпространство в одномерное подпространство. Тем самым, \op{A} определяет некоторое преобразование \op{\we{A}}
пространства $PV$. Оно называется проективным преобразованием.
\ab Свойства: $\om{\we{AB}}=\om{\we{A}\cdot\we{B}};\ \om{\we{E}}=id;\ \we{\om{{A}}^{-1}}=\left(\om{\we{A}}\right)^{-1}$.
\ab Значит, проективные преобразования образуют группу. Она называется проективной группой и обозначается ${\rm PGL}(V).$
Отображение $\om{A}\mapsto \om{\we{A}}$ является гомоморфизмом групп. Но это необязательно изоморфизм.
\ab{\bf Лемма}. $\om{\we{A}}=id\ \lr\ \om{A=\lambda E}.$
\dok Ясно, что $\om{\we{\lambda E}}=id.$ Обратно, пусть $\om{\we{A}}=id.$ Тогда все ненулевые векторы являются собственными
векторами оператора $\om{A}$. Но так как сумма собственных векторов с различными собственными значениями не является собственным
вектором, то все собственные значения оператора $\om{A}$ одинаковы.\qed
\sled $\om{\we{A}}=\om{\we{B}}\ \lr\ \om{{B}=\lambda{A}}.$
\dok $\om{\we{A}}=\om{\we{B}}\ \lr\ \we{\om{{A}}^{-1}\om{B}}=id\ \lr\ \om{A}^{-1}\om{B}=\lambda\om{E}\ \lr\ \om{B=\lambda A}.$\qed
\ab\\ Запись в координатах:
\ab Пусть $(e_0,e_1,\dots,e_n)$ - базис $V$. Рассмотрим аффинную карту $S_0=e_0+\lob{e_1,\dots,e_n}.$\ab
Пусть $x=(x_1,x_2,\dots,x_n)=e_0+x_1e_1+\dots+x_ne_n\in S_0.$
Тогда $\om{A}x=y_0e_0+y_1e_1+\dots+y_ne_n,$ где\\ $y_i=a_{i0}+a_{i1}x_1+\dots+a_{in}x_n.$\\
Значит, $\om{A}x=(z_1,\dots,z_n),$ где
$$
z_i=\frac{\displaystyle y_i}{\displaystyle y_0}=\frac{\displaystyle a_{i0}+a_{i1}x_1+\dots+a_{in}x_n}{\displaystyle a_{00}+a_{01}x_1+\dots+a_{0n}x_n}.
$$
Таким образом, проективное преобразование - это дробно-линейное преобразование.\\ При $n=1$ оно выглядит как
$$x\mapsto\frac{\displaystyle ax+b}{\displaystyle cx+d},\mbox{ где }\left|%
\begin{array}{cc}
  a & b \\
  c & d \\
\end{array}%
\right|\ne 0.$$
При этом $-\frac{\displaystyle d}{\displaystyle c}\mapsto \infty,\ \ \mbox{а\ \ }\infty\mapsto \frac{\displaystyle a}{\displaystyle c}.$
\de Будем говорить, что точки $p_0,p_1,\dots,p_{n+1}\in PV$ находятся в общем положении, если никакие $n+1$ из них
не лежат в одной гиперплоскости.
\te Если точки $p_0,p_1,\dots,p_{n+1}\in PV,$ а также точки $q_0,q_1,\dots,q_{n+1}\in PV$ находятся в общем положении, то
существует единственное проективное преобразование $f$, для которого $$f(p_i)=q_i,\quad i=0,1,\dots,n+1.$$
\dok Пусть $p_i=\we{e}_i,$ где $e_i\in V.$ Тогда любые $n+1$ векторов из $e_0,\dots,e_{n+1}$ линейно независимы, и
в частности, $e_0,e_1,\dots,e_n$ - базис пространства $V$. Тогда $e_{n+1}$ раскладывается по этому базису.
Но за счёт нормировки базисных векторов можно добиться $e_{n+1}=e_0+e_1+\dots+e_n.$
При этом $e_0,e_1,\dots,e_n$ определены однозначно с точностью до одновременного умножения на одно и то же число.
\\Аналогично, существуют такие векторы $f_0,f_1\dots,f_{n+1}\in V,$ что $q_i=\we{f}_i,$\ \,и\ \,$f_{n+1}=f_0+f_1+\dots+f_n.$
Пусть $\om{A}$ - линейное преобразование, переводящее базис $(e)$ в базис $(f),$ тогда $\om{A}e_{n+1}=f_{n+1},$ поэтому
$\om{\we{A}}p_i=q_i\ \ \forall\ i.$
\ab Теперь пусть $\om{B}$ - линейное преобразование, такое, что $\om{\we{B}}p_i=q_i,\quad i=0,1,\dots,n+1.$ Тогда $\om{B}e_i=\lambda_if_i.$
Но так как $e_{n+1}=e_0+e_1+\dots+e_n,$ то $\om{B}e_{n+1}=\om{B}e_0+\dots+\om{B}e_n=\lambda_0f_0+\dots+\lambda_nf_n=\lambda_{n+1}f_{n+1}.$
\\ Значит, $\lambda_0=\dots=\lambda_n=\lambda_{n+1}\ \Rightarrow\ \om{B=\lambda A}.$\qed
\section{Двойное отношение четвёрки точек, лежащих\\ на одной прямой. Его инвариантность\\ при проективных преобразованиях.}
\label{q54}
У проективного преобразования нет инварианта даже трёх точек, лежащих на одной прямой.
\ab Пусть $L=PU\subset PV$ - прямая, то есть\; $\dim U=2.$
Пусть $(e_1,e_2)$ - базис в $U$. Пусть $p_1,p_2,p_3,p_4\in L,$ $p_i=\we{u}_i,$ где $u_1,u_2,u_3,u_4\in U.$
\ab Обозначим через $\det(u,v)$ ($\ \forall \ u,v\in U$) определитель матрицы, составленный из координат векторов
$u$ и $v$ в базисе $(e_1,e_2).$ Двойное отношение точек $p_1,p_2,p_3,p_4$ определяется по формуле
$$
(p_1,p_2;\,p_3,p_4)=\frac{\displaystyle \det(u_1,u_3)}{\displaystyle \det(u_3,u_2)}:\frac{\displaystyle\det(u_1,u_4)}{\displaystyle\det(u_4,u_2)}.
$$
Это выражение не зависит от выбора векторов $u_1,u_2,u_3,u_4\in U,$ также оно не зависит от базиса пространства $U$.
\\Выразим двойное отношение через неоднородные координаты точек $p_i$ на прямой $L.$
\\Пусть $S$ - аффинная карта $PV$. $u_1,u_2,u_3,u_4\in S\cap L,\ u_i=e_2+x_ie_1.$
Пусть $x_1,x_2,x_3,x_4$ - неоднородные координаты точек $p_i$. Тогда
$$
\det(u_i,u_j)=\left|%
\begin{array}{cc}
  x_i & 1 \\
  x_j & 1 \\
\end{array}%
\right|=x_i-x_j,\mbox{ таким образом, }(p_1,p_2;\,p_3,p_4)=\frac{\displaystyle x_1-x_3}{\displaystyle x_3-x_2}:
\frac{\displaystyle x_1-x_4}{\displaystyle x_4-x_2}=\frac{\displaystyle (u_1,u_2;\,u_3)}{\displaystyle (u_1,u_2;\,u_4)}.
$$
\te Проективное преобразование $f\in{\rm PGL}(V)$ сохраняет двойное отношение, то есть $$
\left(f(p_1),f(p_2);\,f(p_3),f(p_4)\right)=(p_1,p_2;\,p_3,p_4).
$$
\dok
Пусть $p_1,p_2,p_3,p_4\in PU,\ \dim U=2.$  Пусть $(e_1,e_2)$ - базис $U$, и $u_1,u_2,u_3,u_4\in U$ таковы, что $\we{u}_i=p_i.$
\\Пусть $f=\om{\we{A}},\ \om{A}\in {\rm GL}(V).$ Пусть $v_i=\om{A}u_i,\ \ f_1=\om{A}e_1,\ f_2=\om{A}e_2.$ Тогда $(f_1,f_2)$ -
базис $\om{A}U,\ \ \we{v}_i=f(p_i).$
$$
\left(f(p_1),f(p_2);\,f(p_3),f(p_4)\right)=\frac{\displaystyle \det(v_1,v_3)}{\displaystyle \det(v_3,v_2)}:\frac{\displaystyle\det(v_1,v_4)}{\displaystyle\det(v_4,v_2)}.
$$
Но $v_i$ выражается через $(f_1,f_2)$ также, как $u_i$ выражался через $(e_1,e_2),$ поэтому
$$\det(v_i,v_j)=\det(u_i,u_j).$$
Таким образом, двойное отношение сохраняется при проективном преобразовании.\qed
\section{Квадрики в проективном пространстве, их аффинные\\ изображения. Проективная классификация\\ невырожденных вещественных квадрик,
её сопоставление\\ с аффинной классификацией.}
\label{q55}
\de Конусом в векторном пространстве $V$ называется подмножество $X\subset V$, обладающее свойством
$$
x\in X\ \Rightarrow\ \lambda x\in X\ \forall\ \lambda\in K.
$$
Проективизацией конуса $X\subset V$ называется множество $PX\subset PV$ всех одномерных подпространств, содержащихся в $X$.
Изображение проективизации конуса $X$ на аффинной карте $S$ есть $X\cap S$.
\ab Квадратичным конусом в пространстве $V$ называется коническая квадрика с вершиной в нуле. Проективизация квадратичного
конуса называется проективной квадрикой.\ab
Квадратичный конус - это подмножество, задаваемое уравнением $Q(x_0,x_1,\dots,x_n)=0,$ где $Q$ - квадратичная функция
в пространстве $V$, при условии, что это множество не есть подпространство.
Это же уравнение есть уравнение соответствующей проективной квадрики в однородных координатах. Изображение
на аффинной карте $S_0:\ x_0=1$ задаётся уравнением\ \ $Q(1,x_1,\dots,x_n)=0.$
\\Если это не пустое множество и не плоскость, то это аффинная квадрика (на самом деле, можно доказать,
что если поле $K$ бесконечно, то это не может быть пустым множеством). Тип этой аффинной квадрики, безусловно, зависит от аффинной карты.
\\ Бесконечно удалённая часть проективной квадрики задаётся уравнением\ \ $Q(0,x_1,\dots,x_n)=0.$ Это уравнение в
однородных координатах на бесконечно удалённой гиперплоскости, и если это не пустое множество и не плоскость, то это квадрика.
\\ Всякая аффинная квадрика $X$ на $S_0$ является изображением однозначно определённой проективной квадрики $\we{X}.$
Уравнение $\we X$ в однородных координатах получается из уравнения квадрики $X$ путём вставления $x_0$ в члены первой
степени и $x_0^2$ в свободный член.
\de Проективная квадрика $Q(x_0,x_1,\dots,x_n)=0$ называется невырожденной, если квадратичная функция $Q$ невырождена,
и вырожденной в противном случае.
\ab Пусть $Q$ вырождена, и $F$ - соответствующая симметрическая билинейная функция.\\ Пусть $u\in \rom{Ker}F,\ u\ne 0.$
Тогда $Q(x)=0\ \Rightarrow\ Q(\lambda x+\mu u)=0\ \forall\ \lambda,\mu\in K,$ потому что \\
$Q(\lambda x+\mu u)=\lambda^2Q(x)+2\lambda\mu F(x,u)+\mu^2Q(u)=0.$\\ Это означает, что соответствующая проективная квадрика
вместе с каждой точкой $p$ содержит прямую, проходящую через $p$ и точки $o=\we{u}.$
\\В аффинном изображении на карте $S$  мы получим конус, если $o\in S$, и цилиндр в противном случае (если $o\notin S,$ то
это бесконечно удалённая точка, и $p\in$ изображению $\ \Rightarrow\ $ прямая, параллельная $o$, принадлежит изображению).
\ab Таким образом, в проективной геометрии нет разницы между конусом и цилиндром.
\ab\\ Рассмотрим невырожденные проективные квадрики в вещественном проективном пространстве.
\\ Канонический вид уравнения в однородных координатах:
$$
x_0^2+x_1^2+\dots+x_k^2-x_{k-1}^2-\dots-x_n^2=0\quad\left(\frac{n-1}{2}\le k<n\right).
$$
Рассмотрим случаи $n=2$ и $n=3$.
\\ При $n=2$ есть только одна возможность:\\ $x_0^2+x_1^2-x_3^2=0.$ Эта квадрика называется коникой.
\\ При $n=3$ - две возможности:\\ $x_0^2+x_1^2+x_2^2-x_1^2=0$ - овальная квадрика, и\\ $x_0^2+x_1^2-x_2^2-x_1^2=0$ -
линейчатая квадрика.

\vbox{Таблица:

\begin{tabular}{|c|c|c|c|}

  % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
\hline

    $n$ & Проективная квадрика & Аффинное изображение & Бесконечно удалённая часть \\
  \hline
  2 & коника & эллипс & пусто \\\cline{3-4}
   &  & парабола & точка \\\cline{3-4}
   &  & гипербола & пара точек \\\hline
  3 & овальная квадрика & эллипсоид & пусто \\\cline{3-4}
   &  & эллиптический параболоид & точка \\\cline{3-4}
   &  & двуполостный гиперболоид & коника \\\cline{2-4}
   & линейчатая квадрика & однополостный гиперболоид & коника \\\cline{3-4}
   &  & гиперболический параболоид & пара прямых \\\cline{3-4}
\hline

\end{tabular}
}

%\input linal10.tex
%\renewcommand{\c}{\mathbb{C}}
%\newcommand{\eps}{\varepsilon}
%\newcommand{\pr}{{\rm pr\,}}%
%\newcommand{\rk}{{\rm rk\,}}%
%\newcommand{\de}{\par\noindent\underline{Def}.\ }%
%\newcommand{\ab}{\par\noindent}%
%\newcommand{\te}{\par\noindent{\bf Теорема.}\ }%
%\newcommand{\dok}{\par\noindent{\bf Доказательство.}\ }%
%\newcommand{\qed}{\quad${{\bf Q.E.D.}}$}
%\renewcommand{\phi}{\varphi}
%\newcommand{\sled}{\par\noindent{\bf Следстсвие.}\ }%
%\newcommand{\baz}[1]{\left(#1_1,\dots,#1_n\right)}%
%\newcommand{\lr}{\Leftrightarrow}%
%\newcommand{\nn}[1]{#1_1,#1_2,\dots,#1_n}%
%\newcommand{\lob}[1]{\left\langle#1\right\rangle}%
%\newcommand{\ps}{\oplus}
%\newcommand{\rom}[1]{{\rm#1\,}}
%\newcommand{\op}[1]{$\mathcal{#1}$}
%\newcommand{\om}[1]{\mathcal{#1}}
%\newcommand{\oi}[1]{\overrightarrow{#1}}%
%\renewcommand{\le}{\leqslant}
%\renewcommand{\ge}{\geqslant}
%\newcommand{\we}[1]{\widehat{#1}}

\section{Векторные модели сферической и гиперболической\\ геометрий. Плоскости, расстояние между точками\\ и движения в этих моделях.}
\label{q56}
\subsection{Сферическая геометрия.}
Пусть $E^{n+1}$ - $(n+1)-$мерное евклидово пространство со скалярным умножением $$(x,x)=x_0^2+x_1^2+\dots+x_n^2.$$
Рассмотрим $S^n$ --- $n-$мерную сферу, задаваемую уравнением $(x,x)=1.$ $k-$мерные плоскости на $S^n$ - это
подмножества вида $S^n\cap U,$ где $U$ --- $(k+1)-$мерное подпространство в $E^{n+1}.$ Нульмерные плоскости - это
пары диаметрально противоположных точек, одномерные - это большие круги, называемые прямыми в сферической геометрии.
\ab Пусть $\dim \Pi_1+\dim\Pi_2\ge n.$ Тогда $\Pi_1\cap\Pi_2\ne \varnothing.$ В частности, любые две прямые на $S^2$ пересекаются.
Через любые две точки проходит прямая.
\ab Расстояние между точками определяется по формуле $\cos\rho(x,y)=(x,y),$ то есть равно длине дуги большого круга.
\ab Групповой смысл:
\ab Рассмотрим однопараметрическую группу поворотов в подпространстве $\lob{x,y}.$ В ортонормированном базисе
$$
\Pi(t)=\left(%
\begin{array}{cc}
  \cos t & -\sin t \\
  \sin t & \cos t \\
\end{array}%
\right).
$$
$\Pi(t)\Pi(s)=\Pi(t+s).$\ \ Если $y=\Pi(t)x,\ 0\le t\le\pi,$ то $\rho(x,y)=t.$
\ab Отсюда следует, что расстояние аддитивно: действительно, для точек $x,y,z,$ лежащих на одной полуокружности,
и $y$ - между $x$ и $z$ выполняется $\rho(x,y)+\rho(y,z)=\rho(x,z),$ так как $y=\Pi(t)x;\ z=\Pi(s)y,$ тогда
$z=\Pi(t+s)x.$
\ab Группа движений сферической геометрии - это ортогональная группа $O_{n+1},$ так как эта группа сохраняет сферу.
\subsection{Гиперболическая геометрия (геометрия Лобачевского).}
Пусть $E^{n,1}$ - псевдоевклидово пространство сигнатуры $(n,1)$ (пространство Минковского) со скалярным умножением
$$(x,x)=-x_0^2+x_1^2+\dots+x_n^2.$$
Рассмотрим гиперболоид $L^n\ :\ (x,x)=-1;\ x_0>0$ (рассматривается только одна связная компонента).
\de $(k+1)-$мерное подпространство $U\subset E^{n,1}$ называется гиперболическим, если ограничение скалярного умножения на
него имеет сигнатуру $(k,1)$, то есть невырождено и неопределённо.
\ab$k-$мерной плоскостью пространства $L^n$ называется подмножество вида $L^n\cap U,$ где \\
$U$ --- $(k+1)-$мерное гиперболическое подпространство.\\
Нульмерные плоскости - это точки, одномерные плоскости называются прямыми.
\\ Расстояние между точками определяется по формуле $$\ch\rho(x,y)=-(x,y).$$
\ab Групповой смысл:
\ab Рассмотрим однопараметрическую группу гиперболических поворотов в двумерном подпространстве $\lob{x,y}.$
В ортонормированном базисе
$$
H(t)=\left(%
\begin{array}{cc}
  \ch t & \sh t \\
  \sh t & \ch t \\
\end{array}%
\right).
$$
Групповое свойство:\ \ $H(t)H(s)=H(t+s).$\ \ В подходящем базисе (где $(x,x)=x_0x_1$)
$$
H(t)=\left(%
\begin{array}{cc}
  e^t & 0 \\
  0 & e^{-t} \\
\end{array}%
\right).
$$
Такое преобразование называется ещё преобразованием Лоренца.
\ab Если $y=H(t)x,$ то $\rho(x,y)=t.$ Действительно,пусть $(e_0=x,e_1)$ - ортонормированный базис в $\lob{x,y}$.
Тогда $H(t)x=x\ch t+e_1\sh t=y.\ \ (x,y)=-\ch t\ \Rightarrow\ \ch\rho(x,y)=-(x,y).$
\\Свойство аддитивности расстояний между точками: если точки $x,y,z$ лежат на одной прямой, причём $y$ лежит между
$x$ и $z$, то $$\rho(x,y)+\rho(y,z)=\rho(x,z).$$
Группа движений геометрии Лобачевского - это псевдоортогональная группа $O_{n,1}$ - группа линейных
преобразований $E^{n,1},$ сохраняющая скалярное умножение. Точнее, её подгруппа индекса 2 ($O'_{n,1}),$ сохраняющая
каждую связную компоненту гиперболоида $(x,x)=-1.$
\section{Свойство максимальной подвижности\\ в сферической и гиперболической геометриях.}
\label{q57}
\de Ортонормированным репером в пространстве $S^n$ (соответственно, $L^n$) называется система $(e_0;\,e_1,\dots,e_n),$
где $e_0\in S^n$ (соответственно, $L^n$), а $\baz{e}$ - ортонормированный базис в касательном подпространстве $T_{e_0}(S^n)=\lob{e_0}^\bot$
(соответственно, $T_{e_0}(L^n)=\lob{e_0}^\bot,$ а ортонормированный базис в $T_{e_0}(L^n)$ - это базис, для которого $(e_0,e_0)=-1,\
(e_i,e_i)=1$ при $i>0,\ (e_i,e_j)=0$ при $i\ne j$).
\te Для любых ортонормированных реперов $(e_0;\,e_1,\dots,e_n)$ и $(e'_0;\,e'_1,\dots,e'_n)$ существует единственное движение,
переводящее первый репер во второй (в $S^n$ и в $L^n$).
\dok Для $S^n$ существует единственный линейный оператор $\om{A}$ в $E^{n+1},$ переводящий базис
$$(e_0,e_1,\dots,e_n)$$ в базис
$(e_0',e_1',\dots,e'_n)$, и так как оба базиса ортонормированные, то $\om{A}\in O_{n+1};$
\ab Для $L^n$ аналогично с тем замечанием, что $\om{A}e_0=e'_0,$ поэтому $\om{A}\in{O'_{n,1}}.$\qed
\section{Сумма углов сферического\\ и гиперболического треугольника.}
Измерение углов между прямыми $m$ и $l$:
\\Если $m=\Pi(t)l,$ где $\Pi(t)$ - поворот вокруг точки $p=m\cap l$ на угол $t$ в плоскости $ml$, то $\angle ml=t.$
\\Если $e$ и $f$ - единичные векторы, ортогональные $l$ и $m$ соответственно, то $\cos\angle lm=-(e,f).$
\ab Составим матрицу для треугольника с углами $\alpha,\beta$ и $\gamma$, вершинами $p,q,r$ и единичными нормалями к
сторонам $e,f,g$ соответственно:
$$
G(e,f,g)=\left(%
\begin{array}{ccc}
  1 & -\cos\gamma & -\cos\beta \\
  -\cos\gamma & 1 & -\cos\alpha \\
  -\cos\beta & -\cos\alpha & 1 \\
\end{array}%
\right).
$$
Определитель этой матрицы обозначим $\Delta(\alpha,\beta,\gamma):$
$$
\Delta(\alpha,\beta,\gamma)=\det G(e,f,g)=1-2\cos\alpha\cos\cos\gamma-\cos^2\alpha-\cos^2\beta-\cos^2\gamma.
$$
Если $E^2$, то $\Delta(\alpha,\beta,\gamma)=0,$ если $S^2$, то $\Delta(\alpha,\beta,\gamma)>0,$ если $L^2$, то $\Delta(\alpha,\beta,\gamma)<0.$
\te Сумма углов сферического (гиперболического) треугольника больше $\pi$ (соответственно, меньше $\pi$).
\dok
Докажем, что для сферического (гиперболического) треугольника $\alpha+\beta+\gamma\ne\pi.$ Действительно, иначе
существовал бы евклидовый треугольник с теми же углами, и тогда $\Delta(\alpha,\beta,\gamma)=0.$
\ab Из соображений непрерывности следует, что $\alpha+\beta+\gamma-\pi$ имеет один знак для всех треугольников.
Для $S^2$ есть треугольник с $\alpha=\beta=\gamma=\frac\pi2.$\ab
Для $L^2$ - идеальный треугольник с $\alpha=\beta=\gamma=0.$\qed\ab
Рассмотрим равносторонний треугольник с $\alpha=\beta=\gamma.$ \ab Тогда $\Delta(\alpha,\beta,\gamma)=
\Delta(\alpha,\alpha,\alpha)=1-3\cos^2\alpha-2\cos^3\alpha=(1+\cos\alpha)^2(1-2\cos\alpha).$
$$1-2\cos\alpha\ \left\{%
\begin{array}{ll}
    >0, & \hbox{для $S^2$;} \\
    =0, & \hbox{для $E^2$;} \\
    <0, & \hbox{для $L^2$.} \\
\end{array}%
\right.\mbox{\ \ Поэтому\ }\alpha\ \left\{%
\begin{array}{ll}
    >\frac\pi3, & \hbox{для $S^2$;} \\
    =\frac\pi3, & \hbox{для $E^2$;} \\
    <\frac\pi3, & \hbox{для $L^2$.} \\
\end{array}%
\right.    $$
%\input linal11.tex
\section{Тензорная алгебра векторного пространства.}
\label{q59}
\de Полилинейной функцией, или $p-$линейной функцией на векторном пространстве $V$ над полем $K$ называется
отображение $\alpha:\underbrace{V\times\dots\times V}_p\rightarrow K,$ линейное по каждому аргументу.\\
Пусть $\baz{e}$ - базис пространства $V$. Положим $\alpha(e_{i_1},\dots,e_{i_p})\doteqdot a_{i_1\dots i_p}.$
\\В координатах $\alpha(x_1,\dots,x_p)=\sum\limits_{i_1,\dots,i_p}a_{i_1\dots i_p}x_{1i_1}\dots x_{pi_p}.$ Здесь
первый индекс - это номер вектора, второй - номер координаты.\\
Пространство $p-$линейных функций на $V$ обозначается $T_p(V).$ Базис этого пространства составляют функции
$$
\left\{\eps_{i_1\dots i_p}\ :\ i_1,\dots,i_p\right\},
$$
определяемые следующим образом:
\\
$\eps_{i_1\dots i_p}(e_{i_1},\dots,e_{i_p})=1;$\\
$\eps_{i_1\dots i_p}(e_{j_1},\dots,e_{j_p})$ в остальных случаях.
\\
Таким образом, $\alpha=\sum\limits_{i_1,\dots,i_p}a_{i_1\dots i_p}\eps_{i_1\dots i_p}$, значит, базис. Поэтому
$\dim T_p(V)=(\dim V)^p.$\\ В частности, $T_0(V)=K;\ T_1(V)=V^*.$
\ab Тензорное умножение определяется как операция
$$
\ty:T_p(V)\times T_q(V)\rightarrow T_{p+q}(V)
$$
по следующему правилу: если $\alpha\in T_p(V),\ \beta\in T_q(V),$ то $\alpha\ty\beta\in T_{p+q}(V)$, так, что
$$
\alpha\ty\beta(x_1,\dots,x_{p+q})=\alpha(x_1,\dots,x_p)\cdot\beta(x_{p+1},\dots,x_{p+q}).
$$
Свойства: \begin{enumerate}
    \item Линейность по обоим аргументам: по $\alpha$ и по $\beta$;
    \item Ассоциативность: $\alpha\in T_p(V),\ \beta\in T_q(V),\ \gamma\in T_r(V)\ \Rightarrow\ (\alpha\ty\beta)\ty\gamma=\alpha\ty(\beta\ty\gamma);$
    \item $\eps_{i_1,\dots,i_p}\in T_p(V),\ \eps_{i_{p+1},\dots,i_{p+q}}\in T_q(V)\ \Rightarrow\ \eps_{i_1,\dots,i_p}\ty\eps_{i_{p+1},\dots,i_{p+q}}=\eps_{i_1,\dots,i_{p+q}}\in T_{p+q}(V).$
\end{enumerate}
\de Тензорным произведением векторных пространств $V$ и $U$ называется векторное пространство $W$ вместе с билинейным отображением
$\ty:V\times U\rightarrow W,\ (x,y)\mapsto x\ty y,$ обладающим свойством:
\\
Если $\baz{e}$ - базис $V$, $(f_1,\dots,f_m)$ - базис $U$, то $(e_i\ty f_j\ :\ i=1,\dots,n;\ j=1,\dots,m)$ - базис $W$.
\\
Обозначается: $W=V\ty U,\ \dim W=\dim V\cdot\dim U.$
\ab
Таким образом, $T_{p+q}(V)=T_p(V)\ty T_q(V).$
\\
Аналогично определяется тензорное произведение нескольких векторных пространств, поэтому
$$T_p(V)=\underbrace{V^*\ty\dots\ty V^*}_p.$$
В частности, $\eps_{i_1,\dots,i_p}=\eps_{i_1}\ty\dots\ty\eps_{i_p},$ где $\eps_{i_1},\dots,\eps_{i_p}$ - координатные функции
из $V^*.$ Для любых $\alpha_1,\dots,\alpha_p\in V^*\ \ (\alpha_1\ty\dots\ty\alpha_p)(x_1,\dots,x_p)=\alpha_1(x_1)\dots\alpha_p(x_p).$
\ab Рассмотрим $T(V^*)=\bigoplus\limits_{p=0}^\infty T_p(V)\doteqdot\left\{(\alpha_0,\alpha_1,\dots)\ :\
\alpha_p\in T_p(V),\mbox{ и лишь конечное число }\alpha_p\ne 0\right\}.$
\ab Операции в $T(V^*)$ определяются покомпонентно. Таким образом, $T(V^*)$ - векторное пространство.
Также на $T(V^*)$ определена операция тензорного умножения:
$(\alpha_0,\alpha_1,\dots)(\beta_0,\beta_1,\dots)=(\gamma_0,\gamma_1,\dots),$ где
$$
\gamma_p=\sum_{q+r=p}\alpha_q\ty\beta_r.
$$
\de Алгеброй над полем $K$ называется векторное пространство над $K$, в котором задана билинейная операция
умножения $A\times A\rightarrow A,\ (a,b)\mapsto ab.$ Всё должно удовлетворять аксиомам:
\begin{enumerate}
    \item Относительно сложения и умножения $A$ - кольцо;
    \item Относительно сложения и умножения на элементы поля $K$ $A$ - векторное пространство;
    \item $\lambda(ab)=(\lambda a)b=a(\lambda b).$
\end{enumerate}
Операция умножения в алгебре однозначно определяется произведениями базисных векторов:\\
$e_ie_j=\sum\limits_kc_{ijk}e_k.$ Числа $c_{ijk}$ называются структурными константами алгебры.
\ab $T(V^*)$ - алгебра. Она называется тензорной алгеброй пространства $V^*$. Это ассоциативная алгебра
с единицей (единицей служит единица поля $K=T_0(V)$).
\ab Аналогично можно определить $T(V).$\\
$T(V)=\bigoplus\limits_{p=0}^\infty T^p(V),$ где $T^p(V)=\underbrace{V\ty\dots\ty V}_p.$ Элементы $T^p(V)$ можно
рассматривать как $p$-линейные функции на $V^*:\ \ (x_1\ty\dots\ty x_p)(\alpha_1,\dots,\alpha_p)=
x_1(\alpha_1)\dots x_p(\alpha_p).$\\
$T^1(V)=V,$ потому что векторы - это линейные функции на $V^*.$
\section{Симметрическая алгебра векторного пространства\\ (над полем нулевой характеристики), её связь\\
с алгеброй многочленов.}
\label{q60}
Пусть $S_p$ - группа подстановок $p$ элементов.\\
$\forall \sigma\in S_p\ \ \forall \alpha\in T_p(V)$ определим $\sigma\alpha\in T_p(V)$ по формуле
$$
(\sigma\alpha)(x_1,\dots,x_p)=\alpha\left(x_{\sigma(1)},\dots,x_{\sigma(p)}\right).
$$
\ab{\bf Лемма}. $(\sigma\tau)\alpha=\sigma(\tau\alpha)$.
\dok $\sigma(\tau\alpha)(x_1,\dots,x_p)=(\tau\alpha)\left(x_{\sigma(1)},\dots,x_{\sigma(p)}\right)=\\=
(\tau\alpha)(y_1,\dots,y_p)=\alpha\left(y_{\tau(1)},\dots,y_{\tau(p)}\right)=
\alpha\left(x_{\sigma\tau(1)},\dots,x_{\sigma\tau(p)}\right)=((\sigma\tau)\alpha)(x_1,\dots,x_p).$\qed
\de $p-$линейная функция называется симметрической, если $\sigma\alpha=\alpha\ \forall\ \sigma\in S_p.$
\ab Симметрические функции образуют подпространство $S_p(V)\subset T_p(V).$
\ab Пусть далее $\rom{char}K=0.$
\ab Рассмотрим отображение симметризации
$$
\rom{Sym}:T_p(V)\rightarrow T_p(V),\quad \rom{Sym}\alpha=\frac{\displaystyle 1}{\displaystyle p!}\sum_{\sigma\in S_p}\sigma\alpha.
$$
\te Оператор $\rom{Sym}$ есть проектор на подпространство $S_p(V).$
\dok \begin{enumerate}
    \item Если $\alpha\in S_p(V)$, то $\rom{Sym}\alpha=\alpha;$
    \item $\ \forall\alpha\ \  \rom{Sym}\alpha\in S_p(V):\\ \forall\tau\ \ \
    \tau\rom{Sym}\alpha=\frac{\displaystyle 1}{\displaystyle p!}\sum\limits_{\sigma\in S_p}\tau\sigma\alpha=\frac{\displaystyle 1}{\displaystyle p!}\sum\limits_{\sigma'\in S_p}\sigma'\alpha=\rom{Sym}\alpha;$
    \item Из доказательства следует, что $\,\rom{Sym}^2=\,\rom{Sym},$ поэтому $\rom{Sym}$ ---\, проектор.\qed
\end{enumerate}
\ab{\bf Лемма}. $\rom{Sym}(\rom{Sym}\alpha\ty \beta)=\rom{Sym}(\alpha\ty \rom{Sym}\beta)=\rom{Sym}(\alpha\ty \beta).$
\dok Действительно, $\rom{Sym}(\sigma\alpha\ty\beta)=\rom{Sym}(\alpha\ty\beta),$ потому что в $\sigma\alpha$ - перестановка
аргументов, но в $\rom{Sym}(\alpha\ty\beta)$ потом всё равно переставляем, поэтому ничего не меняется.\\ Суммируя по всем
$\sigma\in S_p$ и деля на $p!$, получаем, что $\rom{Sym}(\rom{Sym}\alpha\ty \beta)=\rom{Sym}(\alpha\ty \beta).$\\ Вторая часть доказывается аналогично.\qed
\de Определим операцию симметрического умножения:
$$
\vee:S_p(V)\times S_q(V)\rightarrow S_{p+q}(V);\quad \alpha\vee\beta=\rom{Sym}(\alpha\ty\beta).
$$
Свойства:
\begin{enumerate}
    \item Линейность по обоим аргументам;
    \item Коммутативность:\\
    $\beta\vee\alpha=\rom{Sym}(\beta\ty\alpha)=\rom{Sym}(\rho(\alpha\ty\beta))=\alpha\vee\beta$\ \ для некоторой\ \ $\rho\in S_{p+q}.$
    \item Ассоциативность: вытекает из леммы\ \ ''\,$\rom{Sym}-\rom{Sym}$''.
\end{enumerate}
\ab Рассмотрим симметрическую алгебру пространства $V^*:$
$$
S(V^*)=\bigoplus_{p=0}^\infty S_p(V),
$$
где операция умножения продолжается с операции $\vee$ по линейности (аналогично $T(V^*)$).
\ab Пусть $\alpha_1,\dots,\alpha_p\in S_1(V)=V^*.$\\
$(\alpha_1\vee\dots\vee\alpha_p)(x_1,\dots,x_p)=\frac{\displaystyle 1}{\displaystyle p!}\sum\limits_{\sigma\in S_p}
\alpha_1\left(x_{\sigma(1)}\right)\dots\alpha_p\left(x_{\sigma(p)}\right)=\frac{\displaystyle 1}{\displaystyle p!}\rom{per}(\alpha_i(x_j))$ - перманент.\\
Пусть $\baz{\eps}$ - базис $V^*$;\ \ $\baz{\eps^*}=\baz{e}$ - базис $V$.
\te $\eps_{i_1}\vee\dots\vee\eps_{i_p}\quad(i_1\le\dots\le i_p)$\ \ ---\ \ базис в $S_p(V).$
\dok \begin{enumerate}
    \item Произведения $\eps_{i_1}\ty\dots\ty\eps_{i_p}$ образуют базис в $T_p(V),$ значит,\\
    произведения \ \
    $\rom{Sym}\left(\eps_{i_1}\ty\dots\ty\eps_{i_p}\right)=\eps_{i_1}\vee\dots\vee\eps_{i_p}$
    порождают пространство $S_p(V).$\\ Но ввиду коммутативности достаточно рассматривать только
    $\eps_{i_1}\vee\dots\vee\eps_{i_p}$, где $(i_1\le\dots\le i_p).$
    \item Пусть $\sum\limits_{i_1\le\dots\le i_p}a_{i_1\dots i_p}\eps_{i_1}\vee\dots\vee\eps_{i_p}=0.$ Возьмём
    $j_1\le\dots\le j_p$ и рассмотрим значение суммы на $\left(e_{j_1},\dots,e_{j_p}\right).$
    Если $\left({i_1},\dots,{i_p}\right)\ne\left({j_1},\dots,{j_p}\right)$,\ \ то $\left(\eps_{i_1}\vee\dots\vee\eps_{i_p}\right)\left(e_{j_1},\dots,e_{j_p}\right)=0,$
    в противном случае это значение не равно нулю. Значит, $a_{i_1\dots i_p}=0.$\qed
\end{enumerate}
\sled $\dim S_p(V)=CC_n^p=\frac{\displaystyle n(n+1)\dots(n+p-1)}{\displaystyle p!}$\ \ \ (число сочетаний с повторениями).
\de Функция на $V$ со значениями в $K$ называется многочленом, если в координатах она записывается как многочлен.
\\ Степень многочлена не зависит от базиса (так как замена координат линейна).\\ Многочлены образуют алгебру $K[V].$
$$
K[V]=\bigoplus_{p=0}^\infty K[V]_p,
$$
где $K[V]_p$ - пространство однородных многочленов степени $p$.
\de Для любой симметрической $p-$линейной функции $\alpha\in S_p(V)$ определён ассоциированный с ней многочлен
$f_\alpha(x)=\alpha(x,x,\dots,x)\in K[V]_p.$
\te Отображение $\alpha\mapsto f_\alpha$ определяет изоморфизм алгебр $S(V^*)$ и $K[V].$
\dok \begin{enumerate}
    \item Докажем, что это гомоморфизм. Надо доказать, что $f_{\alpha\vee\beta}=f_\alpha f_\beta.$ Действительно,\\
    $f_{\alpha\vee\beta}(x)=(\alpha\vee\beta)(\underbrace{x,x,\dots,x}_{p+q})=\alpha(\underbrace{x,\dots,x}_p)\beta(\underbrace{x,\dots,x}_q)=
    f_\alpha(x)f_\beta(x).$
    \item $f_{\eps_i}(x)=\eps_i(x)=x_i\ \Rightarrow\ f_{\eps_{i_1}\vee\dots\vee\eps_{i_p}}(x)=x_{i_1}\dots x_{i_p}.$\\
    Но одночлены $x_{i_1}\dots x_{i_p}$ с $i_1\le\dots\le i_p$ образуют базис в пространстве многочленов,\\ а $\eps_{i_1}\vee\dots\vee\eps_{i_p}$ с $i_1\le\dots\le i_p$
    образуют базис в пространстве $S_p(V),$ так как $\rom{char}K\ne 0.$\\ Поэтому $\alpha\mapsto f_\alpha$ - изоморфизм.\qed
\end{enumerate}
\ab Аналогично строится $S(V).$ Оно изоморфно $K[V^*].$
\section{Внешняя алгебра векторного пространства\\ (над полем нулевой характеристики).}
\label{q61}
\de $p-$линейная функция $\alpha\in T_p(V)$ называется кососимметрической, если $\ \forall\sigma\in S_p\ \ \sigma\alpha=(\rom{sgn}\sigma)\alpha.$
\ab Кососимметрические функции образуют подпространство $\Lambda_p(V)\subset T_p(V).$
\de Операция альтернирования определяется следующим образом:
$$
\rom{Alt}:T_p(V)\rightarrow T_p(V),\quad \rom{Alt}\alpha=\frac{\displaystyle 1}{\displaystyle p!}\sum_{\sigma\in S_p}(\rom{sgn}\sigma)\sigma\alpha.
$$
\te $\rom{Alt}$ - проектор на подпространство $\Lambda_p(V).$
\dok \begin{enumerate}
    \item $\alpha\in \Lambda_p(V)\ \Rightarrow\ \rom{Alt}\alpha=\alpha.$
    \item $\forall\alpha\in T_p(V)\ \ \rom{Alt}\alpha\in\Lambda_p(V).$ Действительно, \\
    $\forall \tau\in S_p\ \ \ \tau\rom{Alt}\alpha=\frac{\displaystyle 1}{\displaystyle p!}\sum\limits_{\sigma\in S_p}(\rom{sgn}\sigma)\tau\sigma\alpha=
    \rom{sgn}\tau \cdot \frac{\displaystyle 1}{\displaystyle p!}\sum\limits_{\sigma\in S_p}(\rom{sgn}\sigma)\sigma\alpha=\rom{sgn}\tau\rom{Alt}\alpha.$
    \item $\rom{Alt}^2=\rom{Alt}\ \Rightarrow\ \rom{Alt}$ - проектор на $\Lambda_p(V).$\qed
\end{enumerate}
\ab{\bf Лемма}. $\rom{Alt}(\rom{Alt}\alpha\ty \beta)=\rom{Alt}(\alpha\ty \rom{Alt}\beta)=\rom{Alt}(\alpha\ty \beta).$
\dok $\forall\sigma\in S_p\ \ \ \rom{Alt}(\sigma\alpha\ty\beta)=(\rom{sgn}\alpha)\rom{Alt}(\alpha\ty\beta).$ Суммируя по всем
$\sigma$ и деля на $p!$, получаем, что $\rom{Alt}(\rom{Alt}\alpha\ty \beta)=\rom{Alt}(\alpha\ty \beta).$\qed
\de Операция внешнего умножения определяется таким образом:
$$
\wedge:\Lambda_p(V)\times\Lambda_q(V)\rightarrow\Lambda_{p+q}(V),\quad \alpha\wedge\beta=\rom{Alt}(\alpha\ty\beta).
$$
Свойства:
\begin{enumerate}
    \item Билинейность;
    \item Суперкоммутативность: $\beta\wedge\alpha=(-1)^{pq}\alpha\wedge\beta$\ \ \ ($\alpha\in\Lambda_p(V),\ \beta\in\Lambda_q(V)$) - доказывается аналогично симметрическому умножению: $\rom{sgn}\rho=(-1)^{pq}$.
    \item Ассоциативность - вытекает из соответствующей леммы.
\end{enumerate}
Можно построить внешнюю алгебру пространства $V^*$:
$$
\Lambda(V^*)=\bigoplus\limits_{p=0}^\infty\Lambda_p(V).
$$
В ней три операции: сумма, умножение на число и внешнее умножение (продолжается по дистрибутивности операции $\wedge:\Lambda_p(V)\times\Lambda_q(V)\rightarrow\Lambda_{p+q}(V)$).\\
$\Lambda_0(V)=K,\ \ \Lambda_1(V)=V^*.$
\ab Если $\alpha_1,\dots,\alpha_p\in V^*,$ то $(\alpha_1\wedge\dots\wedge\alpha_p)(x_1,\dots,x_p)=\frac{\displaystyle 1}{\displaystyle p!}\sum\limits_{\sigma\in S_p}(\rom{sgn}\sigma)\alpha_1\left(x_{\sigma(1)}\right)\dots\alpha_p\left(x_{\sigma(p)}\right)=
\\=\frac{\displaystyle 1}{\displaystyle p!}\det \left(\alpha_i(x_j)\right)$ - обыкновенный определитель.
\te Произведения $\eps_{i_1}\wedge\dots\wedge\eps_{i_p},$ где $i_1<\dots< i_p$, образуют базис подпространства $\Lambda_p(V).$
\dok \begin{enumerate}
    \item Так как произведения $\eps_{i_1}\ty\dots\ty\eps_{i_p}$ образуют базис пространства $T_p(V)$,\\ то $\rom{Alt}\left(\eps_{i_1}\ty\dots\ty\eps_{i_p}\right)=\eps_{i_1}\wedge\dots\wedge\eps_{i_p}$ порождают $\Lambda_p(V).$
    Если среди индексов есть одинаковые, то получается ноль. Если нет, то можно упорядочить по строгому возрастанию (при этом умножится на $\pm 1$). Поэтому
    произведения $\eps_{i_1}\wedge\dots\wedge\eps_{i_p},$ где $i_1<\dots< i_p$, порождают подпространство $\Lambda_p(V).$
    \item То, что это базис, доказывается аналогично симметрическому произведению.\qed
\end{enumerate}
\sled $\dim\Lambda_p(V)=C_n^p,$ в частности, $\dim\Lambda_p(V)=0$ при $p>n.$\\ $\dim\Lambda(V^*)=2^n,\ \dim\Lambda_n(V)=1.$
\ab Аналогично строится внешняя алгебра $\Lambda(V)=\bigoplus\limits_{p=0}^\infty\Lambda^p(V).$\\ Элементы $\Lambda^p(V)$ называются
$p-$векторами.
\section{Разложимые поливекторы\\ и подпространства векторного пространства.}
\label{q62}
\te Пусть $a_1,\dots,a_p\in V.$ Тогда $a_1\wedge\dots\wedge a_p=0\ \lr\ $ векторы линейно зависимы.
\dok \begin{enumerate}
    \item Пусть векторы линейно зависимы. Для определённости положим $a_p=\lambda_1a_1+\dots+\lambda_{p-1}a_{p-1}.$ Тогда
    $a_1\wedge\dots\wedge a_p=a_1\wedge\dots\wedge a_{p-1}\wedge(\lambda_1a_1+\dots+\lambda_{p-1}a_{p-1})=\sum\limits_{i=1}^{p-1}\lambda_i(a_1\wedge\dots\wedge a_{p-1}\wedge a_i)=0.$
    \item Пусть векторы линейно независимы. Включим их в базис $\baz{e}$ пространства $V$, так чтобы $e_i=a_i\ \ \ i=1,\dots,p.$
    Тогда $a_1\wedge\dots\wedge a_p=e_1\wedge\dots\wedge e_p$ - один из базисных векторов пространства $\Lambda_p(V)$, значит, не равен нулю.\qed
\end{enumerate}
\te Пусть $\{\nn{a}\}$ и $\{\nn{b}\}$ - две линейно независимые системы векторов $V$. Тогда
$a_1\wedge\dots\wedge a_p$ и $b_1\wedge\dots\wedge b_p$ пропорциональны $\ \lr\ $ $\lob{a_1,\dots,a_p}=\lob{b_1,\dots,b_p}.$
\dok \begin{enumerate}
    \item Пусть $\lob{a_1,\dots,a_p}=\lob{b_1,\dots,b_p}.$ Тогда система $(b)$ линейно выражается через систему $(a).$ Подставляя
    это выражение в $b_1\wedge\dots\wedge b_p,$ получаем, что $b_1\wedge\dots\wedge b_p$ линейно выражается через $a_{i_1}\wedge\dots\wedge a_{i_p}.$
    Но эти произведения линейно выражаются через $a_1\wedge\dots\wedge a_p,$ поэтому и $b_1\wedge\dots\wedge b_p$ линейно выражается через $a_1\wedge\dots\wedge a_p.$
    \item Пусть $a_1\wedge\dots\wedge a_p$ и $b_1\wedge\dots\wedge b_p$ пропорциональны. Выберем базис $\baz{e}$ пространства $V$,
    согласованный с $\lob{a_1,\dots,a_p}$ и $\lob{b_1,\dots,b_p}$. То есть, $\lob{a_1,\dots,a_p}=\lob{e_1,\dots,e_p}$ и
    $\lob{b_1,\dots,b_p}=\lob{e_1,\dots,e_r}\ps\lob{e_{p+1},\dots,e_{2p-r}}.$ Тогда мы видим, что
    $a_1\wedge\dots\wedge a_p$ пропорционально $e_1\wedge\dots\wedge e_p$, а $b_1\wedge\dots\wedge b_p$ пропорционально
    $e_1\wedge\dots\wedge e_r\wedge e_{p+1}\wedge\dots\wedge e_{2p-r}.$\\ Но $e_1\wedge\dots\wedge e_p$ и $e_1\wedge\dots\wedge e_r\wedge e_{p+1}\wedge\dots\wedge e_{2p-r}$ --- (при $r<p$) два
    разных базисных вектора пространства $\Lambda_p(V)$, поэтому они непропорциональны. Значит, $r=p.$\qed
\end{enumerate}
Таким образом, подпространство может характеризоваться лишь внешними произведениями базисных векторов.
Пусть $U\subset V,\ \dim U=p.$ Пусть $(a_1,\dots,a_p)$ - базис $U$. Разложим $a_1\wedge\dots\wedge a_p\in \Lambda_p(V)$ по
базису:
$$
a_1\wedge\dots\wedge a_p=\sum_{i_1<\dots<i_p}M_{i_1\dots i_p}e_{i_1}\wedge\dots\wedge e_{i_p},
$$
где $\baz{e}$ - базис пространства $V$. $M_{i_1\dots i_p},$ где $i_1<\dots<i_p$, называются плюккеровыми координатами подпространства $U$.
Они однозначно определяют подпространство, но сами они однородны.
\\
$a_i=\sum\limits_ja_{ij}e_j,\ A_{p\times n}=(a_{ij}).$ $M_{1\dots p}=\sum\limits_{\sigma\in S_p}(\rom{sgn}\sigma)\cdot a_{1\sigma(1)}\dots a_{p\sigma(p)}$ - угловой минор
матрицы $A$. Таким образом, $M_{i_1\dots i_p}$ - тоже минор, образованный столбцами $i_1,\dots,i_p.$
\de $p-$вектор, представимый в виде $a_1\wedge\dots\wedge a_p,$\ где $a_1,\dots,a_p\in V$, называется разложимым.
\\
Только разложимые $p-$векторы соответствуют подпространствам.
\section{Канонический вид и критерий разложимости бивектора.}
\label{q63}
Пусть $b\in\Lambda^2(V).$ Это можно рассматривать как кососимметрическую билинейную функцию на $V^*.$
$b(\eps_i,\eps_j)=b_{ij},\ \ B=(b_{ij})$ - матрица бивектора. Она кососимметрическая.
\ab{\bf Лемма}. $b=\sum\limits_{i,j}b_{ij}e_i\wedge e_j.$
\dok Найдём матрицу бивектора $e_i\wedge e_j$:
$$
(e_i\wedge e_j)(\eps_i,\eps_j)=-(e_i\wedge e_j)(\eps_j,\eps_i)=\frac12e_i(\eps_i)e_j(\eps_j)=\frac12.
$$
Получаем $\frac12 b_{ij}.$ Но в сумме будет $b_{ij},$ как раз.\qed
\te $\forall b\in\Lambda^2(V)$ существует симплектический базис.
\dok Вытекает из соответствующей теоремы.\qed
\te Следующие условия эквивалентны:
\begin{enumerate}
    \item Бивектор $b$ разложим;
    \item $\rk b\le 2;$
    \item $b\wedge b=0.$
\end{enumerate}
\dok Пусть $b$ разложим. Можно считать $b\ne 0.$ Пусть $b=a_1\wedge a_2,$ и $a_1,a_2$ линейно независимы.
Дополним $a_1,a_2$ до базиса $\baz{e}$ пространства $V$: $a_1=e_1,\ a_2=e_2.$ Тогда $b=e_1\wedge e_2.$ Значит,
$\rk b=2$ и $b\wedge b=0.$
\\
Пусть $b$ неразложим. Тогда существует базис, в котором
$$
b=e_1\wedge e_2+e_3\wedge e_4+\dots+e_{2k-1}\wedge e_{2k},
$$
где $k\ge 2$ (иначе $b$ разложим). Поэтому $\rk b=2k>2,\ \ b\wedge b=2e_1\wedge e_2\wedge e_3\wedge e_4+\dots\ne 0.$
\section{Определитель как единственная кососимметрическая\\ $n-$линейная функция в $n-$мерном пространстве.}
\label{q64}
Как известно, $\dim\Lambda_p(V)=C_n^p,$ то есть $\dim\Lambda_(V)=1.$ Поэтому кососимметрическая $n-$линейная функция в $n-$мерном пространстве
единственна с точностью до умножения на число.
\\
Рассмотрим определитель $n$ векторов в пространстве $V$: $a_1,\dots,a_n$ ---
пусть $\baz{e}$ - фиксированный базис пространства $V$, тогда составим определитель координат $\det(a_{ij})$ - первая цифра
означает номер вектора, вторая - номер координаты. При переходе к другому базису определитель (как кососимметрическая $n-$линейная функция в $n-$мерном пространстве) умножается
на определитель матрицы перехода.
\end{document}
