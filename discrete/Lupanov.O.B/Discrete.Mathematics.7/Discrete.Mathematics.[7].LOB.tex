\documentclass[a4paper,draft]{article}
\usepackage[nodiagram]{dmvn}

%\newcommand{\bcase}[1]{\left\{\begin{aligned}#1\end{aligned}\right.}

\newbox\mybigbox
\newbox\mysmallbox
\def\Size{\Huge}
\def\bigsyml#1{\setbox\mysmallbox\hbox{#1}\setbox\mybigbox\hbox{\Size#1}%
\smash{\raise\ht\mysmallbox\hbox{\lower\ht\mybigbox\copy\mybigbox}}}
\def\bigsymh#1{\smash{\hbox{\Size#1}}}

\let\amper\&
\def\&{\mathbin{\amper}}

\newcommand{\XSig}[1]{{x_1^{\si_1}\sd x_{#1}^{\si_{#1}}}}

%\newcommand{\sG}[2]{{g_{#1} \sco g_{#2}}}
%\newcommand{\BStd}{\hc{\neg \, \& \, \vee}}


\input picref

\newenvironment{petit}
{\par \smallskip \hrule \smallskip \footnotesize}
{\par \smallskip \hrule \smallskip}

\def\tbk{\par\bigskip
{\huge$$\mathfrak{To\;be\;continued...}$$\par}}

\DeclareMathOperator{\Ver}{Ver}

\def\s#1{\bs{[#1]}}

\newcommand{\CC}{\mathbf{CC}}

\newcounter{piccounter}
\def\thepiccounter{\arabic{piccounter}}
\def\cpic#1#2#3{%
\stepcounter{piccounter}%
\piclabel{#2}{\thepiccounter}%
\par\medskip\vbox{\centerline{\epsfbox{pictures.#1}}
\centerline{\footnotesize\normalfont Рис.~\thepiccounter. #3}}\medskip\par}

\begin{document}
\dmvntitle{Курс лекций по}{дискретной математике}{Лектор\т Олег Борисович Лупанов}
{IV курс, 7 семестр, поток математиков}{Москва, 2006 г.}

\tableofcontents

\pagebreak

\section*{Предисловие}

Порядок изложения материала наиболее соответствует курсу 2005~г.

Огромное спасибо Сергею Гладких за сотрудничество и набор главы про кодирование.
В данной версии исправлено ещё несколько опечаток, написан параграф про формулу включений-исключений,
а также алгоритм сжатия по Хаффману.

За поиск лажи выносится благодарность Ире Шитовой, Мише Левину, Мише Берштейну и Юре Притыкину.

\medskip
\dmvntrail

\pagebreak


\section*{Введение}

Курс условно можно разделить на насколько частей:

\begin{items}{-2}
\item Комбинаторный анализ
\item Теория графов
\item Кодирование
\item Теория сложности
\item Теория автоматов
\item Регулярные языки
\end{items}


\section{Комбинаторика и теория графов}

\subsection{Введение в комбинаторику}

\subsubsection{Простейшие комбинаторные объекты}

Вообще, теория графов\т это геометрическая модель комбинаторных объектов.

Будем обозначать через $M_n$ множество из $n$ элементов. Без ограничения
общности можно считать, что $M_n = \hc{1\sco n}$.

\begin{df}
\emph{Перестановкой} множества $M$ называется произвольная биекция $\pi\cln M \ra M$.
Очевидно, что для $n$\д элементных множеств количество всевозможных
перестановок равно $n!$.
\end{df}

\begin{df}
Назовём \emph{размещением} из $n$ элементов по $k$ любое упорядоченное множество
$(i_1\sco i_k)$, где $i_k \in M_n$.
Количество всевозможных размещений из $n$ элементов по $k$ обозначается $\Ab_n^k$.
\end{df}

\begin{stm}
Справедливо равенство
\eqn{\Ab_n^k = n(n-1)\sd (n-k+1).}
\end{stm}
\begin{proof}
Первый из $k$ элементов можно выбрать $n$ способами, второй\т $(n-1)$ способом, \итд Последний, $k$\д й элемент,
можно выбрать $(n-k+1)$
способами. Поэтому число размещений равно указанному произведению.
\end{proof}

\begin{df}
\emph{Сочетание}\т это неупорядоченное размещение. Говоря более формально, сочетание
из $n$ элементов по $k$\т это произвольное подмножество $n$\д элементного множества.
Количество сочетаний из $n$ элементов по $k$ обозначается $\Cb_n^k$ или $\binom nk$.
\end{df}

\begin{stm}
Справедливо равенство
\eqn{\Cb_n^k = \frac{\Ab_n^k}{k!}}
\end{stm}
\begin{proof}
Рассмотрим произвольное сочетание. Всевозможными перестановками из него можно получить $k!$ различных размещений,
причём для разных сочетаний получаются, естественно, непересекающиеся наборы
размещений. Это означает, что количество размещений в $k!$ больше числа сочетаний.
\end{proof}

Ясно, что
\eqn{\Cb_n^k = \frac{n(n-1)(n-2)\sd (n-k+1)}{1\cdot 2\sd k} =
\frac{n(n-1)(n-2)\sd (n-k+1)\cdot (n-k)\sd 1}{1\cdot 2\sd k\cdot (n-k)\sd 1} = \frac{n!}{k!(n-k)!}}

Из последней формулы очевидно, что $\Cb_n^k = \Cb_n^{n-k}$. У этой формулы есть и другое обоснование:
существует биекция между $k$\д элементными подмножествами и их ${(n-k)}$\д элементными дополнениями.

\begin{stm}
Справедливо равенство
\eqn{\suml{k=0}{n} \Cb_n^k = 2^n.}
\end{stm}
\begin{proof}
Из формулы бинома Ньютона, применённой к $(1+1)^n$, доказываемая формула  следует немедленно.
Однако, дадим второе доказательство. Поскольку $\Cb_n^k$\т это количество
$k$\д элементных подмножеств, то искомая сумма\т это количество всех подмножеств
$n$\д элементного множества. А всех подмножеств в $n$\д элементном множестве
ровно столько, сколько существует последовательностей из нулей и единиц длины $n$ (если
$i$\д й элемент есть в множестве, то ставим $1$, иначе ставим $0$). А таких
последовательностей, очевидно, $2^n$.
\end{proof}

\begin{df}
\emph{Сочетание с повторениями} из $n$ элементов по $k$\т это произвольный набор $(i_1 \le i_2\sle i_k)$, где $i_j \in M_n$.
Количество различных таких наборов мы будем обозначать $\CC_n^k$ (от англ. \emph{complete combination}).
\end{df}

\begin{stm}
\eqn{\CC_n^k = \Cb_{n+k-1}^k=\Cb_{n+k-1}^{n-1}.}
\end{stm}
\begin{proof}
Придумаем хорошую интерпретацию для числа сочетаний с повторениями. Именно, рассмотрим $k$ шариков,
расположенных в ряд. Возьмём $n-1$ <<перегородку>> (тогда образуется как раз $n$ ячеек) и воткнём их между шариками.
Тогда количество шариков до первой перегородки\т это в точности количество объектов первого типа,
количество шариков между первой и второй перегородкой\т это количество объектов второго типа,
и так далее. Итак, мы установили биекцию между расположениями перегородок и сочетаниями.
А теперь сопоставим каждой расстановке перегородок набор из нулей и единиц: пусть нулю соответствует перегородка,
а единице\т шарик. Тогда всякая расстановка перегородок кодируется строкой из ${n-1+k}$ нулей и единиц, в которой
ровно $k$~единиц. Осталось посчитать такие наборы. Это легко: достаточно расставить, например, единицы,
а нули сами найдут своё место. Очевидно, что количество способов расставить единицы\т это $\Cb_{n+k-1}^k$.
Второе равенство сразу следует из симметричности биномиальных коэффициентов.
\end{proof}

\begin{note}
Из определения числа сочетаний с повторениями ясно, что количество монотонных функций $f\cln M_p \ra M_q$\т
это в точности количество сочетаний с повторениями $\CC_q^p$.
\end{note}

\subsubsection{Оценки}

Получим оценки для числа $n!$ (они нам потребуются в дальнейшем).
В качестве очень грубой верхней оценки можно использовать оценку
\eqn{n! \le n^n.}

\begin{stm}
Справедливо неравенство
\eqn{n! \ge \hr{\frac n8}^n.}
\end{stm}
\begin{proof}
Для $n \le 8$ неравенство очевидно, потому что при таких $n$ справа стоит число, не превосходящее~$1$.
Пусть теперь $n \ge 8$. Будем доказывать по индукции. Положим $k:= \hce{\frac n2}$.
$$
n! = 1\cdot 2\cdot 3\sd k \cdot \hr{k+1}\sd n \stackrel{!}{\ge}
\hr{\frac{k}{8}}^{k} \cdot \hr{\frac n2}^{n-k} \ge
\hr{\frac n{16}}^{k}\cdot \hr{\frac n2}^{n-k} = \frac{n^n}{2^{4k}\cdot
2^{n-k}}.
$$
Поясним переход, отмеченный знаком <<$!$>>. Для оценки первой группы множителей пользуемся
предположением индукции, а вторую группу множителей оцениваем снизу меньшим из сомножителей
в соответствующей степени.
Осталось оценить показатель степени: $3k+n\le 3n$ при $n \ge 8$, поэтому всё доказано.
\end{proof}

Что касается чисел сочетаний с повторениями и без повторений, то для них мы чаще всего будем
использовать такие оценки:
\eqn{\Cb_n^k \le 2^n,\quad \CC_n^k \le 2^{n+k-1}.}
Они очевидным образом следуют из определения числа сочетаний.

Надо сказать, что, хотя это оценки достаточно грубы, нам их вполне будет хватать.
Вообще в этом курсе нам придётся бороться за константы один\д единственный раз\т при доказательстве
асимптотики сложности схем из функциональных элементов.

\subsection{Теория графов}

\subsubsection{Графы. Правильная реализация. Критерий Понтрягина\ч Куратовского}

\begin{df}
Пусть задано множество $V = \hc{v_1\sco v_p\etc}$ и множество
$E = \hc{e_1\sco e_q\etc}$. Пусть каждому элементу
$e \in E$ поставлена в соответствие неупорядоченная пара элементов $\hc{v,w}$ множества $V$
(при этом может быть так, что $v = w$).
В этом случае говорят, что задан граф с множеством вершин $V$ и множеством
рёбер $E$. Вершины $v$ и $w$, соответствующие ребру $e$, называются концами ребра $e$.
Этот факт удобно записывать, например, так: $\Ver(e) = \hc{v,w}$ (от англ. \emph{vertex}\т вершина).
\end{df}

\begin{df}
Вершина называется \emph{изолированной}, если в графе нет ребра с концом в этой вершине.
Если два ребра соединяют одну и ту же пару вершин, то говорят, что это \emph{кратные} (\emph{параллельные}) рёбра.
Вершина называется \emph{концевой}, если из неё выходит только одно ребро.
\end{df}

\begin{note}
Если в определении графа мы потребуем, чтобы пара вершин, соответствующих
ребру, была упорядоченной, мы получим определение \emph{ориентированного} графа.
\end{note}

Всякий граф можно реализовать в евклидовом пространстве. Отметим на плоскости столько различных
точек, сколько вершин в нашем графе, а потом соединим кривыми те вершины, которые соединены рёбрами
(эти кривые тоже будем называть рёбрами).
При этом может получиться так, что некоторые рёбра пересекаются.

\begin{df}
Говорят, что граф \emph{допускает правильную реализацию}, если можно так расставить
вершины и так провести рёбра, что любые два ребра не будут иметь общих точек
(кроме, быть может, самих вершин).
\end{df}

\begin{stm}
Всякий граф, у которого не более континуума вершин и не более континуума рёбер, допускает
правильную трёхмерную реализацию.
\end{stm}
\begin{proof}
Рассмотрим произвольную прямую в $\R^3$ и отметим на ней все вершины графа.
Теперь рассмотрим пучок плоскостей, проходящих через эту прямую.
Их там много, поэтому для каждого ребра можно выбрать свою плоскость.
После этого всё тривиально\т соединяем вершины дугой окружности, лежащей
в плоскости, соответствующей данному ребру. Эти дуги не будут пересекаться,
потому что разным рёбрам соответствуют разные плоскости.
\end{proof}

\begin{df}
\emph{Подграфом} графа $(V,E)$ называется такая пара $(V',E')$, что $V' \subs V$, $E' \subs E$,
и множество концов рёбер множества $E'$ содержится в множестве $V'$.
\end{df}

\begin{df}
Будем называть графы $\Ga(V_1,E_1)$ и $\Ga(V_2,E_2)$ изоморфными,
если существуют такие биекции между их рёбрами
и между вершинами, что соответствующие рёбра соединяют соответствующие вершины.
Иначе говоря, если $\ph\cln V_1 \ra V_2$, а $\psi\cln E_1\ra E_2$\т биекции,
то для всех $e \in E_1$ должно быть выполнено $\ph(\Ver(e)) \bw= \Ver(\psi(e))$.
\end{df}

Введём операцию подразбиения ребра: ставим где\д нибудь на ребре (но не в концах) ещё одну вершину,
и у нас получается новый граф, у которого вершин на одну больше и рёбер на одно больше (то есть большое ребро
исчезает, остаётся две <<половинки>>).

Если в графе подразбить несколько рёбер, то будем называть новый граф подразбиением исходного.

\begin{df}
Будем говорить, что $\Ga_1$ и $\Ga_2$ гомеоморфны, если существуют их подразбиения, изоморфные между собой.
\end{df}

\begin{df}
Граф $K_5$\т это полный граф, построенный на $5$ вершинах (рис.~\picref{kfive}).
\cpic{2}{kfive}{Граф $K_5$}
\end{df}

\begin{df}
Граф $K_{3,3}$\т это граф, показанный на рис.~\picref{kthreethree}.
\cpic{3}{kthreethree}{Граф $K_{3,3}$}
\end{df}

Справедливо следующее утверждение, которое мы доказывать не будем.

\begin{theorem}[Критерий Понтрягина\ч Куратовского]
Конечный граф допускает планарную правильную реализацию тогда и только тогда, когда не содержит
в себе подграфов, гомеоморфных $K_{3,3}$ и $K_5$.
\end{theorem}

Следующие несколько определений интуитивно ясны, мы не будем давать их слишком формально.
Все и так понимают, чего хочется от того или иного определения.
Они здесь написаны скорее для того, чтобы знать, что было на лекции.

\begin{df}
\emph{Путь} в графе $\Ga(V,E)$\т это упорядоченный набор рёбер, в котором конец любого предыдущего ребра
совпадает с началом следующего.
\end{df}

\begin{df}
\emph{Цикл}\т это путь, у которого начало и конец совпадают.
\end{df}

\begin{df}
Граф называется \emph{связным}, если из любой вершины в любую существует путь.
По определению, граф из одной вершины считается связным.
\end{df}


\begin{df}
\emph{Дерево}\т это связный граф без циклов.
\end{df}

\begin{df}
\emph{Дерево с корнем}\т это дерево, у которого помечена одна вершина.
\end{df}

Изоморфизм деревьев с корнями\т это изоморфизм графов, при котором корень переходит в корень.
Пусть $\de(q)$\т количество неизоморфных деревьев с $q$ рёбрами, а $\de^*(q)$\т количество неизоморфных
деревьев с корнями с $q$ рёбрами. Очевидно, что $\de(q) \le \de^*(q)$.

\begin{stm}
В любом конечном связном графе существует подграф, содержащий все вершины исходного графа
и являющийся деревом.
\end{stm}
\begin{proof}
Будем разрезать циклы, пока их не останется. При разрезании цикла связность не нарушается.
Поскольку рёбер конечное число, процесс когда-нибудь остановится.
\end{proof}

\begin{imp}
Всякий связный граф можно получить из дерева достройкой рёбер.
\end{imp}

\begin{stm}
Если в дереве $p$ вершин, то в нём $p-1$ ребро.
\end{stm}
\begin{proof}
Докажем индукцией по числу вершин. Найдём концевую вершину и удалим её. При этом пропадёт ровно одна вершина и ровно одно ребро.
Оставшийся граф тоже будет деревом с меньшим количеством вершин.
\end{proof}

\subsubsection{Оценки количества деревьев и графов}

Напомним обозначение $M_q = \hc{1\sco q}$.

\begin{theorem}
Имеет место оценка
\eqn{\de^*(q) \le 4^q.}
\end{theorem}
\begin{proof}
Возьмём дерево и расположим его листья строго по ярусам, чтобы корень был в самом низу.
Далее пронумеруем вершины номерами от $0$ до $q$, идя слева направо, сверху вниз, то есть заметая
ярус за ярусом слева направо. Ясно, что при такой нумерации корень получит номер $q$.
Теперь поставим в соответствие каждому такому пронумерованному дереву некоторую монотонную функцию.
Возьмём любую вершину (кроме корня) с номером $k$. Спустимся по ней на один шаг к корню.
Мы попадём в вершину, в которой будет написано какое\д то число $m$. Тогда пусть наша функция в точке $k+1$ принимает значение $m$.
Это будет функция, у которой область определения\т множество $M_q$, а область значений содержится в множестве $M_q$.
Легко проверить, что если нам дана какая\д нибудь монотонная функция , то по ней можно либо однозначно вырастить дерево, которое ей соответствует
(точнее говоря, \emph{если вообще можно}, то уж единственным образом).
Действительно, возьмём полный прообраз точки $q$. Его мощность\т это в точности количество рёбер, которые растут от корня.
Нарисуем их. Далее, возьмём самую правую вершину, она получит номер $q-1$. Снова берем прообраз, и так далее (если прообраз пуст, то это значит,
что данная вершина является концевой). Затем переходим к следующей вершине в том же яруса, двигаясь справа налево. В итоге мы раскодируем
всё дерево.

Итак, мы устроили инъективное отображение из множества деревьев с корнями в множество монотонных функций $f\cln M_q \ra M_q$.
А их количество мы знаем\т это $\CC_q^q = \Cb_{2q-1}^q \le 2^{2q-1} \le 4^q$. Стало быть, различных деревьев с корнем и того меньше.
\end{proof}

\begin{stm}
Количество $\de(q)$ неизоморфных деревьев с $q$ рёбрами оценивается снизу:
\eqn{\de(q) \ge \frac{1}{2\sqrt[3]{2}} \cdot \hr{\sqrt[3]{2}}^q.}
\end{stm}
\begin{proof}
Возьмём цепочку из $t$~рёбер, в ней будет $t+1$ вершина. Расположим эту цепочку
горизонтально, и к самой левой вершине прицепим $4$ ребра, чтобы сделать её особой (см.~рис.~\picref{TreeCodingSkel}).
\cpic{4}{TreeCodingSkel}{Дерево}
К остальным вершинам будем цеплять деревья из двух рёбер, изображённые на рис.~\picref{TreeCodingElem}
(первое будем кодировать нулём, второе\т единицей).
\cpic{5}{TreeCodingElem}{Поддеревья}
К каждой из $t$ вершин можно прицепить любое из этих двух деревьев, поэтому количество таких деревьев получается
равным $2^t$. Они, очевидно, неизоморфны между собой. Посчитаем количество рёбер у такой конструкции.
Скелет дерева состоит из $t$ рёбер, к каждой из $t$ вершин добавляется по $2$ ребра,
и ещё $4$ ребра добавлено к особой вершине. Таким образом, $q = 3t +4$. Отсюда $t = \frac{q-4}{3}$,
поэтому
\eqn{\de(q) \ge 2^ \le \frac{1}{2\sqrt[3]{2}} \cdot \hr{\sqrt[3]{2}}^q,}
что и требовалось доказать.
\end{proof}

\begin{note}
На самом деле можно доказать (Otter, 1948), что основание степени не меньше, чем $2.98$.
Доказательство Оттера существенно использует ТФКП.
\end{note}

\begin{stm}
Количество $\ga(q)$ неизоморфных связных графов с $q$ рёбрами.
оценивается сверху:
\eqn{\ga(q) \le (Cq)^q, \quad C = \const.}
\end{stm}
\begin{proof}
У каждого ребра два конца. Можно считать, что количество вершин равно~$2q$,
потому что во всякий граф можно добавить нужное количество изолированных вершин (полученные графы тоже будут неизоморфны,
потому что у каждого из них найдётся по связной компоненте, не изоморфной никакой связной компоненте другого графа).
Занумеруем вершины, тогда каждое ребро\т это пара чисел.
Посчитаем количество различных сортов рёбер. С учётом петель, их ровно $\CC_{2q}^2 = \Cb_{2q+1}^2 = q(2q+1) =: s$ штук.
Теперь у нас есть $s$ сортов рёбер, и из них нужно (возможно, с повторениями, потому что графы могут иметь кратные ребра)
выбрать $q$ штук. Значит,
\eqn{\ga(q) \le \CC_s^q = \Cb_{s+q-1}^q \le \frac{(s+q-1)^q}{q!}\le
\frac{(s+q-1)^q}{\hr{\frac{q}{8}}^q}.}
Имеем $s + q-1 \le 2q^2 + q + q \le 4q^2$. Отсюда получаем оценку
\eqn{\ga(q) \le \frac{(4q^2)^q}{\hr{\frac{q}{8}}^q} = (32q)^q,}
то есть в качестве константы $C$ можно взять $C = 32$.
\end{proof}

Через $\ga(p,q)$ будем обозначать количество связных графов с $p$ вершинами и $q$ рёбрами.

\begin{stm}
Для количества графов справедлива оценка сверху:
\eqn{\ga(p,q) \le p^{q-p} \cdot A^{q+p}, \quad A = \const.}
\end{stm}
\begin{proof}
Рассмотрим произвольное $p$\д вершинное дерево.
Чтобы из $p$\д вершинного дерева сделать $q$\д рёберный граф, нужно дополнительно провести ещё $q - (p-1) = q-p+1 =: k$ ребро.
Из каждой вершины дерева можно выпустить куда\д то ребро (так, чтобы второй конец болтался в воздухе).
Это можно сделать, очевидно, $\CC_p^k$ способами. Теперь эти концы надо как\д то подсоединить к имеющимся вершинам.
Это можно сделать $p^k$ способами. Значит, существует не более $\CC_p^k \cdot p^k$ способов получить из дерева граф.
А поскольку количество деревьев не превосходит $4^{p-1}$, то в итоге имеем оценку
\eqn{\ga(p,q) \le 4^{p-1} \cdot \CC_p^k \cdot p^k = 4^{p-1} \cdot \Cb_{p+k-1}^k \cdot p^k =
4^{p-1} \cdot \Cb_q^k \cdot p^k \le 4^{p-1} \cdot 2^q \cdot p^{q-p}\cdot p \stackrel{!}{\le} 8^p \cdot 8^q \cdot p^{q-p}.}
В последней оценке, отмеченной <<!>>, мы очень сильно всё загрубили: $4^{p-1} \le 4^p$, $p \le 2^p$ и, наконец, $2^q \le 8^q$.
Таким образом, достаточно взять $A = 8$.
\end{proof}

До сих пор мы рассматривали только связные графы. Теперь получим оценки  для графов с заданным количеством компонент связности~$r$.
Количество таких графов мы будем обозначать символом $\ga(p,q,r)$.

\begin{stm}
Имеет место неравенство
\eqn{\ga(p,q,r) \le p^{q-p}\cdot B^{q + p + r} .}
\end{stm}
\begin{proof}
Граф $\Ga(p,q,r)$ состоит из $r$ связных графов $\Ga(p_1,q_1)\sco \Ga(p_r,q_r)$, причём $p = \sum p_i$, $q = \sum q_i$.
Ясно, что при фиксированных наборах $\hc{p_i}$ и $\hc{q_i}$ количество оценивается произведением
\eqn{\prodl{i=1}{r} \ga(p_i,q_i) \le A^{q_1+p_1}\cdot p_1^{q_1-p_1} \sd A^{q_r+p_r} \cdot p_r^{q_r -p_r} \le A^{q+p} \cdot p^{q-p}.}
Итак, оценено каждое слагаемое. Теперь нам нужно оценить количество таких слагаемых, то есть посчитать количество
возможных наборов $\hc{p_i}$ и $\hc{q_i}$. Разбиения набора $p$ не допускают нулевых слагаемых
(потому что в каждом графе должна быть хотя бы одна вершина),
а разбиения числа $q$ допускают нулевые слагаемые (рёбер может не быть вовсе).
Посмотрим, что значит разбить число $p$ на $r$ слагаемых, среди которых не может быть нулевых.
Напишем подряд $p$ единиц и будем между ними расставлять $r-1$ знак <<$+$>>, то есть для расстановки есть $p-1$ позиция,
при этом два знака не могут стоять рядом. Значит, в первом случае имеем дело с сочетаниями без повторений,
а их $\Cb_{p-1}^{r-1} \le 2^{p-1}$.

Во втором случае надо разбить число $q$ на $r$ слагаемых, среди которых могут быть нулевые.
Будем тоже расставлять знаки <<$+$>> среди $q$, но теперь их можно ставить в самом начале и в самом конце,
то есть позиций $q+1$ штука, и кроме того, можно два плюса ставить подряд, то есть это сочетания с повторениями.
Поэтому их количество равно
$\CC_{q+1}^{r-1} = \Cb_{q+r-1}^{r-1} \le 2^{q+r-1}$.
Значит, количество разбиений заведомо не превосходит $2^{p-1} \cdot 2^{q+r-1} \le 2^{p+q+r}$.
Таким образом,
\eqn{\ga(p,q,r) \le A^{q+p} \cdot p^{q-p} \cdot 2^{p+q+r} \le A^{p+q+r}\cdot p^{q-p},}
поскольку $A \ge 2$. Таким образом, в качестве константы $B$ можно взять $A$, но это не так важно.
\end{proof}

\subsubsection{Ориентированные графы}

\begin{df}
Назовём граф \emph{ориентированным}, если каждому его ребру приписано направление.
\end{df}

\begin{df}
\emph{Ориентированный цикл}\т цикл, в котором все рёбра направлены в одну сторону, \те конечная
последовательность ориентированных рёбер $\br{\overrightarrow{v_{i},v_{i+1}}}$, где первая
вершина совпадает с последней.
\end{df}

\begin{lemma}
В любом конечном ориентированном графе без ориентированных циклов есть вершина, из которой рёбра не выходят.
\end{lemma}

\begin{proof}
От противного: выберем любую вершину и, выходя из неё, будем двигаться по рёбрам в направлении,
приписанном данному ребру. Если из каждой вершины выходит хотя бы одно ребро, то рано или поздно мы
вернёмся туда, где уже были, поскольку граф конечен. Но это будет ориентированный цикл. Противоречие.
\end{proof}

\begin{theorem}\label{thm:OriGraphNum}
В любом конечном ориентированном графе без ориентированных циклов можно занумеровать вершины первыми
натуральными числами так, что каждое ребро будет направлено от вершины с меньшим номером в вершину с большим
номером.
\end{theorem}

\begin{proof}
Докажем индукцией по числу вершин~$p$. При $p=1$ утверждение очевидно. Пусть $p>1$.
Предположим, что это верно для всех графов с числом вершин, меньшим $p$. Рассмотрим граф с $p$ вершинами. По
лемме у него есть вершина, из которой рёбра не выходят. Уберём из графа эту вершину и все входящие в неё
рёбра, получим граф с числом вершин, меньшим $p$. По предположению индукции такой граф допускает искомую
нумерацию вершин числами $1,2 \sco p-1$. Тогда присвоим выкинутой вершине номер~$p$.
\end{proof}

\subsubsection{Двудольные графы. Критерий Холла}

\begin{df}
Пусть множество вершин графа разбито на два подмножества $U$ и $L$. Граф называется \emph{двудольным},
если концы любого ребра лежат в разных подмножествах.
\end{df}

\begin{ex}
Примеры двудольных графов (рис.~\picref{twosidegr}):
\cpic{0}{twosidegr}{Двудольные и не двудольные графы}
\end{ex}

Условимся называть подмножество $U$ верхним, а $L$\т нижним. Будем рисовать двудольные графы
в соответствии с этими названиями.

\begin{df}
Говорят, что задано \emph{паросочетание} в двудольном графе, если для каждой верхней вершины зафиксировано по одному ребру (идущему в нижнее множество).
Фактически это означает, что задано отображение $f\cln U \ra E$. Паросочетание называется совершенным, если концы выпущенных
рёбер при этом не склеиваются.
\end{df}

Пусть $A \subs U$. Через $\Rs(A)$ будем обозначать образ бинарного отношения <<соединён ребром>> в~$L$.

\begin{theorem}[Критерий Холла]
Конечный двудольный граф обладает совершенным паросочетанием тогда и только тогда, когда для любого (непустого) $A \subs U$ имеем $\hm{\Rs(A)} \ge \hm{A}$.
\end{theorem}
\begin{proof}
Необходимость этого условия очевидна: если совершенное паросочетание нашлось, то ясно, что образ любого подмножества
содержит не меньше вершин, чем само это подмножество (иначе какие\д то два ребра, выходящие из множества $A$, упёрлись бы
в одну вершину в образе).

Докажем достаточность. Будем доказывать индукцией по числу $n = \hm{U}$. База $n=1$ очевидна: любое ребро годится.
Пусть всё доказано для $n$, докажем для $n+1$. Возможны два случая.

\pt{1} Для любого непустого $A \subs U$ имеем $\hm{\Rs(A)} > \hm{A}$, то есть по крайней мере $\hm{\Rs(A)} \ge \hm{A} + 1$.
Рассмотрим $a \in U$. По крайней мере одно ребро из неё выходит, пусть оно приходит в вершину $b \in L$.
Уберем вершины $a$ и $b$ из нашего графа вместе со всеми рёбрами, которые в них входят. Получим двудольный граф $\wt \Ga$
с множествами верхних и нижних вершин $\wt U$ и $\wt L$.
Покажем, что $\bm{\Rs(\wt A)} \ge \bm{\wt A}$. Действительно, рассмотрим множество оставшихся <<претендентов>> на вершину $b$.
Для любого подмножества с их участием, но без участия вершины $a$, неравенство было строгим.
Образ этого подмножества, конечно, захватывает вершину $b$, но когда мы её уберём, неравенство лишь превратится
в нестрогое, ибо мы теряем всего одну вершину. Все остальные подмножества и вовсе сохранят строгие равенства.
Итак, к новому графу уже применимо предположение индукции, потому что в $\wt U$ меньше вершин, чем в $U$.

\pt{2} Пусть нашлось собственное непустое подмножество $A_0 \subs U$, для которого $\hm{\Rs(A_0)} = \hm{A_0}$.
Поскольку оно собственное, то в нём уже по предположению индукции существует совершенное паросочетание.
Теперь рассмотрим то, что останется от графа, если вырезать $A_0$ и $\Rs(A_0)$. Если для какого\д то множества $\wt A$
в новом графе неравенство нарушится, то оно нарушится и для $A_0 \cup \wt A$ в исходном графе.
Значит, можно применить предположение индукции по\д отдельности к множеству $A_0$ и к его <<дополнению>>.
\end{proof}

\subsection{Формальные степенные ряды и производящие функции}

Производящие функции\т это замечательный инструмент для того, чтобы что-нибудь посчитать.
Чтобы иметь возможность что-либо про них говорить, нам нужны формальные степенные ряды.

\subsubsection{Формальные степенные ряды}

Пусть $K$\т  кольцо с $1$. Рассмотрим последовательность $\hc{a_i} \subs K$.
Построим формальное выражение $\sumizi a_i x^i$. Его мы будем называть формальным степенным рядом
над кольцом $K$.

Множество формальных степенных рядов над кольцом $K$ будем обозначать $K\s x$.
Введём на этом множестве структуру кольца. Определим сложение степенных рядов естественным образом,
а именно, если
\eqn{(A+B)(x) = \sumizi (a_i+b_i)x^i, \text{ где } A(x) = \sumizi a_ix^i, \quad B(x) = \sumizi b_i x^i.}
Произведение определим так: будем говорить, что $C(x) = A(x) \cdot B(x)$, если коэффициенты
ряда $C(x)$ определяются по формуле $c_k = \suml{i=0}{k} a_ib_{k-i}$.
Два ряда будем называть равными, если у них равны все коэффициенты при соответствующих степенях.
Итак, мы получили кольцо формальных степенных рядов с единицей.

Заметим, что подстановка вместо переменной $x$ какого\д либо значения вообще лишена смысла.
Однако удобно считать, что подстановка нуля даёт коэффициент $a_0$, поэтому будем по определению
считать, что $A(0) = a_0$ для степенного ряда $\sumizi a_i x^i$.

Отметим простые свойства полученного кольца.

\begin{items}{-2}
\item Если кольцо $K$ было ассоциативным (коммутативным), то кольцо $K\s x$ тоже будет ассоциативным (коммутативным).
\item Если в $K$ нет делителей нуля, то их нет и в $K\s x$.
\end{items}

\begin{note}
Эти свойства, очевидно, выполнены и в обратную сторону, поскольку $K$ является подкольцом в $K\s x$.
\end{note}

Далее мы будем считать, что $K$\т ассоциативное коммутативное кольцо с $1$ и без делителей нуля, то есть область целостности.
Выясним, какие элементы в кольце $K\s x$ обратимы.

\begin{df}
Если $A(x) \cdot B(x) = 1$, то говорят, что $B = A^{-1}$.
\end{df}

\begin{stm}
Ряд $A(x)$ обратим тогда и только тогда, когда $A(0)$ обратим в кольце $K$.
\end{stm}
\begin{proof}
Попробуем найти коэффициенты ряда $B(x) := A^{-1}(x)$ в явном виде.
Для этого приравняем коэффициенты:
\eqn{
\begin{aligned}
a_0 b_0 &= 1,\\
a_0b_1 + a_1b_0 &= 0,\\
&\dots\\
a_0 b_k \spl a_k b_0 &= 0,
\end{aligned}}

Ясно, что эта система разрешима тогда и только тогда, когда $a_0$ обратим в кольце $K$\т в этом случае
все коэффициенты последовательно выражаются через предыдущие:
\eqn{b_k = -a_0^{-1}(a_1b_{k-1}\spl a_k b_0),}
что и требовалось доказать.
\end{proof}

\begin{imp}
Если $K$\т поле, то обратимые элементы\т это ряды с ненулевым свободным членом.
\end{imp}

\begin{ex}
\eqn{(1+x+x^2+x^3+\ldots) = \frac{1}{1-x}.}
Заметим, что это чисто алгебраический результат. Никаких геометрических прогрессий мы здесь не суммируем.
\end{ex}

\begin{df}
Пусть дана последовательность $\hc{a_i}$. Производящей функцией этой последовательности называется
формальный ряд
\eqn{\sumizi a_i x^i.}
\end{df}

\textbf{Биномиальные коэффициенты.}
Пусть $x_1\sco x_n$\т формальные объекты.
Пусть $X = \hc{x_1\sco x_n}$. Рассмотрим всевозможные $k$\д элементные подмножества в множестве $X$.
Это всевозможные выборки $x_{i_1}\sco x_{i_k}$. Выпишем соответствующую производящую функцию:
\eqn{(1+x_1)\cdot(1+x_2)\sd(1+x_n) = \sumkzn \sums{\substack{S \subs X\\|S| = k}} \prods{x_j\in S} x_j.}
Что такое произвольное подмножество в $X$? Всякий элемент $x_k$ либо входит в него (этому соответствует слагаемое $x_k$
в соответствующем множителе), либо не входит (этому соответствует слагаемое $1$).
А теперь, поскольку нас интересует только количество $k$\д элементных подмножеств, можно подставить $x_i =x$ и получить
искомую производящую функцию:
\eqn{(1+x)^n = \sumkzn \Cb_n^k x^k.}

\textbf{Сочетания с повторениями.}
В этом случае каждый элемент может встречаться уже не один раз, а сколько угодно.
Значит, каждая скобка должна содержать формальную сумму всех степеней переменной $x_i$:
\eqn{(1+x_1+x_1^2+x_1^3+\ldots)\cdot(1+x_2+x_2^2+x_2^3+\ldots)\sd(1+x_n+x_n^2+x_n^3+\ldots)=
\sumkzi \sums{\substack{s_i \ge 0\\s_1\spl s_n=k}} x_i^{s_1}\sd x_n^{s_n}}
После подстановки $x_i = x$ получаем производящую функцию:
\eqn{(1+x+x^2+x^3+\dots)^n = \sumkzi \CC_n^k x^k.}
Теперь заметим, что у нас слева стоит произведение формальных рядов.
А их мы уже умеем сворачивать. Получаем
\eqn{(1-x)^{-n} = \sumkzi \CC_n^k x^k.}
Теперь получим формулу бинома Ньютона для отрицательных степеней:
\eqn{(1-\al x)^{-n} = \sumkzi \CC_n^k \al^k x^k.}

Отметим одно полезное свойство числа сочетаний:
\eqn{\CC_n^k = \Cb_{n+k-1}^{n-1} = \frac{(k+n-1)\sd (k+1)}{(n-1)!},}
то есть это многочлен по переменной $k$ степени $n-1$.

Теперь рассмотрим ещё один содержательный пример, в котором используются производящие функции.
Рассмотрим сначала такую простенькую задачу. Найти число $u_n$ последовательностей длины $n$,
в которых нет двух нулей, стоящих подряд. Идея решения состоит в том, чтобы выразить $u_n$
через числа $u_j$ с меньшими номерами (написать рекуррентное соотношение).
Попробуем сделать это: ясно, что $u_0 = 1$ и $u_1 = 2$. Далее, если у нас есть последовательность $w$ длины~$n$,
то возможны два случая:
\eqn{w = 1\ub{{*}\dots{*}}_{n-1}{}, \quad w = 01\ub{{*}\dots{*}}_{n-2}.}
На месте звёздочек могут стоять любые допустимые последовательности длин $n-1$ и $n-2$ соответственно.
Таким образом, $u_n = u_{n-1} + u_{n-2}$. Мы получили линейное рекуррентное соотношение.
Давайте выясним, какой общий вид могут иметь решения линейных рекуррентных соотношений.

\begin{theorem}
Пусть $K = \Cbb$. Пусть $u_0, u_1, u_2\etc$\т искомая последовательность.
Пусть задано рекуррентное соотношение
\eqn{u_{n+r} = a_1u_{n+r-1}\spl a_r u_n, \quad a_r \neq 0}
и заданы начальные условия $u_0\sco u_{r-1}$.
Тогда общий член последовательности $u_n$ выражается в виде многочлена степени строго меньше $r$:
\eqn{u_n = \suml{i=1}{s} P_i(n) \al_i^n.}
\end{theorem}
\begin{proof}
Рассмотрим производящую функцию этой последовательности:
\eqn{U(x) = \sumnzi u_nx^n.}
Рассмотрим многочлен
\eqn{G(x) := 1 - a_1x -a_2x^2-\ldots-a_rx^r.}
А теперь перемножим их:
\eqn{C(x) := G(x)\cdot U(x) = \sumnzi c_n x^n.}
Заметим, что
\eqn{c_{n+r} = u_{n+r} - a_1 u_{n+r-1}-\ldots-a_ru_n}
при всех $n \ge 0$. Но в силу имеющегося рекуррентного соотношения получаем, что все коэффициенты ряда,
начиная с $r$\д го, равны нулю. Значит, $C(x)$\т это просто многочлен степени не выше $r-1$.

Рассмотрим многочлен
\eqn{F(x) = x^r - a_1 x^{r-1}-\ldots- a_r = (x-\al_1)^{q_1}\sd (x-\al_s)^{q_s}, \quad \sum q_i = r.}
Легко видеть, что
\eqn{\label{eqn:g-polyRep}G(x) = (1-\al_1x)^{q_1}\sd (1-\al_sx)^{q_s}.}
В самом деле, из определения $G$ ясно, что $G(x) = x^rF\hr{\frac1x}$, но выписанное произведение~\eqref{eqn:g-polyRep}
тоже, очевидно, равно $x^r F\hr{\frac1x}$.

Далее, поскольку
\eqn{U(x) = \frac{C(x)}{G(x)} = \suml{i=0}{r-1} c_i x^i(1-\al_1x)^{-q_1}\sd(1-\al_sx)^{-q_s}.}
А теперь применяем формулу для бинома с отрицательными степенями:
\eqn{u_n = \suml{i=0}{\min(n,r-1)} \Br{c_i \sums{\substack{m_1\sco m_s \ge 0,\\ m_1\spl m_s = n-i}} \prodl{j=1}{s} \al_j^{m_j}\CC_{q_j}^{m_j}}.}
С другой стороны, вспомним теорему из анализа о разложении рациональных дробей в сумму простейших: $\deg C < \deg G$, поэтому
\eqn{U(x) = \frac{C(x)}{G(x)} = \frac{C(x)}{(1-\al_1x)^{q_1}\sd (1-\al_sx)^{q_s}} = \suml{i=1}{s} \suml{k=1}{q_i} \frac{\be_{ik}}{(1-\al_i x)^k}.}
Разлагаем в ряды наши <<прогрессии>> и приравниваем коэффициенты:
\eqn{U(x) = \suml{i=1}{s} \suml{k=1}{q_i} \suml{n=0}{\bes} \be_{ik} \CC_k^n \al_i^n x^n = \suml{i=1}{s} \suml{n=0}{\bes} P_i(n)\al_i^n x^n.}
Здесь $\deg P_i \le q_i -1 \le r-1$. Окончательно получаем
\eqn{u_n = \suml{i=1}{s} P_i(n) \al_i^n,}
что и требовалось доказать.
\end{proof}


\subsubsection{Формальное дифференцирование}

Чтобы не напрягать себя лишними проблемами, будем далее считать кольцо $K$ ассоциативным коммутативным кольцом,
потому что ничего другого нам, по сути, и не потребуется.

\begin{df}
Пусть дан формальный ряд $A(x)$. Его формальной производной назовём ряд
\eqn{\Ds A(x) := \sumnzi (n+1)a_{n+1}x^n.}
\end{df}

Очевидно, что производная\т это линейная операция.

Несложно проверить, что имеет место формула Лейбница
\eqn{\Ds(A\cdot B) = \Ds A\cdot B + A \cdot \Ds B.}

Кроме того, если ряды $A$ и $B$ обратимы, то имеет место формула (правило логарифмического дифференцирования)
\eqn{\frac{\Ds(A\cdot B)}{A\cdot B} = \frac{\Ds A}{A} + \frac{\Ds B}{B}.}
Этот результат немедленно следует из формулы Лейбница.

Далее, эта формула без труда обобщается на произвольное количество слагаемых:
\eqn{\frac{\Ds (A_1\sd A_n)}{A_1\sd A_n} = \frac{\Ds A_1}{A_1}\spl \frac{\Ds A_n}{A_n}.}

Из формулы Лейбница легко выводится ещё одно полезное свойство:
\eqn{\Ds(A^n) = n A^{n-1} \Ds A.}


\subsubsection{Сходимость в пространстве формальных рядов}

Верхние индексы будут обозначать не степень, а номер.

\begin{df}
Рассмотрим последовательность рядов $\hc{A^i} \subs K\s x$.
Будем говорить, что $A^i \ra A$, если для всякого $n$ найдётся $\de(n)$ такое что
при всех $i \ge \de(n)$ имеем $a_n^i = a_n$. Иначе говоря, начиная с некоторого номера,
$n$\д й коэффициент предела стабилизируется.
\end{df}

\begin{df}
Будем говорить, что формальный ряд, составленный из рядов, сходится, если сходится последовательность его частичных сумм.
\end{df}

\begin{ex}
Рассмотрим ряды $A^i(x) := a_i x^i$. Тогда $\sum A^i(x) = A(x) = \sumizi a_i x^i$.
\end{ex}

\begin{df}
Через $\deg^* A$ будем обозначать номер минимального ненулевого коэффициента ряда $A$.
\end{df}

\begin{stm}[Критерий сходимости]
Ряд $\suml{j=0}{\bes} A^j(x)$ сходится тогда и только тогда, когда
\eqn{\deg^*A^j \ra \bes, \quad  j \ra \bes.}
\end{stm}
\begin{proof}
Очевидно.
\end{proof}

\begin{df}
Пусть ряды $B^j$ таковы, что $B^j(0) = 0$. Будем говорить, что $B(x) = \prodl{j=1}{\bes} \br{1 + B^j(x)}$,
если последовательность частных произведений
\eqn{\prodl{j=1}{i} \br{1 + B^j(x)}}
сходится к ряду $B$.
\end{df}

\begin{stm}
Бесконечное произведение
\eqn{\prodl{j=1}{\bes} \br{1 + B^j(x)}}
сходится тогда и только тогда, когда $\deg^* B^j \ra \bes$ при $j \ra \bes$.
\end{stm}
\begin{proof}
Очевидно.
\end{proof}

Эти свойства сходимости позволяют беспрепятственно перенести операцию дифференцирования на ряды
и произведения. Так, для сходящихся рядов имеет место свойство:
\eqn{\Ds \suml{j=1}{\bes} A^j = \suml{j=1}{\bes}\Ds A^j,}
а для сходящихся произведений\т формула
\eqn{\label{eqn:diffProd}\frac{\Ds \hr{\prodl{j=1}{\bes} \br{1 + B^j(x)}}}{\prodl{j=1}{\bes}\br{1 + B^j(x)}} =
\suml{j=1}{\bes}\frac{\Ds\br{1 + B^j(x)} }{1 + B^j(x)}.}

\subsubsection{Подсчёт количества неприводимых многочленов над $\F_p$}

Рассмотрим поле $\F_p$ и кольцо многочленов $\F_p[x]$.

\begin{df}
Многочлен называется приведённым, если его старший коэффициент равен~$1$.
\end{df}

Заметим, что произведение приведённых многочленов является приведённым многочленом.
Мы будем здесь рассматривать \textbf{только} приведённые многочлены, поэтому слово <<приведённый>>
часто будем опускать.

Через $\Rc_k$ будем обозначать множество всех приведённых многочленов степени~$k$.
Заметим, что $c_k := \hm{\Rc_k} = p^k$, потому что старший коэффициент равен~1, а все остальные $k$ коэффициентов
произвольны. Рассмотрим производящую функцию для последовательности $\hc{c_i}$:
\eqn{C_\Rc(x) := \suml{k=0}{\bes} c_k x^k = \suml{k=0}{\bes} p^k x^k = \frac{1}{1 - px}.}

Через $I_m$ будем обозначать количество неприводимых многочленов степени~$m$.
Вычислим нашу производящую функцию другим способом. Покажем, что
\eqn{C_\Rc(x) = \prodl{m=1}{\bes}(1+x^m+x^{2m}+x^{3m}+\dots)^{I_m}.}
Почему так? Всякий многочлен $P$ как\д то разлагается в произведение неприводимых, взятых
в некоторых степенях. У нас есть большой выбор неприводимых многочленов: $I_1$ видов веса~1,
$I_2$ видов веса~2 и так далее. Вес многочлена\т это просто его степень, то есть тот вклад,
который он вносит в степень многочлена $P$. Что касается видов, то многочленов каждого вида
у нас неограниченное количество (потому что, вообще говоря, степени сомножителей ничем не ограничены,
и потому в каждой скобке бесконечное количество слагаемых).
Множитель $m$\д го веса $k$\д го вида, взятый в степени $s$, соответствует одночлену $x^{ms}$ из скобки
с номером $k$ в $m$\д м множителе бесконечного произведения.

А теперь начинаем подсчёт. Сворачивая прогрессии и переходя к обратным рядам, получаем
\eqn{1 - px = \prodl{m=1}{\bes} (1 - x^m)^{I_m}.}
Продифференцируем это тождество, применяя формулу~\eqref{eqn:diffProd}:
\eqn{\frac{-p}{1 - px} = \suml{m=1}{\bes} mI_m \frac{-x^{m-1}}{1-x^m}.}
Умножим равенство на $x$:
\eqn{\frac{-px}{1 - px} = \suml{m=1}{\bes} mI_m \frac{-x^m}{1-x^m}.}
Выделяя целую часть в дробях, получаем
\eqn{1 - \frac{1}{1 - px} = \suml{m=1}{\bes} mI_m \hr{1 - \frac{1}{1-x^m}}.}
Раскатывая слагаемые в левой и правой части в прогрессии, получаем
\eqn{\suml{k=1}{\bes} p^k x^k = \suml{m=1}{\bes} mI_m \hr{x^m + x^{2m}+x^{3m}+\dots}.}
Приравнивая коэффициенты при подобных членах, получаем
\eqn{\label{eqn:polynoms}p^k = \sums{m|k} m I_m.}

Выведем сначала несколько простых следствий.

\pt{1} Без всяких формул ясно, что $I_k \ge 0$.

\pt{2} Ясно, что $I_1 = p$ (это многочлены вида $x + a$, $a = 0\sco p-1$).

\pt{3} Из \pt2 и \eqref{eqn:polynoms} сразу следует, что при $k \ge 2$ имеем $I_k \le \frac{p^k-p}{k} < \frac{p^k}{k}$.

\pt{4} Заметим, что если $k$\т простое число, то слагаемых в сумме всего два, поэтому $I_k = \frac{p^k-p}{k}$.

\pt{5} Получим оценку снизу для чисел $I_k$:
\eqn{p^k = k I_k + \sums{\substack{m|k\\ m < k}} mI_m \stackrel{!}{<} kI_k + \suml{m=0}{k/2}p^m < kI_k + p^{k/2+1}.}
Здесь переход <<!>> следует из оценки, полученной в \pt3. Стало быть,
\eqn{I_k > \frac{p^k-p^{k/2+1}}{k}.}

\pt{6} Из неравенства, полученного в \pt5, следует, что $I_k > 0$, то есть существуют неприводимые многочлены
\textbf{любой} степени.

\begin{note}
В курсе алгебры обычно доказывается, что над конечными полями существуют
неприводимые многочлены сколь угодно высокой степени. Мы получили некоторое усиление этого утверждения,
правда, не для всех конечных полей, а только для полей $\F_p$.
\end{note}

Мы ещё получим явную формулу для вычисления $I_k$, но для этого нам потребуется
одна формула, очень полезная в борьбе с производящими функциями.

\subsubsection{Формула обращения Мёбиуса}

Пусть $f,g\cln \N \ra \R$.

\begin{df}
Пусть $n = p_1^{m_1}\sd p_k^{m_k}$\т разложение числа $n$ на простые множители.
Функция
\eqn{\mu(n) := \case{1,&n=1,\\ (-1)^k, & m_1=\dots=m_k=1,\\ 0 &\text{иначе}.}}
называется функцией Мебиуса.
\end{df}

\begin{lemma}
\eqn{\sums{d|n} \mu(d) = \case{1,&n=1,\\0 &\text{иначе.}}}
\end{lemma}
\begin{proof}
При $n=1$ доказывать нечего. Пусть теперь $n = p_1^{m_1}\sd p_k^{m_k}$,
а $\wh n = p_1\sd p_k$. Тогда
\eqn{\sums{d|n} \mu(d) = \sums{d|\wh n} \mu(d) + \sums{\substack{d|n\\ d\nmid \wh n}} \mu(d).}
Вторая сумма равна нулю, потому что если $d|n$ и $d \nmid \wh n$, то у $d$ есть делители в степенях, больших~$1$.
А первая сумма соответствует неповторяющимся простым делителям. Количество слагаемых для $s$ делителей, очевидно,
равно $\Cb_k^s$. Значит,
\eqn{\sums{d|\wh n} \mu(d) = 1 - \Cb_k^1 + \Cb_k^2 -\Cb_k^3+\dots= (1-1)^k = 0.}
Итак, обе суммы в этом случае равны нулю, и лемма доказана.
\end{proof}


\begin{theorem}[Формула обращения Мёбиуса]
Если для всех $n$ выполнено равенство
\eqn{f(n) = \sums{d|n} g(d),}
то
\eqn{g(n) = \sums{d|n} \mu(d) f\hr{\frac nd}.}
\end{theorem}
\begin{proof}
Для всякого делителя $d$ числа $n$ имеем
\eqn{f\hr{\frac nd} = \sums{\wh d|\frac{n}{d}} g(\wh d).}
Отсюда
\eqn{\sums{d|n} \mu(d) f\hr{\frac nd} = \sums{d|n} \mu(d) \sums{\wh d|\frac{n}{d}} g(\wh d)=
\sums{d,\wh d\cln d\wh d|n} \mu(d) g(\wh d) = \sums{\wh d|n} \sums{d|\frac{n}{\wh d}} \mu(d) g(\wh d)=
\sums{\wh d|n} g(\wh d) \sums{d|\frac{n}{\wh d}} \mu(d) = g(n),}
потому что в силу леммы выживет только то слагаемое, для которого $\frac{n}{\wh d} = 1$, то есть когда $n = \wh d$.
\end{proof}

\begin{imp}[Формула для количества приведённых неприводимых многочленов]
\eqn{I_k = \frac{1}{k} \sums{m|k} \mu(m) p^{k/m}.}
\end{imp}
\begin{proof}
В предыдущем разделе мы установили формулу
\eqn{p^k = \sums{m|k} m I_m.}
Применим формулу обращения к функциям $f(k) = p^k$ и $g(k) =  k I_k$.
Получим
\eqn{kI_k = \sums{m|k} \mu(m) p^{k/m},}
и осталось только разделить это равенство на~$k$.
\end{proof}

\subsubsection{Тождества Ньютона}

Сейчас мы применим технику работы со степенными рядами над кольцом $K[\al_1\sco \al_n]$, где $K$\т поле.
Этот страшный объект обозначается, ясное дело, $K[\al_1\sco \al_n]\s x$.

Напомним, что многочлен $f \in K[\al_1\sco \al_n]$ называется симметрическим,
если он инвариантен относительно любых перестановок его переменных.

Определим степенные суммы: $S_k := \al_1^k\spl \al_n^k$.
Напомним, что элементарные симметрические многочлены от $n$ переменных имеют вид
\eqn{\begin{aligned}
\si_1 &= - (\al_1\spl \al_n),\\
\si_2 &=   \al_1\al_2 + \al_1\al_3+\dots,\\
&\dots\\
\si_k &= (-1)^k\sums{i_1\sco i_k} \al_{i_1}\sd \al_{i_k},\\
&\dots\\
\si_n &= (-1)^n\al_1\sd \al_n.
\end{aligned}}

Рассмотрим
\eqn{S(x) = \suml{k=1}{\bes} S_i x^i.}
Рассмотрим многочлен
\eqn{\si(x) = (1-\al_1 x)(1-\al_2 x) \sd (1-\al_n x) = 1+\suml{k=1}{n}\si_k x^k.}
Применим формулу логарифмического дифференцирования:
\eqn{\frac{\Ds \si(x)}{\si(x)} = \suml{k=1}{n} \frac{\Ds(1-\al_k x)}{1-\al_k x} = \suml{k=1}{n} \frac{-\al_k}{1-\al_k x}.}
Домножая на $x$ это равенство, получаем
\eqn{\label{eqn:newtonLeft}\frac{x \Ds \si(x)}{\si(x)} = \suml{k=1}{n} \hr{1 - \frac{1}{1- \al_k x}}.}
Мы знаем, что
\eqn{\frac1{1-\al_p x} = 1+\al_px + \al_p^2x^2+\al_p^3 x^3+\dots,}
поэтому
\eqn{1-\frac1{1-\al_p x} = -(\al_px + \al_p^2x^2+\al_p^3 x^3+\dots),}
откуда
\eqn{\suml{k=1}{n} \hr{1 - \frac{1}{1- \al_k x}} = -\bs{(\al_1\spl \al_n)x + (\al_1^2 \spl \al_n^2)x^2 +\ldots} = -S(x).}
Комбинируя эту формулу с формулой~\eqref{eqn:newtonLeft}, получаем, что
\eqn{S(x)\si(x) + x \Ds \si(x) = 0.}
Но продифференцировать многочлен $\si(x)$ очень легко:
\eqn{x\Ds \si(x) = \suml{k=1}{n} k\si_k x^k,}
и окончательно получаем тождество
\eqn{S(x)\si(x) = \suml{k=1}{n} k\si_k x^k.}
Приравнивая коэффициенты при степенях $x$, получаем формулы
\eqn{
\begin{aligned}
0&=S_1+\si_1,\\
0&=S_2+S_1\si_1+2\si_2,\\
0&=S_3+S_2\si_1+S_1\si_2+3\si_3,\\
&\dots\\
0&=S_n+S_{n-1}\si_1+S_{n-2}\si_2\spl  S_1\si_{n-1} + n\si_n,\\
&\dots\\
0 &= S_{n+i} + S_{n+i-1}\si_1 \spl S_i \si_n.
\end{aligned}}

Эти соотношения называются формулами Ньютона.

\begin{imp}
В случае, если $\Char K = 0$, многочлены $\si_i$ выражаются через степенные суммы.
\end{imp}

\begin{imp}
Всякий симметрический многочлен однозначно выражается через степенные суммы.
\end{imp}

\subsubsection{Что ещё можно делать со степенными рядами?}

Так вот, степенные ряды так и тянет подставить один в другой.
Разберёмся, когда это можно делать.

Пусть у нас есть ряд $A(x)$, и мы хотим подставить в него ряд $B(x)$. Ясно,
что если $B(0) \neq0$, то всё плохо: нулевой коэффициент результирующего ряда
является бесконечной суммой, что не есть хорошо. Поймём теперь, почему в случае,
когда $B(0) = 0$, всё будет хорошо.

Действительно, если $B(0) = 0$, то $\deg^*B(x)^n \ge n \ra \bes$ при $n \ra \bes$,
поэтому со сходимостью ряда
\eqn{A\br{B(x)} = \suml{n=0}{\bes} a_n B(x)^n}
проблем не будет.

\begin{ex}
В качестве примера рассмотрим последовательность Фибоначчи\ldots
%, определяемую рекуррентным
%соотношением $u_n = u_{n-1} + u_{n-2}$.
%Харак
\end{ex}


\subsubsection{Принцип включений и исключений}

Пусть имеются объекты $x_1\sco x_N$ и свойства $p_1\sco p_n$. Через $E(m)$ будем обозначать число объектов,
обладающих ровно $m$ свойствами, а через $w(p_1\sco p_k)$\т число объектов, обладающих свойствами
$p_1\sco p_k$. Положим
\eqn{W(k) := \sums{(i_1\sco i_k)}w(p_{i_1}\sco p_{i_k}).}

\begin{stm}Имеет место формула для числа объектов, не обладающих никаким свойством:
\eqn{E(0) = N - W(1)+W(2)-W(3)\spl (-1)^nW(n).}
\end{stm}
\begin{proof}
Рассмотрим два случая.
\pt1 Пусть $x_1$ не обладает никаким свойством. Тогда в левую часть формулы он добавит единицу.
А справа будем считать, что его единица входит в число $N$.
\pt2 Пусть $x_1$ обладает свойствами $p_{i_1}\sco p_{i_k}$. Тогда вклад в левую часть есть 0. А в правую\т
$1 - \Cb^1_k + \Cb^2_k \spl  (-1)^k\Cb^k_k = (1-1)^k=0$.
\end{proof}

\section{Кодирование}

\subsection{Общая теория кодирования и сжатия информации}

\subsubsection{Схемы кодирования. Коды с однозначным декодированием}

Пусть заданы два алфавита $A=\hc{a_1\sco a_r}$ и $B=\hc{b_1\sco b_q}$.

\begin{df}
Слово в каком\д либо алфавите\т это конечный упорядоченный набор символов этого алфавита.
Множество всех слов алфавита $A$ мы будем обозначать $A^*$.
\end{df}

\begin{df}
\emph{Схема кодирования}\т это любое отображение $\ph\cln A\ra B^*$,
$\ph\cln a_i \mapsto B_i$.
Образ символа при таком отображении будем называть кодом этого символа.
\end{df}

Такое отображение очевидным образом распространяется на множество всех
слов над алфавитом $A$:
\eqn{a_{i_1}\ldots a_{i_s} \mapsto B_{i_1}\ldots B_{i_s}.}

\begin{ex} $A=\hc{a_1, a_2, a_3}, B=\hc{0, 1}$. Схему кодирования
зададим следующим образом:
\eqn{a_1 \mapsto 01, \quad a_2 \mapsto 010, \quad a_3 \mapsto 101.}
Исходному слову $a_1a_1a_1$ будет соответствовать \emph{кодовое
слово} $010101$.
\end{ex}

\begin{df}
Будем говорить, что некоторая схема кодирования допускает
\emph{однозначное декодирование}, если кодовые слова (то есть результаты
кодирования) различны для любых несовпадающих кодируемых наборов.
\end{df}

Нетрудно заметить, что схема кодирования в предыдущем примере
не допускает однозначного декодирования, так как кодовое слово $010101$
соответствует одновременно двум наборам\т $a_1a_1a_1$ и $a_2a_3$.

\subsubsection{Неприводимые слова}

\begin{df}
\emph{Префиксной} называют такую схему кодирования, в
которой код ни одного из символов входного алфавита не является началом
для кода другого символа.
\end{df}

\begin{note}
Это условие является достаточным для однозначности декодирования, но не
необходимым. В качестве примера можно рассмотреть схему $a\mapsto 0$, $b \mapsto 01$.
Ясно, что это не префиксный код, но тем не менее декодирование однозначно.
\end{note}

\begin{df}
Слово, допускающее неоднозначное декодирование, называют
\emph{неприводимым}, если при удалении из него каких\д либо символов
полученное слово либо не является кодовым (то есть не допускает
декодирования вообще), либо допускает только однозначное декодирование.
\end{df}

Очевидно, что любой код, допускающий неоднозначное декодирование,
содержит неприводимые слова.

\begin{df}
Рассмотрим некоторое кодовое слово $b_1\ldots b_m$,
допускающее неоднозначное декодирование. Схематически это можно
изобразить следующим образом:
\cpic{6}{WordsEx}{Примеры слов}
Рассмотрим разбиение, полученное объединением верхнего и нижнего разбиений,
получим набор \emph{отрезков}. Если отрезок одного декодирования целиком содержится в некотором
отрезке другого (как $a_{j_6}$ и $a_{j_8}$ на нашей схеме), его
называют \emph{отрезком первого рода}, иначе, то есть если он является
началом отрезка при одном декодировании и концом при другом (как
пересечение отрезков $a_{i_4}$ и $a_{j_5}$ на рисунке)\т
\emph{отрезком второго рода}.
\end{df}

\begin{lemma}[О неприводимом слове]
В неприводимом слове все отрезки второго рода различны.
\end{lemma}

\begin{proof}Предположим противное: пусть нашлось два одинаковых отрезка
второго рода. Имеются четыре возможности их расположения:
\cpic{7}{WordsFourCases}{Возможные расположения верхних и нижних слов}
Разберем случай \emph{а)}, а для остальных случаев рассуждения аналогичны.
Совпадающие отрезки второго рода выделены штриховкой.
Удалим из слова все символы от начала первого отрезка до начала второго, и
<<склеим>> оставшиеся слова. Полученное таким образом слово также
будет допускать неоднозначное декодирование, а это противоречит
предположению о том, что исходное слово было неприводимым.
\end{proof}

\subsubsection{Проверка однозначности декодирования}

Мы хотим получить алгоритм проверки однозначности декодирования.
Именно, эта процедура будет выглядеть примерно так: проверяем однозначность
декодирования кодов, полученных из слов алфавита $A$ длины не более $N$, где $N$ зависит только от схемы кодирования,
и если это так, то заключаем, что и вся схема однозначна.

Рассмотрим следующую схему кодирования: исходный алфавит
$A=\hc{a_1\sco a_r}$, конечный алфавит $B$, состоящий из $q$ символов,
причем каждому символу $a_i \in A$ ставится в соответствие слово $B_i \in B^*$
длины $l_i$. Обозначим $l := l_1\spl l_r$.

Ясно, что нужно проверять только неприводимые слова. Сейчас мы покажем, что
длина неприводимого слова ограничена константой. Её\д то и возьмём в качестве
числа~$N$.

Зафиксируем некоторое слово и его код, и мы хотим выяснить, может ли этот
код быть неприводимым словом. Вначале убедимся, что оно допускает по
крайней мере два декодирования. Потом выпишем оба декодирования, как
на рис.~\picref{WordsEx}.

Под кодовым словом (или просто словом) будем понимать код символа. Посчитаем
максимальное число кодовых слов одного декодирования, которые одновременно попадают внутрь некоторого слова
другого декодирования (см.~рис.~\picref{WordsMaxInner}) \cpic{8}{WordsMaxInner}{Слов\'а внутри другого сл\'ова}.
Обозначим эту величину через~$w$.

\begin{stm}
Максимальная длина самого короткого слова в алфавите~$A$, порождающего (при указанной выше схеме кодирования)
неприводимое слово над алфавитом $B$, не превосходит величины \eqn{N = \frac{(1+l-r)(w+1)}{2}.}
\end{stm}
\begin{proof}Рассмотрим первое \emph{длинное} (не содержащееся ни в каком
другом) слово. Все остальные длинные слова начинаются с отрезков
второго рода. Обозначим число длинных слов через $R$, а число
отрезков второго рода\т через $k$. Получим $R=1+k$.
Общее число слов, лежащих внутри других, не превосходит $Rw$, а
число не лежащих внутри (то есть длинных)\т в точности равно $R$. Значит, всего не более $Rw+R=R(w+1)=(1+k)(w+1)$
слов. Осталось оценить $k$. Заметим, что любой отрезок второго рода является
началом некоторого длинного слова.
Сколько может быть <<начал>>? Слово $B_i$ длины $l_i$ имеет $l_i-1$ начало.
Если рассматриваемое декодируемое слово неприводимо, все
отрезки второго рода должны быть различны, значит,
\eqn{k\le \suml{i=1}{r} (l_i-1)=l-r,}
откуда получаем $N\le(1+l-r)(w+1)$. Здесь $N=N_1+N_2$\т число слов
в обоих декодированиях. Осталось заметить, что
\eqn{\min(N_1, N_2)\le\frac{N_1+N_2}{2} = \frac{N}{2},}
и мы приходим к требуемой оценке.
\end{proof}

%Итак, чтобы выяснить, является ли допускает ли кодирование
%неоднозначное декодирование, достаточно рассмотреть коды слов над
%алфавитом $A$ с длиной, не превосходящей $\frac{(1+l-r)(w+1)}{2}$.
%Установим еще один критерий однозначности.

\subsubsection{Неравенство Мак\д Миллана}

Напомним, что мы обозначаем через $q$ количество букв в алфавите~$B$.

\begin{stm}[Неравенство Мак\д Миллана]
Если кодирование допускает только однозначное декодирование, то
\eqn{\label{eqn:mcMillan}
\frac{1}{q^{l_1}}\spl \frac{1}{q^{l_r}}\le1.}
\end{stm}

\begin{proof}
Обозначим $l:=\maxl{i}l_i$. Пусть $Q(n,t)$\т
число кодовых слов длины $t$, которые являются образами
слов длины~$n$ (вполне возможно, что какие\д то $Q(n,t)$ равны нулю). Рассмотрим
\eqn{\hr{\frac{1}{q^{l_1}}\spl\frac{1}{q^{l_r}}}^n=
\sums{(i_1\sco i_n)}\frac{1}{q^{l_{i_1}}\sd q^{l_{i_n}}}\stackrel{!}{=}
\suml{t=1}{ln}\frac{Q(n, t)}{q^t}.}
Переход, отмеченный <<!>> следует в точности из того, что схема однозначно декодируется,
и потому имеется инъективное соответствие
\eqn{(i_1\sco i_n) \mapsto a_{i_1}\ldots a_{i_n} \mapsto B_{i_1}\ldots B_{i_n}.}
Всего имеется $q^t$ слов длины $t$, поэтому во всяком случае $Q(n, t)\le q^t$, следовательно
\eqn{\hr{\frac{1}{q^{l_1}}\spl\frac{1}{q^{l_r}}}^n\le ln,}
откуда
\eqn{\frac{1}{q^{l_1}}\spl\frac{1}{q^{l_r}}\le \sqrt[n]{ln}.}
Переходя к пределу при $n \ra \bes$, получаем неравенство~\eqref{eqn:mcMillan}.
\end{proof}

\begin{theorem}
Для любой схемы кодирования $\Bc$, имеющей однозначное
декодирование, найдется префиксная схема $\wh\Bc$, имеющая тот же
набор длин слов, что и схема $\Bc$.
\end{theorem}
\begin{proof}
Упорядочим по возрастанию длины~$l_i$ кодовых слов из $\Bc$, то есть будем
считать, что $l_1\sle l_r$. Пусть набор $\hc{\la_i}$\т это отсортированный по возрастанию набор
$\hc{l_i}$, из которого выкинуты дубликаты (и таким образом, $\la_1\sles \la_t$), а $\nu_i$\т количество
дубликатов длины $\la_i$.

В этих обозначениях (собирая одинаковые слагаемые) неравенство Мак\д Миллана переписывается следующим образом:
\eqn{\label{eqn:corMcMillan}\frac{\nu_1}{q^{\la_1}}+\ldots+\frac{\nu_r}{q^{\la_r}}\le1.}

Будем строить новую схему $\wh \Bc$ последовательно. Для начала включим
в неё $\nu_1$ различных слов длины $\la_1$. Это не противоречит её префиксности.
В силу условия оптимальности, в ней должно быть ещё $\nu_2$ слов длины $\la_2$.
Чтобы префиксность не нарушилась, мы можем брать не любые слова длины
$\la_2$, коих всего имеется $q^{\la_2}$ штук, а только те, которые не начинаются с уже выбранных.
Таких имеется $\nu_1\cdot q^{\la_2 - \la_1}$ штук, потому что каждое из первых $\nu_1$ кодовых
слов можно расширить до слова длины $\la_2$ именно $q^{\la_2-\la_1}$ способами.
Таким образом, остаётся не более $q^{\la_2} - \nu_1 \cdot q^{\la_2-\la_1}$ кодовых слов.
Но их хватит, потому что их нужно $\nu_2$ штук,
то есть должно быть выполнено неравенство $\nu_2 \le q^{\la_2} - \nu_1\cdot q^{\la_2 - \la_1}$.
А его можно переписать по\д другому:
\eqn{\frac{\nu_1}{q^{\la_1}} + \frac{\nu_2}{q^{\la_2}} \le 1.}
А это уже прямое следствие неравенства~\eqref{eqn:corMcMillan}.
Значит, нужное количество слов длины $\la_2$ тоже найдётся. Далее,
при выборе слов длины $\la_3$ нам запрещено $\nu_1\cdot q^{\la_3-\la_1} + \nu_2\cdot q^{\la_3-\la_2}$ слов,
но, опять\д таки в силу неравенства~\eqref{eqn:corMcMillan} мы их найдём, и так далее.

В итоге мы получи префиксный код $\wh \Bc$, у которого набор длин кодовых слов тот же.
\end{proof}

\begin{imp}\label{imp:alwaysPrefix}
При рассмотрении любой схемы кодирования всегда можно считать, что она префиксная.
\end{imp}

\subsubsection{Оптимальные коды. Код Хаффмана}

Как и раньше, рассматриваем следующую схему кодирования: исходный
алфавит $A=\hc{a_1, \ldots , a_r}$, конечный алфавит $B$, состоящий
из $q$ символов, причем каждому символу $a_i$ ставится в
соответствие слово $B_i$ длины $l_i$.

Теперь наша цель\т построить в некотором смысле оптимальный код.
Пусть мы кодируем некоторый текст (последовательность символов исходного алфавита).
Ясно, что если какие\д то символы очень часто встречаются в этом тексте, то будет
хорошо, если кодовые слова, им соответствующие, будут иметь маленькую длину, и наоборот.
Будем считать, что нам известны вероятности~$p_i$ появления в тексте кодируемых символов~$a_i$.

\begin{df}
\emph{Стоимостью} схемы кодирования $\Bc$ назовём величину
\eqn{L(\Bc):=\suml{i=1}{r}p_il_i.}
\end{df}

Интуитивно ясно, что чем меньше <<стоит>> схема, тем она эффективнее.

Обозначим $l := \minl{i} l_i$. Из неравенства Мак\д Миллана следует, что $q^l\ge r$.

Рассмотрим равномерную схему кодирования, в которой все кодовые слова имеют одинаковую
длину (то~есть фактически просто занумеруем буквы исходного алфавита в $q$\д ичной системе счисления).
Ясно, что нам хватит длины $l = \hce{\log_qr}$. Такой код обозначим $\Bc_0$.
Этот код однозначно раскодируется, и, очевидно, $L(\Bc_0) = l$.

\begin{theorem}[О существовании оптимального кода]
Пусть $p:=\min p_i$. Если в коде $\Bc$ имеется
слово $B_j$ длины $l_j>\frac{l}{p}$, то $L(\Bc)>L(\Bc_0)$.
\end{theorem}
\begin{proof}
В самом деле, \eqn{L(\Bc)=\sum p_i l_i > p_j l_j > p_j \frac{l}{p} \ge l =L(\Bc_0).}
Таким образом, не имеет смысла рассматривать коды с длинами слов больше $\frac1p$, так как равномерный
код будет в этом случае оптимальнее. Но таких кодов (для данного алфавита) конечное число, а потому среди них
существует минимум.
\end{proof}

\begin{df}
Оптимальный код\т код с наименьшей стоимостью среди однозначно декодируемых.
\end{df}

Как уже отмечалось в следствии~\ref{imp:alwaysPrefix}, оптимальный код
можно считать префиксным.


\begin{lemma}\label{lem:ProbOrder}
Если $\Bc$\т оптимальный код, то в нём $l_i\le l_j$ при $p_i>p_j$.
\end{lemma}
\begin{proof}
Докажем от противного. Пусть в коде $\Bc$ нашлись $i$ и $j$, для которых имеем
$p_i>p_j$, но $l_i>l_j$. Построим код $\Bc'$ путём перестановки в
коде $\Bc$ слов $B_i$ и $B_j$, получим код с меньшей стоимостью. Противоречие.
\end{proof}

Далее будем считать, что $q=2$. Иначе говоря, будем рассматривать только двоичные коды,
и выходной алфавит будет состоять из двух символов: $B=\hc{0, 1}$.

\begin{lemma}
В оптимальном коде самое длинное слово не может быть единственным.
\end{lemma}
\begin{proof}
Допустим, что существует единственное максимальное слово.
Уберём из него последний символ. Код префиксный, следовательно
полученный код также будет однозначным и при этом более эффективным,
чем исходный. Противоречие.
\end{proof}

\begin{lemma}\label{lem:DiffLast}
В оптимальном коде среди слов максимальной длины найдутся
два, различающиеся только в последнем (самом правом) разряде.
\end{lemma}
\begin{proof}
Предположим, что все самые длинные слова
различаются не только в последнем разряде. Это означает, что путём
вычеркивания из самых длинных слов этого последнего разряда мы получим
однозначный код, который будет эффективнее предыдущего.
\end{proof}

Рассмотрим оптимальный код $\Bc$ и упорядочим вероятности $p_i$:
$p_1 \sge p_r$. В силу леммы~\ref{lem:ProbOrder} имеем
$l_1 \sle l_r$.

Пусть $p_i=q'+q''$, причем
$p_r\ge q'$, $p_r\ge q''$, и для определённости, $q'\ge q''$. Для алфавита $\wh A$ с
набором вероятностей $p_1\sge \wh{p_k} \sge p_r\ge q' \ge q''$ построим код
\eqn{\wh{\Bc}:=\bc{B_1\sco \wh{B_k}\sco B_r, \ol{B_k0}, \ol{B_k1}}.}
Здесь крышки в последовательности обозначают пропуск элемента,
а черта сверху показывает, что слово полученное склейкой нескольких слов.

\begin{theorem}
$\wh{\Bc}$ является оптимальным кодом для заданного набора вероятностей.
\end{theorem}
\begin{proof}
Будем доказывать от противного.
Прежде всего заметим, что
\eqn{
L(\wh{\Bc})=\sums{i\neq k}p_i l_i+q'(l_k+1)+q''(l_k+1)=
\sums{i\neq k}p_i l_i + (q'+q'')l_k + (q'+q'')=
\sums{i} p_i l_i +p_k=L(\Bc)+ p_k.}
Пусть $\wh\Cc$\т оптимальный код, отличный от $\wh\Bc$ и
более эффективный, то есть $L(\wh\Cc) < L(\wh\Bc)$.
Выделим в нём два самых длинных слова,
различающихся только в последнем разряде (такие найдутся в силу леммы~\ref{lem:DiffLast})
и обозначим их $C'$ и~$C''$. Можно считать,
что $C'=\ol{C0}$, $C''=\ol{C1}$. Восстановим по нему код
\eqn{\Cc:=\hc{C_1\sco C_{k-1}, C, C_{k+1}\sco C_r}}
для исходного набора вероятностей. Тогда, очевидно, $L(\wh\Cc)=L(\Cc)+p_k$.
Тогда
\eqn{L(\Cc) + p_k = L(\wh\Cc) < L(\wh\Bc) = L(\Bc) + p_k,}
откуда получаем, что $L(\Cc) < L(\Bc)$, что неверно, поскольку код $\Bc$ был оптимальным.
\end{proof}

Теперь ясно, как выглядит процесс построения оптимального кода. Упорядочиваем символы по
вероятности их появления в тексте (по убыванию). Далее берём два самых редких, складываем их вероятности,
и полученную сумму вставляем в упорядоченный набор вероятностей без двух последних элементов. Затем эту
процедуру повторяем, пока не придём к двум вероятностям. Им соответствуют коды $0$ и $1$.
А теперь идём назад: находим те две вероятности на предыдущем шаге, которые дали в сумме одну из вероятностей $p_i$,
им присваиваем коды $\ol{K0}$ и $\hc{K1}$ (добавляем 0 и 1 к уже имеющемуся коду $K$ вероятности $p_i$).
И так далее: находим на предыдущем шаге две вероятности, давшие в сумме одну из имеющихся на данном шаге
вероятностей, и приписываем к их кодам нуль и единицу. Остальные коды переносим в предыдущий шаг без изменений.

Набор кодовых слов для исходного набора вероятностей (то есть то, что получится после возвращения к первому шагу)
и есть \emph{код Хаффмана}.

\subsection{Коды с исправлением ошибок}

\subsubsection{Постановка задачи}

Пусть требуется передать по зашумлённому каналу связи некоторое
сообщение (конечный набор символов фиксированного алфавита). При
этом зашумлённость подразумевает возможность искажения некоторых
передаваемых символов. Мы будем передавать сообщение в
закодированном виде, при этом добавляя в него некоторую избыточную
информацию с тем чтобы адресат имел возможность правильно раскодировать наше
сообщение.

При этом мы будем считать, что в процессе передачи данных происходят
только ошибки замещения, то есть один или несколько символов сообщения
изменяются на какие\д то другие символы, но длина сообщения при этом не меняется.

\subsubsection{Коды Хемминга}

Определим схему кодирования для (двоичного) кода Хемминга, исправляющего одну ошибку.
Поскольку мы оперируем с двоичными разрядами, суммирование везде будет предполагаться
по модулю два.

Пусть требуется закодировать некоторое сообщение $a_1a_2\ldots a_l$,
где $a_i \in \B$.

Через $V_k$ обозначим набор индексов, имеющих в двоичной записи единицу в $k$\д м разряде.

Теперь будем строить кодовое слово $b_1b_2\ldots b_n$ по следующему
правилу. Вначале все разряды с номерами, не являющимися степенями двойки,
заполним символам кодируемого сообщения и назовём \emph{информационными}.
Разряды с номерами, являющимися степенью двойки, заполним так:
\eqn{
b_{2^k}:=\sums{m\neq 2^k, m\in V_k} b_m.}
Такие разряды называют \emph{контрольными}.
Таким образом, мы выбираем их так, чтобы сумма всех
разрядов с индексами из каждой последовательности $V_i$ была равна нулю,
потому что в каждом множестве $V_k$ находится ровно один контрольный разряд.
Несложно заметить, что число контрольных разрядов в кодовом слове длины $n$
будет равно $m$, где $2^{m-1}\le n < 2^m$. Следовательно, число
информационных разрядов равно $n-m$, а общее число наборов длины $n$
в коде Хемминга равно $2^{n-m}$, потому что мы имеем право заполнять только
информационные разряды, а контрольные уже однозначно определяются.


Пусть произошла ошибка в разряде $b_i$. Поскольку код двоичный,
то, чтобы исправить эту ошибку, достаточно знать только номер $i$.
Найдём числа $\ep_k = \sums{m\in V_k}b_m$.
Заметим, что $\ep_k=0$ тогда и только тогда, когда $i \in V_k$.
Иными словами, это означает, что последовательность $\ol{\ep_t\ldots \ep_0}$
есть не что иное, как двоичная запись числа $i$. Если мы получили нулевое число,
то ошибок нет.

\subsubsection{Свойства кодов, исправляющих ошибки}

\begin{df}
\emph{Расстоянием Хемминга} между двумя кодовыми
словами будем называть число различных разрядов в них. \emph{Минимальным
расстоянием} кода~$\Cc$ будем называть, соответственно, минимум таких
расстояний по всем парам слов из~$\Cc$.
\end{df}

\begin{df}
\emph{Весом Хемминга} кодового слова будем называть число
ненулевых символов в нём.
\end{df}

\begin{note}
Это определение работает не только для двоичных кодов, но и для кодов над $\Z_q$.
\end{note}


Сейчас мы выясним, что такое вообще двоичный код $\Cc$, который исправляет одну ошибку.
Пусть $\al, \be \in \Cc$.
Введём на булевом кубе, в который вложен наш код $\Cc$, метрику, задаваемую расстоянием Хемминга.
Шары радиуса~1 с центрами в точках $\al$ и $\be$ не должны пересекаться,
иначе возможна ситуация, когда искажённое слово попадёт в <<сферу влияния>> двух кодовых слов,
и будет неясно, к какому из двух слов его относить.

Пусть кодовые слова имеют длину $n$. Тогда шар радиуса~1 содержит $n+1$ точку.
Пусть $M = \hm{\Cc}$. Тогда получаем оценку $M(n+1) \le 2^n$,
откуда $M \le \frac{2^n}{n+1}$.

Пусть $2^{m-1} \le n < 2^m$. Тогда $2^m \le 2n$, и, как мы знаем,
код Хемминга имеет мощность $M = 2^{n-m}=\frac{2^n}{2^m}$.
Отсюда $M \ge \frac{2^n}{2n}$.

Рассмотрим случай, когда $2^m-1=n$, то есть $2^m=n+1$. Тогда верхняя и нижняя оценки для
числа $M$ просто совпадают, то есть код является \emph{плотным}.
Это означает, что имеется плотная упаковка $M$ шаров радиуса~1 в булев куб $\B^n$.

%\begin{stm}
%Код с обнаружением одной ошибки\т это такой код, в котором нет двух соседних наборов.
%\end{stm}
%\begin{proof}
%will be given later...
%\end{proof}



\subsubsection{Коды с исправлением нескольких ошибок}

Теперь представим себе, что может происходить не одна, а $r$ ошибок,
то есть какие\д то $r$ разрядов портятся. Тогда нужно рассматривать шары
радиуса $r$ с центрами в кодовых словах, и они тоже не должны пересекаться.
Пусть $S_r$\т объём шара радиуса $r$. Ясно, что
\eqn{S_r=\Cb^0_n + \Cb^1_n+\Cb^2_n\spl \Cb^r_n.}

\begin{imp}
Мощность кода, исправляющего $r$ ошибок, не превосходит величины $\frac{2^n}{S_r}$.
\end{imp}

Оценим снизу мощность кода $\Cc_r$, исправляющего $r$ ошибок.
Ясно, что если $\al, \be \in \B^n$, и $\rho(\al,\be) \ge 2r+1$, то шары с центрами
в точках $\al$ и $\be$ не пересекаются. Поэтому эти слова можно взять в качестве кодовых.
Тогда рассмотрим (тупой) алгоритм построения кода:
берём произвольную точку в $\B^n$, объявляем её кодовым словом и описываем вокруг неё шар радиуса $2r$.
Точки этого шара уже брать нельзя, а все остальные\т можно. Находим точку в кубе, которая не попала
в этот шар и повторяем процедуру. Ясно, что так заведомо можно сделать $\frac{2^n}{S_{2r}}$ раз,
поэтому нам гарантирована мощность кода
\eqn{M \ge \frac{2^n}{S_{2r}}.}

Имеется очевидная асимптотика $S_r \sim n^r$ при $n \ra \bes$, поэтому
получаем оценки, верные для всех достаточно больших $n$ при фиксированном $r$:
\eqn{С_1 \cdot \frac{2^n}{n^{2r}} \le M_r(n) \le C_2\cdot \frac{2^n}{n^r}.}

Пусть мы хотим передавать сообщения из $t$\д битных слов.
Тогда нам нужен код мощности $M_r \ge 2^t$.
Отсюда (и из оценки выше) получаем асимптотическое неравенство
\eqn{2^t \le C_1 \cdot \frac{2^n}{n^{2r}}.}
Положим $n := t + 2r\log_2 t + C$, где $C = \const$.
Тогда неравенство перепишется в виде:
\eqn{1 \le C_1 \cdot \frac{2^{t + 2r\log_2 t + C}}{n^{2r}\cdot 2^t} =
C_1\cdot \frac{t^{2r}\cdot 2^C}{n^{2r}} \sim C_1\cdot 2^C.}
Отсюда ясно, как подбирать константу $C$. Это нужно делать так, чтобы асимптотически
неравенство было выполнено.

Таким образом, мы видим, что <<прирост>> количества контрольных разрядов
сравнительно мал, а именно, линейно растёт по $r$ и логарифмически\т по $t$.

\subsubsection{Линейные коды}

При рассмотрении линейных кодов мы будем рассматривать в качестве выходного
и выходного алфавитов поле $\F_q$, где $q$\т простое число. Это поле обозначим
для краткости буквой~$K$.

Зафиксируем натуральные числа $n$ и $k <n$.
Рассмотрим линейный оператор $H\cln K^n \ra K^{n-k}$.
Матрицу этого оператора будем называть проверочной.

\begin{df}
Линейным кодом $V$ с проверочной матрицей $H$ называется ядро оператора $H$,
то есть
\eqn{V := \hc{x\in K^n\cln H x = 0}.}
\end{df}

Как мы знаем, ядро линейного оператора является линейным подпространством.
Поскольку $\dim \Ker H \bw+ \dim \Im H \bw= \dim K^n \bw= n$, получаем, что $\dim V \ge k$.

Мы будем использовать расстояние Хемминга, а под нормой вектора, соответственно,
понимать количество ненулевых координат в нём.

Число $n$ называется длиной кода $V$, число $k(V) := \dim V$\т размерностью кода,
а через $d(V)$ будем обозначать минимальное расстояние между элементами кода,
то есть
\eqn{d(V) := \minl{\substack{x,y\in V\\x \ne 0}} \rho(x,y) = \minl{\substack{x \in V\\ x \ne 0}} \hn{x}.}
Такой код мы будем называть $[n,k,d]$\д кодом.

\begin{note}
Вообще говоря, не следует путать числа $k$ и $k(V)$.
Однако, если нам повезло, и оператор $H$ имеет полный ранг (то есть $n-k$),
то $k = k(V)$, и его матрицу можно привести к виду $H = (A|I_{n-k})$,
где $I_{n-k}$\т единичная матрица.
\end{note}



Заметим, что если минимальное расстояние кода равно $d$, то он умеет исправлять $t:=\hs{\frac{d-1}{2}}$ ошибок,
потому что шары радиуса $t$ с центрами в кодовых словах не пересекаются.

Рассмотрим матрицу $G = (I_k|{-}A^t)$, тогда простая проверка показывает, что $HG^t = 0$.
Это тем более видно из того, что $G^t = \hr{\frac{I_k}{-A}}$.

\begin{df}
Матрица $G$ называется порождающей матрицей кода $V$.
\end{df}

Суть порождающей матрицы проста: $\Im G = \Ker H = V$.


Схема кодирования устроена следующим образом:
\eqn{u = (u_1\sco u_k) \xra{\text{код}} x = (x_1\sco x_n) \xra{\text{помехи}}
y = (y_1\sco y_n) \xra{\text{декод}} \wt u = (\wt u_1\sco \wt u_k).}
Из\д за возможных помех в канале связи, вообще говоря, $x \ne y$.
Кодирование происходит по схеме $x = G^t u$.
Проверка того, произошли ли ошибки, проводится с помощью матрицы $H$,
применяемой к полученному из канала связи вектору $y$.


\begin{theorem}
Пусть $H$\т проверочная матрица кода $V$. Минимальное расстояние $d(V)$ кода $V$
равно $d$ тогда и только тогда, когда любые $d-1$ столбцов матрицы $H$ линейно независимы,
и существует $d$ линейно зависимых столбцов.
\end{theorem}
\begin{proof}
Пусть $d(V) = d$. Тогда существует $x \in V$, такой что $\hn{x} = d$.
Пусть в векторе $x$ ненулевые числа стоят на местах $i_1\sco i_d$.
Пусть матрица $H$ состоит из столбцов $h_1\sco h_n$.
Поскольку $Hx = 0$, получаем, что
\eqn{x_{i_1}h_{i_1}\spl x_{i_d}h_{i_d} = 0.}
Это есть искомая нулевая линейная комбинация для столбцов $h_{i_1}\sco h_{i_d}$,
значит, они линейно зависимы. Теперь, если бы нашлись ${d-1}$ линейно зависимых
столбцов, то коэффициенты линейно зависимости образовали бы вектор веса $d-1$,
зануляющийся матрицей~$H$, что невозможно. Все наши рассуждения обратимы, поэтому
обратное тоже верно.
\end{proof}

\begin{imp}
Если в проверочной матрице любые $d-1$ столбцов линейно независимы, то $d(V) \ge d$.
%Если ранг проверочной матрицы не больше, чем $d$, то $d(V) \le d$.
\end{imp}

\begin{imp}[Граница Синглтона]
Имеет место неравенство $d(V) \le n-k+1$.
\end{imp}
\begin{proof}
Так как максимальное число линейно независимых столбцов равно рангу матрицы~$H$,
а ранг матрицы~$H$ никак не больше ${n-k}$, поэтому $d(V)-1 \le \rk H \le n-k$.
Отсюда сразу получаем доказываемое неравенство.
\end{proof}


\begin{df}
\emph{Синдром}\т это вектор $S := Hy$.
\end{df}

Если представить $y$ в виде $y = x + e$, где $e$\т вектор ошибок, то получаем $Hy = Hx + He = He$,
поскольку $x \bw\in V \bw= \Ker H$. Таким образом, ненулевые элементы синдрома\т это в точности те разряды,
в которых произошли ошибки.

\subsubsection{Код Хемминга как пример линейного кода}

Теперь, наконец, можно дать определение кода Хемминга в терминах линейных кодов.

\begin{df}
Пусть $H$ есть матрица над полем $\F_2$, в которой $r$ строк и $2^r-1$ столбцов,
причём её столбцы\т все различные ненулевые вектора из $\F_2^r$.
Линейный код, для которого эта матрица является проверочной, и есть двоичный код Хемминга.
\end{df}

Стоит объяснить, почему та схема кодирования, которую мы описали вначале, задаёт именно этот код.
Это становится ясно, если заметить, что столбцы в матрице $H$ можно расставить таким образом,
чтобы номера столбцов, в которых стоят единицы на $i$-й строке, были элементами последовательности
$V_{i-1}$. Это означает, что вектор $Hx$ состоит из всех сумм вида
\eqn{\sums{k\in V_{i-1}}x_k}
и равен нулю тогда и только тогда, когда все эти суммы равны нулю.

\begin{stm}
Код Хемминга есть двоичный $[n,k,d]$\д код, где $n=2^r-1$, $k = 2^r-1-r$, $d=3$.
\end{stm}
\begin{proof}
В доказательстве нуждается лишь тот факт, что этот код имеет минимальное расстояние 3. Покажем, что он не
содержит векторов, вес которых меньше~$3$. Предположим противное. Пусть, например, в нём нашелся вектор $x$,
содержащий только одну единицу в разряде с номером $i$. Тогда из равенства $Hx=0$ следует, что $i$\д й столбец
матрицы $H$ должен быть нулевым, а это противоречит определению. Аналогично, если единиц ровно две\т на~$i$\д м
и~$j$\д м местах, то равенство $Hx=0$ означает, что сумма $i$-го и $j$-го столбцов матрицы $H$ равна нулю,
то есть они попросту совпадают. Опять противоречие, которое и доказывает наше утверждение.
\end{proof}

Из общих свойств корректирующих кодов следует, что линейный код $V$, исправляющий $t$ ошибок, имеет
минимальное расстояние не меньше $2t+1$.

\subsection{Коды БЧХ}

Здесь мы тоже будем говорить о корректирующих линейных кодах и изучим более эффективные алгоритмы их построения.

\subsubsection{Эффективное построение корректирующих кодов}

Здесь мы будем рассматривать двоичные коды, то есть $K = \F_2$.

Сначала приведём (тупой) алгоритм построения проверочной матрицы линейного кода с минимальным расстоянием
не меньше заданного числа $d$. Берём матрицу $H$ (первоначально пустую) из $r$ строк и $n$ столбцов.
Пусть её столбцы\т $h_1\sco h_n$. В качестве $h_1$ берём любой ненулевой вектор. Дальше действуем по индукции:
пусть мы уже знаем столбцы $h_1\sco h_i$, среди которых любые $d-1$ линейно независимы.
Тогда покажем, что выполняется неравенство $N := \Cb_i^1 + \Cb_i^2 \spl \Cb_i^{d-2} < 2^r-1$.
Что значит, что вектор $h_{i+1}$ можно добавить к уже имеющимся так, чтобы сохранилось условие
линейной независимости любых $d-1$ векторов? Это значит, что линейная оболочка любых $d-2$ векторов
не должна исчерпывать всё пространство $K^r$ (без нуля). Очевидно, мощность линейной оболочки не больше количества
всевозможных линейных комбинаций, а их всего ровно $N$ штук. Значит, при $N < 2^r-1$ заведомо $(i+1)$\д й вектор
добавить можно.

\begin{imp}[Граница Варшамова\ч Гилберта]
Если $\Cb_{n-1}^0 + \Cb_{n-1}^1 + \Cb_{n-1}^2\spl \Cb_{n-1}^{d-2} < 2^r$, то существует матрица $n\times r$, у
которой любые $d-1$ столбцов линейно независимы.
\end{imp}
\begin{proof}
Очевидным образом следует из алгоритма: если неравенство ещё не обратилось в равенство при $n-1$ столбце, то найдётся
место и для $n$\д го.
\end{proof}

\subsubsection{Построение поля из $2^m$ элементов}

Поле Галуа $F := GF(2^m)$ из $2^m$ элементов строится как факторкольцо кольца многочленов $\F_2[x]$ по идеалу, порождённому
неприводимым многочленом степени $m$. Это поле является $m$\д мерным векторным пространством над полем $\F_2$.
Иногда мы будем рассматривать его элементы как многочлены степени меньше $m$ над полем $\F_2$, а иногда\т как наборы
их коэффициентов, то есть $m$\д мерные вектора из нулей и единиц.

Напомним, что в поле характеристики $p$ имеет место \emph{автоморфизм Фробениуса} $(a+b)^p = a^p+b^p$, так
как все остальные биномиальные коэффициенты делятся на $p$ и потому в этом поле равны нулю.
Применяя эту формулу несколько раз, получаем более общий факт: $(a+b)^{p^s} = a^{p^s} + b^{p^s}$,
и очевидно, что она верна и для нескольких слагаемых.

\subsubsection{Двоичные коды БЧХ}

Пусть $n=2^m-1$, и $\al_1\sco \al_n$\т все ненулевые элементы поля $F$. Через $\ga_i$ будем обозначать столбец
коэффициентов многочлена $\al_i$ (то есть $\al_i$ и $\ga_i$\т это разные записи одного и того же объекта).

Рассмотрим матрицы
\eqn{A := \rbmat{
\al_1   & \al_2   & \dots  & \al_n\\
\al_1^3 & \al_2^3 & \dots  & \al_n^3\\
\cdots  & \cdots & \cdots & \cdots \\
\al_1^{2t-1} & \al_2^{2t-1} & \dots &\al_n^{2t-1}}_{t\times n} \qquad
H := \rbmat{
\ga_1   & \ga_2   & \dots  & \ga_n\\
\ga_1^3 & \ga_2^3 & \dots  & \ga_n^3\\
\cdots  & \cdots & \cdots & \cdots \\
\ga_1^{2t-1} & \ga_2^{2t-1} & \dots &\ga_n^{2t-1}}_{tm\times n}}

\begin{df}
\emph{Кодом БЧХ} (Боулз\ч Чоудхури\ч Хоквингем) называется код с проверочной матрицей $H$.
\end{df}

\begin{theorem}
В матрице $H$ любые $2t$ столбцов линейно независимы.
\end{theorem}
\begin{proof}
Допустим, что это не так, и нашлись линейно зависимые столбцы
$h_{i_1}\sco h_{i_l}$, где $l \le 2t$.
Тогда имеем
\eqn{\begin{aligned}
S_1 &:= \al_{i_1} \spl \al_{i_l} = 0,\\
S_3 &:= \al^3_{i_1} \spl \al^3_{i_l} = 0,\\
& \cdots\\
S_{2t-1} & := \al^{2t-1}_{i_1} \spl \al^{2t-1}_{i_l} = 0.
\end{aligned}}
Покажем, что степенные суммы $S_k$ с чётными номерами тоже равны нулю.
Пусть $k = 2^s u$, где $u$ нечётно. Тогда в силу автоморфизма Фробениуса $(S_u)^{2^s} = S_k$.
Значит, если $S_u = 0$, то и $S_k = 0$.

Таким образом, получаем, что $S_i =0$ при $i = 1\sco l$. Это <<кусочек>> матрицы Вандермонда, столбцы
которой линейно независимы, если все элементы $\al_j$ различны (а в нашем случае это именно так). Противоречие.
\end{proof}

\begin{petit}
Тут ещё был очень малопонятный пример... для случая двух ошибок.
\end{petit}

\subsection{Алгоритм Питерсона}

\subsubsection{Теория}

Здесь все рассуждения проводятся для произвольного поля $F$ из $q^m$ элементов.

\begin{df}
Пусть $b$\т целое неотрицательное число, и пусть $\al\in F$\т примитивный корень $n$\д й степени из $1$, где
$m$ является мультипликативным порядком числа $q$ по модулю $n$.
Тогда кодом БЧХ длины $n$ с конструктивным расстоянием $d$, где $2 \le d \le n$, над полем $F$
называется циклический код, определяемый корнями $\al^b, \al^{b+1}, \ldots, \al^{b+d-2}$
порождающего многочлена $g(x)$.
\end{df}

Порождающая матрица кода с порождающим многочленом $g(x)$, $\deg g(x)=n-k$, имеет вид
\eqn{
G=\rbmat{
g_0 & g_1 & \ldots & g_{n-k} & 0 & 0 & \ldots & 0 \\
0 & g_0 & g_1 & \ldots & g_{n-k} & 0 & \ldots & 0 \\
        &  &  & \ldots &  &  &  &  \\
0 & 0 & \ldots & 0 & g_0 & g_1 & \ldots & g_{n-k}\\
}.}

\begin{note}
До сих пор мы рассматривали случай $b=1$ (БЧХ\д код в узком смысле), $n=q^m-1$ (примитивный БЧХ\д код) и, наконец, $q=2$.
\end{note}

Обозначим через $w(x)$, $v(x)$ и $e(x)$ передаваемый кодовый многочлен,
принимаемый многочлен и многочлен ошибок соответственно; тогда $v(x)=w(x)+e(x)$.
Прежде всего найдем синдром вектора $v$:
\eqn{\label{eq-12}S(v)=Hv^T=(S_b,\ S_{b+1},\ \ldots,\ S_{b+d-2})^T,}
где
\eqn{S_j=v(\al_j)=w(\al_j)+e(\al_j)=e(\al_j),\ b\le j \le b+d-2.}
Если имеется $r\le t$ ошибок, то
\eqn{e(x)=\suml{i=1}{r} c_i x^{a_i},}
где $a_1\sco a_r$\т различные элементы из $\hc{0\sco n-1}$. Элементы $\eta_i=\al^{a_i}\in F$ называются
\emph{локаторами ошибки}, а элементы $c_i\in\Z_{q}^\ast$\т значениями
ошибки. Таким образом, для синдрома получаем формулу
\eqn{S_j=e(\al_j)=\sum\limits_{i=1}^rc_i\eta_i^j,\ b \le j \le b+d-2,}
а тогда
\eqn{S_j^q=\left(\sum\limits_{i=1}^rc_i\eta_i^j\right)^q=\sum c_i^q\eta_i^{jq}=\sum c_i\eta_i^{jq}=S_{jq}.}
В двоичном случае последняя формула\т это формула для вычисления четных элементов синдрома.

Нам надо найти неизвестные пары $(\eta_i,\ c_i)$. В двоичном случае все $c_i$ могут принимать лишь
значение, равное~$1$, поэтому искать их не нужно.

Следующим шагом декодирующего алгоритма является нахождение коэффициентов $\si_i$, задаваемых так:
\eqn{\prodl{i=1}{r} (\eta_i-x)=\sum\limits_{i=0}^r (-1)^i \si_{r-i}x^i.}

Таким образом, $\si_0=1$, а $\si_1\sco \si_r$\т элементарные
симметрические многочлены от $\eta_1\sco \eta_r$. Подставляя
$\eta_i$ вместо $x$, получаем для всех $i=1\sco r$:
\begin{equation}
(-1)^r\si_r+(-1)^{r-1}\si_{r-1}\eta_i+\ldots+(-1)\si_1\eta_i^{r-1}+\eta_i^r=0.
\end{equation}
Умножим на $c_i\eta_i^j$ и просуммируем по всем $i$:
\begin{equation}
(-1)^r\si_rS_j+(-1)^{r-1}\si_{r-1}S_{j+1}+\ldots+(-1)\si_1S_{j+r-1}+S_{j+r}=0,
\end{equation}
где $j=b,\ b+1, \ldots, b+r-1$.

\begin{lemma}
Система уравнений
\begin{equation}
\suml{i=1}{r}c_i\eta_i^j=S_j,\ j=b,\ b+1,\ \ldots,\ b+r-1,
\end{equation}
относительно неизвестных $c_i$ разрешима, если $\eta_i$ различны.
\end{lemma}

\begin{proof}
Определитель этой системы есть определитель Вандермонда,
умноженный на $\eta_1^b\cdot\ldots\cdot\eta_r^b$.
\end{proof}

\begin{lemma}
Система уравнений
\begin{equation}
(-1)^r\si_rS_j+(-1)^{r-1}\si_{r-1}S_{j+1}+\ldots+(-1)\si_1S_{j+r-1}+S_{j+r}=0,
\end{equation}
где $j=b,\ b+1,\ \ldots,\ b+r-1$ относительно неизвестных
$(-1)^i\si_i$ однозначно разрешима тогда и только тогда, когда в
полученном слове имеется ровно $r$ ошибок.
\end{lemma}

\begin{proof}
Матрица этой системы равна $VDV^T$, где $V$\т определитель Вандермонда от переменных $\eta_i$ степени $r-1$, а $D$\т
диагональная матрица с элементами вида $c_i\eta_i^b$ на главной диагонали. Она невырождена тогда и только тогда,
когда невырождены $V$ и $D$\т то есть как раз когда имеется ровно $r$ различных ошибок.
\end{proof}

\subsubsection{Практика}

Теперь, наконец, можно перейти к самому алгоритму Питерсона. Итак:

\begin{points}{-1}
\item Находим синдром полученного слова
\begin{equation}
S(v)=Hv^T=(S_b,\ S_{b+1},\ \ldots,\ S_{b+d-2})^\top.
\end{equation}
Пусть
\begin{equation}
S_j=\sum\limits_{i=1}^rc_i\eta_i^j,\ b \le j \le b+d-2.
\end{equation}

\item Находим максимальное число $r\le t$, такое, что
система уравнений
\begin{equation}
(-1)^r\si_rS_j+(-1)^{r-1}\si_{r-1}S_{j+1}+\ldots+(-1)\si_1S_{j+r-1}+S_{j+r}=0,
\end{equation}
где $j=b,\ b+1,\ \ldots,\ b+r-1$ относительно неизвестных
$(-1)^i\si_i$ имеет невырожденную матрицу коэффициентов. Тем самым
получаем число появившихся ошибок. Построим многочлен локаторов
ошибки:
\begin{equation}
s(x)=\prod\limits_{i=1}^r(1-\eta_ix)=\sum\limits_{i=0}^r\si_ix^i.
\end{equation}
Коэффициенты $\si_i$ выражаем через $S_j$.

\item Решаем уравнение $s(x)=0$ и находим локаторы ошибки
$\eta_i$. В двоичном случае на этом всё заканчивается.

\item Подставляя $\eta_i$ в систему
\begin{equation}
S_j=\sum\limits_{i=1}^rc_i\eta_i^j,\ b \le j \le b+d-2,
\end{equation}
полученную на 1\д м шаге, находим значения ошибки $c_i$.
\end{points}

\section{Схемы из функциональных элементов}

При работе с булевыми функциями мы иногда будем заменять значок $\&$ обычной точкой (произведением)
или не писать его вовсе.

\subsection{Схемы из функциональных элементов}

\begin{df}
\emph{Схема из функциональных элементов} (СФЭ)\т это конечный ориентированный граф без ориентированных
циклов, в каждую вершину которого входит не более 2~рёбер. При этом каждой вершине приписывается символ:
переменная $x_i$, если в эту вершину рёбра не входят; отрицание, если в вершину входит одно ребро; конъюнкция
или дизъюнкция, если в вершину входит 2 ребра. Некоторым вершинам приписывается~$*$.
\emph{Элементами} схемы называются вершины, помеченные логическими операциями.
\end{df}

Занумеруем вершины графа согласно теореме~\ref{thm:OriGraphNum}.
Каждой вершине СФЭ можно сопоставить некоторую булеву функцию по следующему индуктивному правилу.
Пусть всем вершинам с номерами меньше~$n$ уже сопоставлены функции. Возьмём вершину с номером~$n$. Если в неё
не входит ни одного ребра, то ей приписана переменная, которую мы как функцию и поставим ей в соответствие.
Если в вершину входит одно ребро, то в ней записано отрицание, и мы припишем этой вершине отрицание функции
той вершины, из которой в данную вершину приходит ребро. Если входит два ребра, то в этой вершине будет
конъюнкция или дизъюнкция функций тех вершин, из которых приходят эти рёбра. Видно, что такое определение
корректно.

\begin{df}
Функции, отвечающие вершинам, отмеченным $*$, называются \emph{реализуемыми} данной СФЭ.
\end{df}

\cpic{9}{FuncSchemeEx}{Пример СФЭ}

\begin{ex}
Приведённая на рис.~\picref{FuncSchemeEx} схема реализует функцию $(x_1 \vee x_2) \& (\ol{x_1 \& x_2})=x_1 \oplus x_2$.
\end{ex}

Существует физическая интерпретация СФЭ, в которой они рассматриваются как математические модели
соответствующих реальных электронных схем: если на вход подаётся набор значений (наличие тока соответствует
единице, отсутствие\т нулю), то на выходе получается значение функции на этом наборе.

\begin{df}
\emph{Сложностью схемы} $S$ называется число элементов $L(S)$ в ней. \emph{Сложностью функции} $f$ называется минимальная
сложность схемы для $f$. \emph{Функция Шеннона} $L(n)$ выражает максимальную сложность функций от $n$ переменных.
\end{df}

Построим СФЭ, реализующую функцию $f=\XSig{n}$. Перегруппируем множители, собрав в одном месте переменные  с
нулевыми степенями. Тогда, перенумеровав переменные и применив правило де Моргана, функцию можно переписать в
виде
\eqn{f=(x_1\sa x_k)\&(\ol{x_{k+1} \vee x_{k+2} \sv x_n}).}
Заметим, что в этой формуле не~более~$n$ операций.
Значит, сложность схемы данной функции не превосходит~$n$.
Постройка схемы по данной формуле предоставляется читателю.

\begin{stm}
\eqn{L(n) \le (n+1)\cdot 2^n.}
\end{stm}
\begin{proof}
Рассмотрим произвольную функцию $f$ от $n$ переменных и построим её СДНФ. В ней может
быть не более $2^n$ дизъюнкций выражений вида $\XSig{n}$. Так как сложность каждого дизъюнкта мы уже оценили
числом $n$, то сложность всей схемы не превосходит $n \cdot 2^n + (2^n-1) < (n+1)\cdot 2^n$.
Для функций, тождественно равных нулю, можно использовать формулу $f=x_1 \& \ol x_1$. При этом мы предполагаем,
что $f$\т функция по крайней мере от одной переменной. Схема будет содержать 2 элемента, значит, её
сложность $L(f)=2\le n \cdot 2^n$. Итак, сложность любой функции $L(n) \le (n+1) \cdot 2^n$.
\end{proof}

\begin{note}
На самом деле легко доказать, что $L(n) \le (n+1) \cdot 2^{n-1}$. Действительно, посмотрим на таблицу значений
нашей функции и выясним, чего в ней больше: нулей или единиц. В зависимости от этого будем использовать,
соответственно, СДНФ либо СКНФ. В самом худшем случае будет $2^{n-1}$ дизъюнкций или коньюнкций.
\end{note}
\begin{imp}
В силу сделанного замечания верна оценка $L(n) \le n\cdot 2^n$, так как $\frac 12 \cdot (n+1) \cdot 2^n \le n\cdot 2^n$.
\end{imp}

Обозначим через $K_n$ множество всех функций вида $\XSig{n}$.
Сейчас мы будем строить схему, которая реализует \textbf{все} функции из $K_n$.
Сложность такой схемы обозначим $C(n)$.

Мы будем делать это индуктивно. При $n=1$ делать почти нечего.
Предположим, что мы уже построили схему для всех множеств с номерами меньше $n$.
Зафиксируем число $k < n$. Построим схему, реализующую все функции из $K_n$,
используя в качестве подсхем две схемы: для $K_k$ и для $K_{n-k}$.

Рассмотрим произвольную конъюнкцию
\eqn{\XSig{n} = (\XSig{k})\&(x_{k+1}^{\si_{k+1}}\sd x_n^{\si_n}).}
Возьмём по одному выходу из схем для $K_k$ и $K_{n-k}$, реализующие множители в скобках,
и подключим их к конъюнктору. Получим схему, реализующую одну конъюнкцию $n$ переменных.
Также поступим со всеми $2^n$ конъюнкциями $n$ переменных, то есть будем делать их,
используя соответствующие выходы в схемах $K_k$ и $K_{n-k}$, связывая их конъюнктором.
Итого получим схему для $K_n$, затратив $C(k) + C(n-k) + 2^n$ элементов.

Теперь возьмём $k := \frac{n}{2}$.
Значит,
\eqn{C(n) \le 2^n + 2C\hr{\frac n2} = 2^n + 2\hr{ 2^{\frac n2} + 2 C\hr{\frac n{2^2}}} =
2^n + 2^{\frac n2+1} + 2^2 C\hr{\frac{n}{2^2}} =\dots \lesssim 2^n.}

Отсюда следует, что можно (асимптотически) улучшить оценку для $L(n)$:
реализовав все конъюнкции ценой $\sim2^n$ элементов, склеим их не более чем $2^n$ дизъюнкциями,
в итоге получим схему сложности порядка $2^{n+1}$.

\subsubsection{Метод Шеннона синтеза схем}

Все дальнейшие оценки будут асимптотическими, поэтому мы не будем всякий раз об этом упоминать.
Так как никаких других логарифмов в дискретной математике не встречается, под $\log$ мы всегда
будем понимать $\log_2$.

Мы будем использовать разложение функции по переменным:
\eqn{f(x_1\sco x_n) = \bigvee_{(\si_1\sco \si_q)} \XSig{q} f(\si_1\sco \si_q,x_{q+1}\sco x_n).}
Пусть $q = n-k$. Реализуем все конъюнкции $K_q$ первых $q$ переменных, при этом
потратим $2^q$ элементов. Кроме этого, нам по максимуму может потребоваться реализовать
все функции от $k$ переменных, коих имеется $2^{2^k}$ штук. Не напрягаясь, реализуем каждую из них
со сложностью $k\cdot 2^k$. При склейке основной схемы по указанной выше формуле
потребуется ещё $2^q$ конъюнкторов (для вычисления слагаемых) и ещё $2^q-1$ дизъюнкторов.
Итого
\eqn{L(f) \lesssim 2^q + 2^q + (2^q - 1) + k\cdot 2^k\cdot 2^{2^k} \lesssim 3\cdot 2^q + k\cdot 2^k\cdot 2^{2^k}.}
Выбор $k$\т дело ответственное. Нам нужно, чтобы последнее слагаемое не было очень большим.
Логично взять $k = \log  n$, но, если подставить, получается многовато.
Поэтому возьмём $k := \hs{\log n}-1$. Тогда
\eqn{L(f) \lesssim 3\cdot 2\cdot \frac{2^n}{2^{\hs{\log n}}} + \frac{n\log n}{2}\cdot 2^{\frac{n}{2}}
\lesssim 3\cdot 2\cdot 2\cdot \frac{2^n}n + \frac{n\log n}{2}\cdot 2^{\frac{n}{2}} \lesssim 12\frac{2^n}{n}.}


\subsubsection{Асимптотически наилучший метод построения схем}

\begin{theorem}[О.\,Б.\,Лупанов]
\eqn{L(n) \lesssim \frac{2^n}{n}.}
\end{theorem}

\begin{proof}
Рассмотрим произвольную булеву функцию $n$ переменных.
Отделим $q := n-k$ первых переменных и рассмотрим таблицу, в которой $2^k$ строк и $2^q$ столбцов.
Строки занумеруем всевозможными значениями последних $k$ переменных, а столбцы\т всевозможными
значениями  первых $q$ переменных. Ячейки таблицы заполним значениями функции.
Каждый столбец представляет собой значения функции, полученной подстановкой констант в первые $q$ переменных,
то есть $f(\si_1\sco \si_q,x_{q+1}\sco x_n)$. Разрежем таблицу на горизонтальные полоски
по $s$ строк в каждой (последняя полоса будет, возможно, меньше; пусть в ней $s' < s$ строк).
Число полос будет равно
\eqn{p := \hce{\frac{2^k}{s}} < \frac{2^k}{s} + 1.}

Через $I_i$ обозначим индикатор $i$\д й полосы, то есть функцию, которая равна единице
на строках этой полосы, и только на них. Обозначим теперь $f_{(\si_1\sco \si_q),i}(x_{q+1}\sco x_n)
:= f(\si_1\sco \si_q, x_{q+1}\sco x_n)\cdot I_i$.
Такие функции будем называть обрезанными функциями.
Ясно, что
\eqn{f(\si_1\sco \si_q,x_{q+1}\sco x_n) = \bigvee_{i=1}^{p} f_{(\si_1\sco \si_q),i}(x_{q+1}\sco x_n).}
Имеем
\eqn{f(x_1\sco x_n) = \bigvee_{(\si_1\sco \si_q)} \XSig{q} \cdot f(\si_1\sco \si_q,x_{q+1}\sco x_n).}
Реализуем все конъюнкции первых $q$ переменных, потратив $2^q$ элементов.
Кроме этого, реализуем все конъюнкции последних $k$ переменных, потратив $2^k$ элементов.
Все обрезанные функции имеют не более $s$ ненулевых значений, значит, их количество не превышает $2^s$.
Поскольку все конъюнкции последних переменных уже есть, на изготовление СДНФ для каждой обрезанной функции
уйдёт всего $s$ дизъюнкций, значит, всего на реализацию обрезанных функций каждой полосы
мы потратим не более $s\cdot 2^s$ элементов, а всего\т не более $p \cdot s \cdot 2^s$.


На сборку каждой $f(\si_1\sco \si_q,x_{q+1}\sco x_n)$ уйдёт ещё $p$ дизъюнкций (поэтому всего
на это уйдёт $p\cdot 2^q$ операций), а на сборку функции $f$
уйдёт ещё $2^q$ конъюнкций и $2^q$ дизъюнкций.

Суммируя полученные оценки, имеем
\eqn{L(f) \lesssim 2^q + 2^k + ps \cdot 2^s + p\cdot 2^q + 2^q + 2^q = 3\cdot 2^q + ps \cdot 2^s + p\cdot 2^q + 2^k.}
Вспоминая, что $p < \frac{2^k}{s} + 1$, получаем
\eqn{L(f) \lesssim  3 \cdot 2^q + \hr{\frac{2^k}{s} + 1}\hr{s \cdot 2^s + \cdot 2^q} + 2^k.}
Видно, что $s$ должно быть порядка $n$, но всё же чуть меньше его.
Что касается $k$, то нужно, чтобы $\frac{2^k}{s} \ra \bes$, чтобы нам не мешала единица в скобках.
Положим $k := \hs{2\log n}$ и $s := \hs{n - 4\log n}$.
Подставляя эти значения, получаем оценку порядка $\frac{2^n}{n}$ (выкладки временно предоставляем читателю).
\end{proof}

\subsubsection{Асимптотическая оценка снизу для сложности схем}

\begin{theorem}
Для любого $\ep>0$ выполено асимптотическое неравенство
\begin{equation}
L(n)\gtrsim(1-\ep)\frac{2^n}{n}.
\end{equation}
\end{theorem}

\begin{proof}
Введем следующие обозначения:
\begin{items}{-1}
  \item $P_2^*(n)$\т функции, существенно зависящие от $n$ переменных.
  \item $N(h, n)$\т число функций, существенно зависящих от $n$
  переменных, которые реализуются схемами сложности, не превосходящей~$h$.
  \item $N'(h, n)$\т число функций, существенно зависящих от $n$
  переменных, которые реализуются схемами сложности ровно~$h$;
  \item $N''(h, n)$\т число схем сложности $h$ для функций,
  существенно зависящих от $n$ переменных;
\end{items}

Очевидно, что $N'=N$, потому что всегда можно дополнить схему ничего не делающими
элементами. Очевидно также, что $N\le N''$, так как одну функцию можно реализовать разными схемами,
но не наоборот.

Идея доказательства состоит в том, чтобы показать, что функций, реализуемых
схемами сложностью меньше $(1-\ep)\frac{2^n}{n}$, гораздо меньше, чем всех функций.
Итак, покажем, что для $h_0\bw{:=}(1-\ep)\frac{2^n}{n}$ выполнено
$N(h_0, n)\bw<\hm{P_2^*(n)}$. Мы будем оценивать величину $N$, мажорируя её величиной~$N''$.

Пусть $\ga(p, q)$\т число графов с $q$ ребрами и $p:=h+n$
вершинами ($n$ входов и $h$ элементов), $N''(h, n, q)$\т число схем с $q$ ребрами. Сколько
схем можно сделать из одного графа? У нас имеется не более:
\begin{items}{-1}
  \item $2^q$ способов выбрать ориентацию ребер;
  \item $(h+n)^n$ способов выбрать входы;
  \item $3^h$ способов присвоения вершинам различных ФЭ;
  \item $h+n$ способов выбора выхода.
\end{items}
Итак, вспоминая оценку для числа графов, получаем:
\eqn{
N''(h, n, q)\le \ga(p, q)\cdot 2^q \cdot (h+n)^{n+1}\cdot3^h\le
A^{h+n+q}(h+n)^{q-h+1}\cdot 2^q\cdot 3^h.}
Вспоминая, что $q\le2h$, и собирая константы, окончательно запишем:
\eqn{N''(h, n, q)\le  B^{3h+n}(h+n)^{h+1}.}
Теперь получим оценку для $N''(n, h)$:
\eqn{N''(n, h)\le \suml{q=h}{2h} N''(h, n, q)\le B^{3h+n}(h+n)^{h+1}(h+1)\le (C(h+n))^{h+n}.}

Нам нужно убедиться, что $N''(h_0, n)<|P_2^*(n)|$ при
достаточно больших $n$. Заметим, что
\eqn{|P_2^*(n)|>2^{2^n}-n2^{2^{n-1}}\sim2^{2^n}.}
Таким образом,
требуемое неравенство будет выполнено, если
\begin{equation}
\log\frac{N''(h_0, n)}{|P_2^*(n)|}=\log N''(h_0, n) - 2^n +
o(1) \ra -\bes, n\ra\bes.
\end{equation}
Пришло время использовать полученную для $N''$ оценку. Далее все
неравенства записаны для достаточно больших $n$:
\begin{multline}
\log N''(h_0, n) - 2^n +o(1) \le
(h_0+n)\log\br{C(h_0+n)}-2^n+o(1)\le\\ \le
\hr{(1-\ep)\frac{2^n}{n}+n}n-2^n+o(1)=(1-\ep)2^n+n^2-2^n+o(1)=\\
=n^2+o(1)-\ep2^n\ra-\bes,\quad n\ra\bes,
\end{multline}
что и требовалось доказать.
\end{proof}

\subsection{Инвариантные классы}

В логике для множества всех булевых функций от $n$ переменных используется обозначение~$P_2(n)$.
Множество всех булевых функций обозначается через~$P_2$.

\begin{df}
Множество $K \subs P_2(n)$ называется \emph{инвариантным классом}, если оно замкнуто относительно
подстановок констант, переименования переменных (без отождествления) и добавления/отбрасывания
несущественных переменных.
\end{df}

\begin{ex}
\begin{items}{-2}
\item Очевидно, $P_2$ является инвариантным классом.
\item Функции, существенно зависящие не более чем от $k$ переменных, образуют инвариантный класс.
\item Линейные и монотонные функции образуют инвариантный класс.
\end{items}
\end{ex}


Пусть $Q$\т инвариантный класс. Через $P_Q(n)$ будем обозначать количество функций из $Q$ от $n$ переменных.
Ясно, что $P_Q(n) \le 2^{2^n}$.

Будем считать, что $Q \ne \es$. Рассмотрим последовательность
\eqn{q_n := \sqrt[2^n]{P_Q(n)}.}

\begin{stm}
Последовательность $\hc{q_n}$ монотонно убывает (нестрого).
\end{stm}
\begin{proof}
Возьмём функцию $f \in Q$, зависящую от $n+1$ переменной и разложим её по последней переменной:
\eqn{f(x_1\sco x_{n+1}) = x_{n+1} f(x_1\sco x_n, 1) \vee \ol x_{n+1} f(x_1\sco x_n,0) .}
Имеем $f(x_1\sco x_n, c) \in Q$, где $c = 0,1$. Итак, каждая функция от $n+1$ переменной может быть
сконструирована из двух функций от $n$ переменных этого же класса. Стало быть,
число функций от $n+1$ переменных из $Q$ никак не больше, чем число пар функций из $Q$ от $n$ переменных.
Итак,
\eqn{P_Q(n+1) \le P_Q(n)^2.}
Извлекая из этого неравенства корень степени $2^{n+1}$, получаем
\eqn{q_{n+1} = \sqrt[2^{n+1}]{P_Q(n+1)} \le \sqrt[2^{n+1}]{P_Q(n)^2} = \sqrt[2^n]{P_Q(n)} = q_n,}
что и требовалось доказать.
\end{proof}

С другой стороны, ясно, что $q_n \ge 1$ при всех $n$ (так как $Q \ne \es$ и потому $P_Q(n) \ge 1$).
Значит, существует предел у этой последовательности.

\begin{df}
Число
\eqn{\si(Q) := \log \liml{n\ra \bes} q_n}
называется параметром инвариантного класса.
\end{df}

Поскольку $1 \le q_n \le 2$, получаем, что $\si(Q) \in [0,1]$.
Сейчас мы докажем, что $P_2$\т единственный инвариантный класс с параметром~$1$.

\begin{stm}
$\si(Q) = 1 \Lra Q = P_2$.
\end{stm}
\begin{proof}
Справа налево\т очевидно. Обратно, пусть $Q \ne P_2$.
Значит, в нём нет какой\д либо функции от $m$~переменных.
Стало быть, $P_Q(m) < 2^{2^m}$, и потому $q_m < 2$. Но эта последовательность убывает,
поэтому и предел не может быть равен~2.
\end{proof}

\begin{note}
Можно доказать, что для каждого $\si \ne 1$ существует континуум инвариантных классов
с параметром $\si$.
Это нетривиальная теорема, мы не будем её здесь доказывать.
\end{note}



Так как $\lim q_n = 2^\si$, то $q_n = 2^\si(1+\ep_n)$, где $\ep_n \ra 0$.
Логарифмируя это равенство, получаем
\eqn{\frac{1}{2^n} \log P_Q(n) = \si + \de_n, \quad \de_n := \log (1+\ep_n) \ra 0.}
Умножая на $2^n$ обе части, имеем
\eqn{\log P_Q(n) = 2^n\si + 2^n\de_n.}
Если $\si \ne 0$, то главный член этой последовательности определяется
первым слагаемым, и $\log P_Q(n) \sim \si\cdot 2^n$. Если же $\si = 0$,
то $\log P_Q(n) = o(2^n)$.

\begin{theorem}
Имеет место асимптотическая оценка сложности функций из класса с параметром $\si$:
если $\si \ne 0$, то $L(f) \lesssim \si \cdot \frac{2^n}{n}$,
а если $\si = 0$, то $L(f) \lesssim o\hr{\frac{2^n}{n}}$.
\end{theorem}
\begin{proof}
Будем нумеровать функции из нашего класса последовательностями нулей и единиц. Ясно, что
для нумерации всех функций от $n$ переменных из $Q$ достаточно брать $l_n := \hce{\log P_Q(n)}$ двоичных
разрядов.
Итак, $l_n \sim \si\cdot 2^n$, а при $\si = 0$ имеем $l_n = o(2^n)$.

Возьмём какую\д либо функцию $f \in Q$ от $n$ переменных, выберем $k < n$ и обозначим $m := n-k$.
Положим $l := l_k$ для краткости.
Оставим первые $k$ переменных, а вместо остальных будем подставлять константы $\al_{k+1}\sco \al_n$.
При подстановке констант будем получать функции от $k$ аргументов, которые тоже лежат в $Q$,
поскольку это инвариантный класс. Каждой такой функции $f(x_1\sco x_k,\al_{k+1}\sco \al_n)$ соответствует
какой\д то номер. Итак, для фиксированной функции $f$ получаем отображение нумерации
\eqn{\ph\cln (\al_{k+1}\sco \al_n) \mapsto (\tau_1\sco \tau_{l}).}

А теперь построим схему $\Phi$, которая реализует это отображение. Нам нужно построить $l$ функций,
каждая из которых зависит от $m$ аргументов $x_{k+1} \sco x_n$. Значит, на каждую функцию уйдёт порядка
$\frac{2^m}{m}$ элементов, а всего на схему $\Phi$ уйдёт порядка $l\cdot \frac{2^m}{m}$ элементов.

Через $\De$ обозначим схему, которая будет по номеру функции $f(x_1\sco x_k,\al_{k+1}\sco \al_n)$,
то есть по набору $(\tau_1\sco \tau_{l})$, генерировать её таблицу значений. Эта схема
будет иметь $l$ входов и $2^k$ выходов, поэтому
\eqn{L(\De) \lesssim 2^k\cdot\frac{2^{l}}{l}.}

К этому декодеру подключим схему $\Sig$, которая получает на вход набор $(\al_1\sco \al_k)$ и таблицу истинности
функции от $k$ переменных (ту самую, которую выдаёт декодер $\De$), а на выходе даёт значение
этой функции на наборе $(\al_1\sco \al_k)$.
Схема $\Sig$ имеет $2^k + k$ входов, поэтому её сложность имеет порядок
\eqn{L(\Sig) \lesssim \frac{2^{2^k+k}}{2^k+k} \le \frac{2^{2^k+k}}{2^k} = 2^{2^k}.}

Теперь считаем сложность агрегата, полученного соединением $\De$, $\Ph$ и $\Sig$. (обозначим его $F$).
Соединяя полученные выше оценки, получаем
\eqn{L(F) \lesssim l \cdot \frac{2^m}{m} + 2^k \cdot\frac{2^{l}}{l} + 2^{2^k}.}

Функция $\frac{2^x}{x}$ монотонно возрастает при больших $x$, поэтому
в силу того, что $l \le 2^k$, имеем $\frac{2^l}{l} \le \frac{2^{2^k}}{2^k}$.

\pt1. Пусть $\si \ne 0$. Тогда имеем $l \sim \si\cdot 2^k$, и потому
\eqn{L(F) \lesssim \si \cdot 2^k \cdot \frac{2^m}{m} + 2^k \cdot \frac{2^{2^k}}{2^k} + 2^{2^k} =
\si \cdot 2^k \cdot \frac{2^m}{m} + 2 \cdot  2^{2^k} =
\si \cdot \frac{2^n}{n-k} + 2\cdot 2^{2^k} \lesssim
\si \cdot \frac{2^n}{n} + 2\cdot 2^{2^k}.}
Волевым решением полагая $k:=\hfl{\frac{\log n}{2}}$, получаем $2^k \le \sqrt{n}$, поэтому
\eqn{L(F) \lesssim \si\cdot \frac{2^n}{n} + 2\cdot 2^{\sqrt n} \lesssim \si\cdot \frac{2^n}{n}.}

\pt2. Если $\si = 0$, то аналогично показывается, что $L(F) \lesssim o\hr{\frac{2^n}{n}}$.
\end{proof}

\begin{imp}[С.\,В.\,Яблонский]
Пусть $f_k(x_1\sco x_k)$\т самая сложная функция от $k$ переменных, то есть $L(f) = L(k)$.
Рассмотрим множество функций $\Fc := \hc{f_i}_{i=1}^\bes$. Тогда замыкание $\hs{\Fc}$ относительно
подстановки констант даст все булевы функции.
\end{imp}
\begin{proof}
К сожалению, мы не можем утверждать, что $\hs{\Fc}$\т инвариантный класс,
поскольку априори неясно, что он замкнут относительно добавления и удаления
несущественных переменных. Однако мы видим, что в нём (по построению)
есть функции от любого числа переменных и потому для него тоже можно корректно определить
параметр $\si$ (пройдёт рассуждение с ограниченностью снизу последовательности $q_n$).
Доказанная только что теорема вовсе не использует данное свойство инвариантных классов,
поэтому она справедлива и для~$\hs{\Fc}$. Осталось заметить, что никакие значения параметра,
кроме~$1$, для $\hs{\Fc}$ не подходят, потому что иначе асимптотическая сложность была бы строго
меньше $\frac{2^n}{n}$, а у нас есть все самые сложные функции. Значит, параметр множества~$\hs{\Fc}$
равен~$1$, а потому $\hs{\Fc} = P_2$.
\end{proof}

\begin{petit}
Было ещё сказано, что <<если допустить отождествление переменных, то инвариантных классов не будет>>.
Почему это так, и в каком смысле это надо понимать, неясно, потому что, например, из линейных функций
даже используя отождествление переменных, ничего лучше линейных функций получить нельзя.
\end{petit}

\section{Теория автоматов}

\subsection{Автоматы}

\subsubsection{Детерминированные функции}

Рассмотрим два алфавита $A=\hc{a_1,a_2 \sco a_\nu}$, $B=\hc{b_1,b_2 \sco b_\mu}$ и функции
вида $f\cln A^\bes \ra B^\bes$, то есть функции, преобразующие бесконечные последовательности букв алфавита~$A$ в
бесконечные последовательности букв алфавита~$B$.

\begin{ex}
Пусть $f$ переводит последовательность, состоящую сплошь из нулей, в себя, а все остальные\т в
последовательность, состоящую сплошь из единиц. Для такой функции существует последовательность\т состоящая
лишь из нулей, для которой невозможно определить её образ, зная лишь конечное число членов. Это причиняет
неудобства при вычислении, поэтому введём понятие детерминированности.
\end{ex}

Мы будем обозначать символы входной последовательности через $a(t)$, где $t = 1,2,3\etc$,
а выходной последовательности\т через $b(t)$.

\begin{df}
Функция $f\cln A^\bes \ra B^\bes$ называется \emph{детерминированной}, если $b(t)$ однозначно определяется
первыми $t$ членами входной последовательности $a(1),a(2) \sco a(t)$.
\end{df}

\begin{ex} Детерминированными функциями являются:
\begin{itemize}
\item Функция $\br{0 \sco 0,\us{t}{1},? \sco ?,\dots} \mapsto \br{0 \sco 0,\us{t}{1},1 \sco 1,\dots}$.
      Здесь «?»\т любой символ.
\item Функция чётности $b(t)=a(1)\sop a(t)$;
\item Функция единичной задержки $\br{a(1),a(2) \sco a(t),\dots} \mapsto \br{0,a(1),a(2) \sco a(t-1),\dots}$;
\item Функция $b(t)=\case{1, & t=2^m; \\ 0, & t\neq 2^m.}$
\end{itemize}
\end{ex}

Без ограничения общности можно считать, что входной алфавит состоит из двух символов: $0$ и $1$.
Тогда детерминированные функции можно задавать на бинарных деревьях. Бинарное дерево\т это дерево
с корнем, такое что из каждой вершины выходит 2~ребра, и во все вершины, кроме корня, входит одно ребро.
Каждой бесконечной двоичной последовательности поставим в соответствие
определённый путь на дереве: движение начинается из начальной вершины, и если $a(i)=0$, то идём по левой
ветке, а если $a(i)=1$, то по правой. При этом очередному звену пути приписываем значение $b(i)$. Легко
видеть, что такое соответствие осуществляет биекцию между деревьями и детерминированными функциями.

\begin{ex}
\cpic{10}{AutoTreesEx}{Деревья детерминированных функций}
Деревья на рис.~\picref{AutoTreesEx} иллюстрируют первые два примера детерминированных функций, приведённых выше.
\end{ex}

Можно было бы и не ограничивать выходной алфавит двумя символами. Тогда вместо
бинарных деревьев следовало бы рассматривать деревья, у которых из каждой вершины растёт по $\mu$~веток.

\subsubsection{Автоматы}

\begin{df}
\emph{Ограниченно детерминированные} функции \emph{(конечные автоматы)}\т детерминированные функции, деревья
которых содержат лишь конечное число различных поддеревьев.
\end{df}

\begin{note}
Слово <<конечный>> в названии <<конечный автомат>> часто опускают. Мы тоже будем это делать,
всегда подразумевая конечный автомат.
\end{note}

Пронумеруем различные поддеревья. Номера будем писать в начальных вершинах поддеревьев.

\begin{ex}
\cpic{11}{OddTreesEx}{Поддеревья функции чётности}
Рассмотрим снова функцию чётности. Её дерево содержит только 2 вида поддеревьев.
Эту диаграмму надо понимать так: если мы находимся в дереве №1 и на входе 0, то выход\т 0 и мы остаёмся  в
дереве №1, а если на входе 1, то выход\т 1 и мы переходим в дерево №0. Аналогично для дерева №0.
\end{ex}

В общем случае, если речь идёт о конечно детерминированных функциях, можно утверждать, что достаточно знание
конечного числа конечных фрагментов дерева, чтобы найти образ любой последовательности.

\begin{df}
Номера поддеревьев называются \emph{состояниями} автомата.
\end{df}

Фрагменты дерева могут задаваться \emph{диаграммами переходов (диаграммами Мура)}. Они представляют собой
ориентированные графы, вершины которых соответствуют состояниям,
а каждому ребру приписывается пара символов, первая компонента которой соответствует входу, а вторая\т выходу.
Направление ребра соответствует переходу из одного состояния в другое.

\begin{ex}
Диаграмма Мура для функции чётности (см.~рис.~\picref{OddMoore}).
\cpic{12}{OddMoore}{Диаграмма Мура функции чётности}
\end{ex}

Автомат можно задавать \emph{функцией перехода} $q(t+1)=G\br{a(t),q(t)}$ и \emph{функцией выхода}
$b(t)=F\br{a(t),q(t)}$. Здесь $q(t)$\т состояние в момент $t$. Удобно считать $q(1)=0$.
Эти три уравнения называются \emph{уравнениями автомата}.

\begin{ex}
\cpic{13}{WaitMoore}{Диаграмма Мура функции единичной задержки}
Найдём уравнения автомата единичной задержки, \те функции с выходом
$b(1)=0$, $b(t)=a(t-1)$, $t>1$. Построим диаграмму Мура (см.~рис.~\picref{WaitMoore}).
По ней видно, что $q(t+1)\bw=a(t)$, а $b(t)\bw=q(t)$. При этом $q(1)\bw=0$.
\end{ex}

Можно также задавать диаграммы функций таблицами. Например, функция единичной задержки задаётся
следующей таблицей:
\ctab{|c|c|c|}{
\hline $a$ & $q$ & $F(a,q), \, G(a,q)$ \\
\hline 0   & 0   & $(0,0)$ \\
\hline 0   & 1   & $(1,0)$ \\
\hline 1   & 0   & $(0,1)$ \\
\hline 1   & 1   & $(1,1)$ \\ \hline}


\begin{theorem}
Любой автомат можно реализовать СФЭ, используя элементы 4 видов: конъюнкцию, дизъюнкцию,
отрицание и функцию единичной задержки.
\end{theorem}
\begin{proof}
Пусть автомат работает на алфавитах $A$ и $B$ и имеет $\la$ состояний.
Положим $n \bw{:=} \bigl\lceil\log |A|\bigr\rceil$,
$m \bw{:=} \bigl\lceil\log |B|\bigr\rceil$. Занумеруем буквы $A$ и $B$
двоичными последовательностями длины $n$ и $m$ соответственно. Состояния автомата $q_0 \sco  q_{\lambda-1}$
также занумеруем двоичными последовательностями длины $l \bw{:=} \bigl\lceil\log_2 \lambda \bigr\rceil$,
причём $q_0$ соответствует $(0 \sco 0)$. Введём новые функции перехода и выхода, определённые уже на наборах
из 0 и 1:
\eqn{\case{\br{\be_1(t) \sco \be_m(t)} = \wt{F}\br{\al_1(t) \sco \al_n(t),\om_1(t) \sco \om_l(t)},\\
\br{\om_1(t+1) \sco \om_l(t+1)}=\wt{G}\br{\al_1(t) \sco \al_n(t),\om_1(t) \sco \om_l(t)}.}}
\cpic{14}{Device}{Автомат}
Каждая из компонент векторов $\wt{\be}$ и
$\wt{\om}$ реализуется некоторой булевой функцией  (вообще говоря, не всюду определённой).
Построим СФЭ, совместно реализующую все эти функции (обозначим их через $f_1 \sco f_m$ и
$g_1\sco g_l$).

Соединим выходы $g_1\sco g_l$ через элементы единичной задержки (они
показаны на рис.~\picref{Device} прямоугольниками) с входами $\om_1\dots \om_l$. Очевидно, что такая схема будет
работать согласно приведённым выше уравнениям автомата (при условии, что элементы единичной
задержки в первый момент времени выдают нули).
\end{proof}

Обратное также верно: любая СФЭ типа той, что была рассмотрена выше, моделирует некоторый автомат.


\subsection{Регулярные события. Теорема Клини}

\subsubsection{Регулярные события}

Пусть, как и раньше, мы рассматриваем конечные автоматы с алфавитами $A$ и $B$.
Зафиксируем некоторое подмножество $B' \subs B$.

\begin{df}
Рассмотрим слово $w := a(1)\sco a(t)$, поданное на вход конечного автомата.
Будем говорить, что слово $w$ принято автоматом, если $b(t) \in B'$.
Множество всех слов, принимаемых автоматом, будем называть событием,
или представимым данным автоматом.
\end{df}


Мы будем выяснять вопрос о том, можно ли описать все события.
Оказывается, это можно сделать, и ответ будет дан в терминах так называемых регулярных множеств,
которые мы сейчас определим.

Для начала нам потребуется несколько вспомогательных определений.

\begin{df}
Конкатенация (склейка) двух слов $w_1$ и $w_2$ какого\д либо алфавита\т это просто слово
$w_1w_2$.
\end{df}

\begin{df}
Конкатенация $M_1M_2$ двух множеств $M_1$ и $M_2$\т это множество
\eqn{M_1M_2 := \hc{w_1w_2 \vl w_1 \in M_1, w_2 \in M_2}.}
\end{df}

Конкатенацию множества с самим собой мы будем обозначать в виде степени (не путать с декартовой степенью!).
Иначе говоря,
\eqn{\ub{M\ldots M}_{k\text{ раз}}  = M^k.}

\begin{df}
Итерация данного множества\т это множество
\eqn{\ha{M} := M \cup M^2 \cup M^3 \cup \dots}
\end{df}

\begin{df}
Одноэлементные подмножества алфавита $A$ по определению являются регулярными множествами.
Далее, если $M_1, M_2$\т регулярные множества, то
$M_1 \cup M_2$, $M_1M_2$ и $\ha{M_1}$ тоже будем называть регулярными множествами.
Пустое множество тоже будем считать регулярным.
\end{df}

Чуть позже мы докажем \emph{теорему Клини}, которая утверждает, что регулярные множества и
представимые множества\т это одно и то же.

\subsubsection{Свойства регулярных множеств}

Все однобуквенные слова регулярны по определению.
Очевидно, что любое конечное множество слов регулярно.

\begin{lemma}
Рассмотрим уравнение $X = XC\cup D$ на $X$.
Его решение существует и единственно.
\end{lemma}
\begin{proof}
Покажем, что множество $F_0 := D\ha{C} \cup D$ является решением.
В самом деле, подставим в уравнение:
\eqn{(D\ha{C} \cup D)C \cup D = D\ha{C}C \cup DC \cup D = D\ha{C} \cup D.}

Допустим, что существует какое\д либо другое решение $F_1 \ne F_0$, то есть $F_1 = F_1C \cup D$.

Пусть сначала $F_1\nsubseteq F_0$. Рассмотрим самое короткое слово $\al \in F_1\wo F_0$.
Ясно, что $\al \notin D$, иначе бы $\al \in F_0$.
Стало быть, $\al \in F_1C$ и потому имеет вид $\al = \al_1\al_2$, где $\al_1 \in F_1$,
а $\al_2 \in C$. Заметим, что $\al_1 \in F_0$, иначе $\al$ не было бы самым коротким словом в $F_1\wo F_0$.
Но тогда $\al \in F_0C \subs F_0C\cup D = F_0$, противоречие.

Пусть теперь $F_0 \nsubseteq F_1$. Дальнейшие рассуждения абсолютно аналогичны, если поменять ролями $F_0$ и $F_1$:

Возьмём самое короткое $\al \in F_0 \wo F_1$.
Ясно, что $\al \notin D$, иначе $\al \in F_1$. Отсюда следует, что
$\al \in F_0C$ и потому имеет вид $\al = \al_1\al_2$, где $\al_1 \in F_0$,
а $\al_2 \in C$. Но тогда $\al_1 \in F_1$, иначе $\al$ не было бы самым коротким,
а тогда $\al = \al_1\al_2 \in F_1C \subs F_1C \cup D = F_1$\т противоречие.

Значит, на самом деле $F_0 = F_1$, то есть решение единственно.
\end{proof}

\begin{imp}
Если коэффициенты в уравнении $X = XC \cup D$ регулярны, то и решение регулярно.
\end{imp}

\begin{imp}
Рассмотрим систему уравнений
\eqn{\bcase{
X_1 &= X_1 R_{11} \cup X_2 R_{21} \cup \dots \cup X_n R_{n1} \cup R_1,\\
\dots &\\
X_n &= X_1 R_{1n} \cup X_2 R_{2n} \cup \dots \cup X_n R_{nn} \cup R_n,
}}
относительно переменных $X_1\sco X_n$. Если события $R_{ij}$ регулярны, то решение системы существует, единственно
и также регулярно.
\end{imp}
\begin{proof}
Докажем для случая двух переменных, для случая б\'ольшего их числа всё делается аналогично (и по индукции).
\eqn{\bcase{
X_1 &= X_1 R_{11} \cup X_2 R_{21} \cup R_1,\\
X_2 &= X_1 R_{12} \cup X_2 R_{22} \cup R_2,
}}
Перепишем второе уравнение так: $X_2 = X_2 R_{22} \cup (X_1 R_{12} \cup R_2)$ и обозначим второе слагаемое через $D$,
а $R_{22}$ через $C$.
Получаем уравнение $X_2 = X_2 C \cup D$. По лемме у него имеется единственное решение
\eqn{X_2 = D\ha{C} \cup D = (X_1R_{12}\cup R_2) \ha{R_{22}} \cup (X_1R_{12}\cup R_2).}
Подставим во первое уравнение:
\eqn{X_1 = X_1 R_{11} \cup \ub{\hs{(X_1R_{12}\cup R_2) \ha{R_{22}} \cup (X_1R_{12}\cup R_2)}}_{X_2}R_{21} \cup R_1.}
А теперь раскроем скобки и вынесем $X_1$:
\eqn{X_1 = X_1 \br{R_{11} \cup [R_{11}\ha{R_{22}} \cup R_{12}]R_{21}} \cup [R_2\ha{R_{22}}\cup R_2]R_{21} \cup R_1.}
Опять получилось уравнение, про которое мы уже всё знаем. Осталось заметить, что все коэффициенты регулярны.
\end{proof}



\subsubsection{Обобщённые источники. Доказательство теоремы Клини}

Рассмотрим автомат с набором состояний $q_1\sco q_\la$, входным алфавитом $A = \hc{a_1\sco a_\nu}$
и выходным алфавитом $B = \hc{b_1\sco b_\mu}$. Рассмотрим подмножество $B' \subs B$.


Сейчас мы докажем одну половину теоремы Клини.

\begin{stm}
Все представимые события регулярны.
\end{stm}
\begin{proof}
Обозначим через $M_i$ множество всех слов, под воздействием которых автомат
из состояния $q_1$ попадает в состояние $q_i$. Через $M_i'$ обозначим множество букв,
при подаче которых в состоянии $q_i$ автомат выдаёт букву из~$B'$.
Очевидно, что все представимые слова имеют вид
\eqn{\cupl{i=1}{\la} M_iM_i'.}
Поскольку все множества $M_i'$ конечны, они регулярны. Значит, осталось доказать,
что все множества $M_i$ тоже регулярны.

Пусть $R_{ij}$\т множество букв, которые переводят автомат из состояния $q_i$ в состояние $q_j$.
Множества $R_{ij}$ конечны, а потому регулярные.

Выясним, откуда можно прийти в состояние $q_k$.
В него можно прийти из $M_1$, если нам дадут букву $R_{1k}$.
Кроме того, в него можно прийти из $M_2$, но только если нам дадут букву из $R_{2k}$,
и так далее. Стало быть,
\eqn{M_k = M_1R_{1k} \cup M_2 R_{2k} \cup \dots \cup M_\la R_{\la k} \cup R_{1k}.}
Последняя возможность соответствует тому, что мы сразу попали в $q_k$.
Мы видим, что у нас получилась как раз такая система, про решения которой мы всё знаем\т все они регулярные.
Итак, первая часть теоремы Клини доказана.
\end{proof}


\begin{df}
Обобщённый источник\т это ориентированный конечный граф, в котором выделены две вершины,
называемые началом $S$ и концом $E$ соответственно. Некоторым рёбрам приписаны буквы исходного алфавита.
\end{df}

По рёбрам источника можно ходить, соблюдая ориентацию.
Рассмотрим все пути в графе по рёбрам из $S$ в $E$. При этом каждому пути естественным образом
сопоставляется слово из тех букв, которые написаны на рёбрах.
Таким образом, всякий обобщённый источник порождает некоторое множество слов.

Пусть нам дано регулярное событие. Покажем, что можно построить обобщённый источник,
который порождает в точности это событие.

Источник, порождающий какую\д либо букву, строится тривиально: это одно ребро
из $S$ в $E$, на котором написана эта буква.
\cpic{15}{SLetter}{Генератор одной буквы}
Пусть мы умеем строить источники $D_1$ и $D_2$ для событий $M_1$ и $M_2$ соответственно. Тогда источник для
события $M_1M_2$ делается так, как показано на рис.~\picref{SConcat}.
\cpic{16}{SConcat}{Генератор конкатенации}
Для генерации объединения множеств $M_1\cup M_2$ нужно использовать источник, изображённый
на рис.~\picref{SCup}.
\cpic{17}{SCup}{Генератор объединения}
Наконец, для итераций используется источник, изображённый на рис.~\picref{SIter}.
\cpic{18}{SIter}{Генератор итераций}

Итак, по регулярному множеству построен источник.
А теперь по источнику построим автомат, для которого данное множество является представимым.
Пусть $V$\т множество вершин источника. Рассмотрим автомат, в котором состояниями будут подмножества
вершин нашего источника. Таким образом, у него будет $2^{\hm{V}}$ состояний. В качестве выходного
алфавита возьмём $B := \hc{0,1}$, а $B' = \hc{1}$.

Рассмотрим $q_i \subs V$. Рассмотрим то множество вершин, в которое мы можем попасть под действием буквы $a_k$
из вершин, принадлежащих состоянию $q_i$. Получим какое\д то другое подмножество вершин $q_j$.
Таким образом определена функция перехода: $G(a_k, q_i) = q_j$.

Осталось определить отображение выхода: если в $q_j$ попала вершина $E$, то при переходе
$q_i \xra{a_k} q_j$ выдаём на выход $1$, а иначе выдаём $0$. Понятно, что такой автомат в случае регулярного события
выдаёт единицу, а в случае нерегулярного\т ноль.

Это завершает доказательство обещанной теоремы:

\begin{theorem}[Клини]
Всякое регулярное событие является представимым, и наоборот.
\end{theorem}


\subsubsection{О том, чего не могут автоматы}

В заключение мы докажем теорему о том, что не существует никакой конечной полной
системы автоматных функций. Иначе говоря, если
разрешить использовать в схеме вместо $\hc{\neg\,\&\,\vee}$ любые автоматные функции, но запретить
ориентированные циклы, то не существует такого конечного набора автоматных функций, схемой из которых можно
было бы реализовать любой автомат.


\begin{lemma}
Пусть есть автомат с $\la$ состояниями. Пусть на вход ему подаётся периодическая последовательность с периодом $T$.
Тогда выходная последовательность периодична с периодом $Td$, где $d \le \la$.
\end{lemma}
\begin{proof}
Пусть автомату в некоторый момент времени $t_1$ был подан символ $a_1$. Через $T$ шагов ему снова дадут символ $a_1$.
Возможно, автомат окажется в другом состоянии. Ещё через $T$ шагов он снова окажется c тем же входным символом,
и так далее. Число состояний равно $\la$, поэтому не более чем через $\la$ таких циклов (обозначим это количество
через $d$) он по принципу Дирихле дважды побывает в одним и том же состоянии. Начиная с этого момента всё повторится,
а значит, и выход автомата будет периодическим с указанным периодом.
\end{proof}

Через $S_l$ будем обозначать множество периодических последовательностей, у которых длина минимального
имеет среди своих простых делителей лишь числа не больше $l$.

\begin{imp}
Пусть на вход автомата c не более чем $l$ состояниями подаётся последовательность из $S_l$. Тогда на выходе
тоже будет последовательность из $S_l$.
\end{imp}

\begin{imp}
Пусть есть схема из автоматных функций, каждая из которых имеет не более $l$ состояний. Если на вход подаётся
последовательность из $S_l$, то на выходе будет последовательность из $S_l$.
\end{imp}

\begin{note}
У всей схемы состояний, конечно, может быть будет гораздо больше, но простые делители периодов всё равно не
будут превосходить $l$.
\end{note}

\begin{theorem}
Не существует конечной полной системы автоматных функций.
\end{theorem}
\begin{proof}
Допустим, что она существует: $\Fc_1\sco \Fc_N$. Пусть $\la_i$\т количество состояний автомата $\Fc_i$.
Пусть $l := \max \la_i$.
Рассмотрим автомат, выдающий последовательность (вне зависимости от входных данных)
\eqn{(\ub{0\sco 0,1}_p, \ub{0\sco 0,1}_p,\dots),
}
где $p$\т простое число, б\'ольшее $l$. Будем на вход подавать сплошные нули (очевидно, это последовательность из $S_l$).
По доказанному выход любого автомата, построенного на базисе $\hc{F_i}$,
должен быть из $S_l$, а у этого автомата это не так. Противоречие.
\end{proof}

\end{document}
