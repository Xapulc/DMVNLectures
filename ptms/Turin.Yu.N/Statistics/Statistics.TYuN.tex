\documentclass[a4paper,draft]{article}
\usepackage[nodiagram]{dmvn}

%\tocsectionparam{2em}
\tocsubsectionparam{3em}
\tocsubsubsectionparam{4em}

\DeclareMathOperator{\proj}{proj}

\begin{document}
\dmvntitle{Лекции по}{математической статистике}{Лектор\т Юрий Николаевич Тюрин}
{III курс, 5 семестр, поток математиков}{Москва, 2004 г.}

\section*{Предисловие}

Данный документ представляет собой исправленную версию лекций по статистике, первоначально набранную автором курса.
Огромная благодарность объявляется следующим людям: Евгению Гречникову, который исправил много ошибок и опечаток,
а также провёл структурирование документа, а также Кириллу Никитину и Cергею Захарову.

В данной версии сделана еще одна серия исправлений, в основном типографского характера, а также устранены ошибки,
привнесённые предыдущей редакцией.

\hfill Последнее обновление: \сегодня~г.

\pagebreak

\tableofcontents

\section{Введение}

\subsection{Статистическая модель}
\subsubsection{Простейшая модель: выборка}

К общей (абстрактной) статистической модели мы придем, рассмотрев
несколько примеров. Заодно укажем, каким образом статистический
материал можно представить наглядно.

\underline{Пример 1.}

Этот пример я заимствовал из старой книги А. Хальда, которую далее
цитирую.

Хальд приводит результаты измерений 200 головок заклепок. Эти числа
записаны в том порядке, в котором они поступали.

Первичное представление данных\т таблица:
\begin{center}
{\bf Исходные данные}
\end{center}
$$
\begin{tabular}{|cccccccc|}
\hline
\multicolumn{8}{|c|}{Диаметры 200 головок заклепок, {\it мм}}\\
\hline
13,39 & 13,43 & 13,54 & 13,64 & 13,40 & 13,55 & 13,40 & 13,26\\
13,42 & 13,50 & 13,32 & 13,31 & 13,28 & 13,52 & 13,46 & 13,63\\
13,38 & 13,44 & 13,52 & 13,53 & 13,37 & 13,33 & 13,24 & 13,13\\
13,53 & 13,53 & 13,39 & 13,57 & 13,51 & 13,34 & 13,39 & 13,47\\
13,51 & 13,48 & 13,62 & 13,58 & 13,57 & 13,33 & 13,51 & 13,40\\
13,30 & 13,48 & 13,40 & 13,57 & 13,51 & 13,40 & 13,52 & 14,56\\
13,40 & 13,34 & 13,23 & 13,37 & 13,48 & 13,48 & 13,62 & 13,35\\
13,40 & 13,36 & 13,45 & 13,48 & 13,29 & 13,58 & 13,44 & 13,56\\
13,28 & 13,59 & 13,47 & 13,46 & 13,62 & 13,54 & 13,20 & 13,38\\
13,43 & 13,35 & 13,56 & 13,51 & 13,47 & 13,40 & 13,29 & 13,20\\
13,46 & 13,44 & 13,42 & 13,29 & 13,41 & 13,39 & 13,50 & 13,48\\
13,53 & 13,34 & 13,45 & 13,42 & 13,29 & 13,38 & 13,45 & 13,50\\
13,55 & 13,33 & 13,32 & 13,69 & 13,46 & 13,32 & 13,32 & 13,48\\
13,29 & 13,25 & 13,44 & 13,60 & 13,43 & 13,51 & 13,43 & 13,38\\
13,24 & 13,28 & 13,58 & 13,31 & 13,31 & 13,45 & 13,43 & 13,44\\
13,34 & 13,49 & 13,50 & 13,38 & 13,48 & 13,43 & 13,37 & 13,29\\
13,54 & 13,33 & 13,36 & 13,46 & 13,23 & 13,44 & 13,38 & 13,27\\
13,66 & 13,26 & 13,40 & 13,52 & 13,59 & 13,48 & 13,46 & 13,40\\
13,43 & 13,26 & 13,50 & 13,38 & 13,43 & 13,34 & 13,41 & 13,24\\
13,42 & 13,55 & 13,37 & 13,41 & 13,38 & 13,14 & 13,42 & 13,52\\
13,38 & 13,54 & 13,30 & 13,18 & 13,32 & 13,46 & 13,39 & 13,35\\
13,34 & 13,37 & 13,50 & 13,61 & 13,42 & 13,32 & 13,35 & 13,40\\
13,57 & 13,31 & 13,40 & 13,36 & 13,28 & 13,58 & 13,58 & 13,38\\
13,26 & 13,37 & 13,28 & 13,39 & 13,32 & 13,20 & 13,43 & 13,34\\
13,33 & 13,33 & 13,31 & 13,45 & 13,39 & 13,45 & 13,41 & 13,45\\
\hline
\end{tabular}
$$
\begin{center}
{\it Таблица 1.}
\end{center}

Для получения более ясного представления о данных, результаты измерений располагаются в соответствии с их
величиной следующим образом: на бумагу, разграфленную в клетку (обычно\т на миллиметровую бумагу), наносится
горизонтальная прямая и на ней специальным образом размечается шкала. Результаты наблюдений отмечаются тогда
точками над соответствующими числами.

Правильность заполнения точечной диаграммы может быть проверена посредством суммарного подсчета общего числа наблюдений,
произведенного как по таблице исходных данных, так и по точечной диаграмме.

Для того, чтобы иметь возможность проследить появление возможных
ошибок, перечисление и суммирование должно выполняться по группам, в
каждой из которых содержится не более 100 наблюдений.

Контроль суммированием, разумеется, не является вполне надежным, так
как при этом способе контроля противоположные по знаку ошибки могут
скомпенсировать друг друга.

Результаты наблюдений могут перечисляться также при помощи {\it
карт}, причем результат каждого из наблюдений наносится на карту, а
карты сортируются по величине указанных в них результатов.

% TODO: insert picture
% \begin{picture}(500,200)
% \end{picture}
% \begin{center}
% {\it Рисунок 1.}
% \end{center}

{\it Рисунок 1.} дает более ясное представление данных,
 чем первоначальный список из 200 чисел. Представление можно сделать еще
 более наглядным при помощи группировки наблюдений и построения т.н.
{\it гистограмм}. Обратите внимание, как изменение интервалов
группировки отражается на форме гистограмм. На последующих рисунках
можно видеть влияние изменения длины интервала группировки на
внешний вид гистограммы. Частоты и другие величины, связанные с
распределением, используются в качестве ординат после их деления на
длину соответствующих интервалов группировки; поэтому единица
ординаты обратно пропорциональна длине интервала группировки, а $1
\mbox{см}^2$ представляет на всех фигурах одно и то же число
наблюдений.

% TODO: insert 4 pictures
%\begin{picture}(500,200)
%\end{picture}
%\begin{center}
%{\it Рисунок 2.}
%\end{center}
%\begin{picture}(500,180)
%\end{picture}
%\begin{center}
%{\it Рисунок 3.}
%\end{center}
%\begin{picture}(500,180)
%\end{picture}
%\begin{center}
%{\it Рисунок 4.}
%\end{center}
%\begin{picture}(500,200)
%\end{picture}
%\begin{center}
%{\it Рисунок 5.}
%\end{center}

Если длина интервала группировки мала, то влияние случайных
колебаний начинает преобладать, так как каждый интервал содержит при
этом лишь небольшое число наблюдений; если же длина интервала
велика, то скрадываются основные характерные черты распределения.

Гистограммы и точечная диаграмма показывают, что данные из {\it
таблицы 1} ведут себя как совокупность реализаций некой случайной
величины.

В статистике совокупность независимых одинаково распределенных
случайных величин часто называют одним словом: {\it выборка}. (Слово
{\it выборка} имеет в статистике и другое, буквальное значение). Так
что данные из {\it таблицы 1} похожи на выборку. Если разобраться в
деле получше (например, с помощью выборочной функции распределения и
нормальной вероятностной бумаги), то можно убедиться, что эти двести
чисел можно считать выборкой из нормального распределения (выборкой
из нормальной совокупности).

Итак, статистическая модель для 200 чисел этого примера\т это выборка из нормального распределения. Параметры
этого нормального распределения при этом не уточняются; они остаются неопределенными.

Можно указать и некоторые задачи, естественные для этого примера:
\begin{itemize}
\item
оценить неизвестные параметры упомянутого нормального распределения;
\item
указать пределы, в которые укладывается предписанная доля изделий;
\item
проверить высказанное утверждение (предположение), что данная
выборка извлечена из нормальной совокупности;
\item
и т.д.
\end{itemize}

\subsubsection{Простая линейная регрессия}

Рассмотрим данные из статьи Э. Хаббла ({\it E.\,Hubble}) 1929 года,
 где впервые была подтверждена мысль о расширении вселенной (о <<разбегании галактик>>).

Эти данные связывают расстояние от Земли до ближайших туманностей с
лучевыми скоростями этих туманностей.

% TODO: add picture
\begin{center}
{\it Рисунок 6. Данные из статьи E.\,Hubble 1929 года, связывающие
удаления и лучевые скорости \\ 24 туманностей.}
\end{center}

Рисунок наводит нас на мысль (так же, как и Э.\,Хаббла семьдесят лет
назад), что лучевые скорости <<в целом>> пропорциональны удалениям:
$$
y_{i}=\ta x_{i}+\varepsilon_{i},\qquad i=\overline{1,24}.
$$

Здесь:
\begin{itemize}
\item
 $x_{i}$\т удаление $i$-й туманности;
\item
$y_{i}$\т ее лучевая скорость;
\item
$\ep_{i}$\т отступление от линейной зависимости. Эти отступления, возможно,
 объясняются собственными движениями туманностей в пространстве, а также
 ошибками в измерении скоростей и удалений;
\item
коэффициент $\ta$, определяющий скорость расширения пространства,
сейчас
 называют {\it постоянной Хаббла}.
\end{itemize}

Величины удалений и скоростей для тех туманностей, которые отражены
на {\it рисунке 6}, впоследствии были пересмотрены и уточнены,
поэтому оценка для $\ta$ сильно изменилась по сравнению с той,
которую нашел сам Хаббл.

Были также измерены удаления и скорости для многих других
туманностей, находящихся на гораздо больших расстояниях от Земли,
чем первые двадцать четыре, о которых написал Хаббл. Линейный
характер зависимости, тем не менее, сохранился, был убедительно
подтвержден и, в настоящее время, выражен из основных законов
астрономии. Впрочем, численное значение $\ta$ все еще вопрос
дискуссионный (и чрезвычайно важный для теорий возникновения и
эволюции вселенной).

Основное статистическое предположение о $\ep_1\sco\ep_n$: это реализация \emph{независимых случайных
величин}. Именно предположение о {\it случайности} отклонений от
определенной закономерности позволяет называть обсуждаемую модель
явления {\it статистической}. Дальнейшее накопление данных и/или
более глубокий их анализ, а также опыт других задач обычно позволяет
сказать больше о свойствах случайных ошибок $\ep_1\sco\ep_n$:
\begin{itemize}
\item[(a)]
$ \Ef\ep_i=0,\qquad\mbox{ или } P(\ep_i>0)=
P(\ep_i<0)=\frac{1}{2}; $

(Эти предположения выражают мысль об отсутствии в ошибках
 систематической составляющей.)
\item[(b)]
Случайные величины $\ep_{1}\sco\ep_{n}$
одинаково
 распределены;
\item[(c)]
Случайные величины $\ep_{1}\sco\ep_{n}$
распределены
 по (общему) нормальному закону;
\item[(d)]
и т.д.
\end{itemize}

\subsubsection{Общая (абстрактная) статистическая модель}

Имеется наблюдение $X$. Это наш {\it статистический материал}. Все
выводы мы будем делать, основываясь на наблюдении $X$. Его
математическая природа несущественна: $X$ может быть совокупностью
чисел, вектором, матрицей, функцией времени (например, кривой,
записанной самописцем) или пространства и.т.д.

Мы рассматриваем $X$ как точку некоего множества $\Xc$,
называемого {\it пространством наблюдений}, {\it выборочным
пространством}, {\it генеральной совокупностью} и т.д.

Выборочное пространство $\Xc$ мы {\it примысливаем} к нашему реальному наблюдению $X$, собирая вместе
все значения, которые, по нашему мнению, могли появиться вместо конкретного $X$.

Мы предполагаем, что данное значение $X$ появилось как результат
{\it случайного выбора} элемента из $\Xc$. Этот случайный выбор
был произведен в соответствии с некоторым распределением
вероятностей $P$ на $\Xc$. Как правило, это конкретное
распределение $P$ нам не известно. Однако мы можем указать какие-то
свойства, которыми $P$ обладает. Иначе говоря, нам известно (мы
можем указать) некоторое множество ${\cal P}$ вероятностных
распределений на $\Xc$, которому принадлежит неизвестное
истинное распределение $P$.

Задача статистики\т выводы о $P$ на основании $X$. Например, основываясь на $X$, вычислить приближенные
значения функционалов от $P$ или ответить, совместимы ли с наблюденным $X$ предположения о тех или иных
свойствах $P$.

Множество ${\cal P}$ в практических задачах часто оказывается параметризованным с помощью некоторого
параметра $\ta$, который меняется в заданной области $\Ta$. Обычно $\Ta$\т интервал числовой прямой (когда
$\ta$\т одномерный параметр) или область конечномерного пространства (когда $\ta$\т многомерный параметр).

В параметрическом случае:
$$
\Pc= \{P_{\ta } , \ta\in\Ta \}.
$$

В этом случае нас обычно интересует значение $\ta$, отвечающее
 истинному распределению $P_{\ta }$ (истинное значение $\ta$) либо
 значение тех или иных функций $\tau(\ta )$ при истинном $\ta$.
 Основываясь на $X$, мы должны найти для них приближенные значения.

\subsection{Теорема Гливенко}

(Пример того, как по выборке устанавливаются свойства распределения
 вероятностей.)

Пусть $x_{1}\sco x_{n}$\т независимые одинаково
распределенные случайные величины. Их (общую) функцию распределения
обозначим через $F(x)$:
$$
F(x)=P(x_{i}\le x)
$$

Обозначим через $F_{n}(X)$ так называемую {\it эмпирическую} функцию
распределения, которая строится по выборке. Для этого в каждую из
точек $x_{1}\sco x_{n}$ поместим вероятность, равную
$\frac{1}{n}$. На числовой прямой возникнет новое распределение
вероятностей. Его функцию распределения и обозначим через
$F_{n}(X)$. $F_{n}(X)$ называют {\it функцией распределения
выборки}. С помощью индикаторов событий $I(x_{i}\le x)$ функцию
$F_{n}(X)$ можно записать в виде:
$$
F_{n}(x)=\frac{1}{n}\sum\limits^{n}_{i=1}I(x_{i}\le x)
$$

\underline{\it Замечание:}
Часто функцию распределения определяют чуть иначе, чем сказано выше,
 посредством строгих неравенств:
$$
F(x)=P(x_{i}< x).
$$

В этом случае аналогично изменяется и определение функции
распределения выборки. Различие между этими двумя определениями
несущественны:
\begin{itemize}
\item
для непрерывных распределений они совпадают;
\item
для других различие состоит лишь в том, с какой стороны (слева или
справа) функция распределения оказывается непрерывной.
\end{itemize}

Следующая ниже формулировка теоремы Гливенко не зависит от того,
 какой вариант определения мы принимаем.

\begin{theorem}[Гливенко]
Последовательность случайных величин ($n=1, 2, \ldots$)
$$
D_{n}=\supl{x}|F_{n}(x)-F(x)|
$$
сходится к нулю по вероятности при $n\to\infty$.

Другими словами: для любых $\ep >0$, $\delta >0$ найдется
номер
 $N=N(\ep ,\delta )$ такой, что для всех $n\ge N$
$$
P\{\supl{x}|F_{n}(x)-F(x)| < \ep \}>1-\delta.
$$
\end{theorem}
\begin{proof}
\underline{Предварительное замечание:} для всякого $x$
$$
F_{n}(x){\longrightarrow}F(x) ,\qquad n\rightarrow\infty
$$

Это всего лишь переформулировка теоремы Бернулли (о сходимости частоты события к его вероятности в
последовательности независимых испытаний) для события $\{x_{i}\le x\}$.

Сначала доказательство проведем для непрерывной функции $F(\cdot)$. С небольшими изменениями это окажется
справедливым и для разрывных функций  распределения, о чем будет сказано ниже.

\begin{points}{-2}
\item Пусть $R$\т натуральное число. Его выбор уточним позже. Разобьем отрезок $[0, 1]$ оси ординат на $R$
равных частей. Одновременно, на $R$ отрезков $\De_1 \sco \De_R$ будет разделена и ось абсцисс точками
$$
-\infty=a_{0}<a_{1}<\ldots <a_{R}=+\infty,
$$
где $\De_{k}=[a_{k-1}, a_{k}]$, $F(a_{k})=k/R$, $k=0, 1, \ldots, R$.

Пусть $\ep' >0$, выбор $\ep'$ уточним позже. Рассмотрим событие
$$\Om_{n} =\left\{\maxl{1\le k\le R-1} |F_{n}(a_{k})-F(a_{k})|< \ep'\right\}$$

По теореме Бернулли существует $N=N(\ep',\delta)$ такое, что для всех $n\ge N$
$$P(\Om_{n})>1-\delta.$$
(Другими словами: следствием сходимости в каждой точке является
равномерная сходимость на каждом конечном множестве точек.)

\item Теперь покажем, что, если произошло событие $\Om_{n}$, то (при правильном выборе $\ep'$ и $R$)
$$\supl{-\infty <\,x<\,\infty }|F_{n}(x)-F(x)|<\ep.$$

Ясно, что
$$
\supl{-\infty <x<\infty }|F_{n}(x)-F(x)|=\maxl{k=1,\ldots ,R}\;\supl{x\in\De_{k}}|F_{n}(x)-F(x)|
$$

Поэтому достаточно показать, что если произошло событие
$\Om_{n}$, то для каждого $k=\overline{1,R}$
$$
\supl{x\in\De_{k}}|F_{n}(x)-F(x)|<\ep . \eqno (*)
$$

Поскольку для любой функции $f(\cdot)$
$$
\sup\nolimits |f(x)|=\max \big[\sup f(x),\,\sup (-f(x))\,\big],
$$
для доказательства $(*)$ достаточно оценить сверху порознь
$$
\supl{x\in\De_{k}}[F_{n}(x)-F(x)]\, \mbox{  и  } \supl{x\in\De_{k}}[F(x)-F_{n}(x)]
$$

Оценим только первое из двух выражений, поскольку вторая оценка
получается аналогично.

\item В силу того, что функции распределения $F(\cdot)$ и $F_{n}(\cdot)$ монотонно неубывают, при
$x\in\De_{k}=[a_{k-1},a_{k}]$:
$$
F_{n}(x)-F(x)\le F_{n}(a_{k})-F(a_{k-1})= [F_{n}(a_{k})-F(a_{k})]+
[F(a_{k})-F(a_{k-1})]= [F_{n}(a_{k})-F(a_{k})]+\frac{1}{R}
$$

Если произошло событие $\Om_{n}$, то цепочку можно продолжить и
написать:
$$
F_{n}(x)-F(x)\le\ep'+\frac{1}{R}
$$

Причем это верно для каждого отрезка $\De_{k}$.

Если $R$ и $\ep'$ выбрать так, что
$\frac{1}{R}+\ep'<\ep$, то получим, что (при $n\ge
N(\ep',\delta)$)
$$
\Om_{n}\subset \{\supl{x}|F_{n}(x)-F(x)|<\ep \}.
$$

Для непрерывных $F(\cdot)$ доказательство окончено, поскольку
$P(\Om_{n})>1-\delta$ для всех достаточно больших $n$.

Для функций с разрывами то же доказательство проходит с некоторыми
изменениями.

\item Взамен последовательности ($a_{0}, a_{1}\sco a_{R}$) рассмотрим последовательность
$$
-\infty=b_{0}< b_{1}<\ldots <b_{K}=+\infty
$$
такую, что приращение $F(\cdot)$ на каждом интервале
$(b_{k-1},b_{k})$,
 $k=\overline{1,K}$, не превосходит $\ep /2$:
$$
|F(b_{k}-0)-F(b_{k-1}+0)|\le\frac{\ep}{2}.$$

(Пишем пределы слева и пределы справа вместо того, чтобы в одном
случае написать значение функции в точке, с тем, чтобы выкладка
годилась для обоих определений функции распределения: для
$P(x_{i}\le x)$ и для $P(x_{i}<x)$.)

Как можно построить такую последовательность, показано на рисунке.
% TODO: insert picture

В частности, в последовательность ($b_{0}, b_{1},\ldots ,b_{K}$) войдут все точки скачков функции $F$,
которые превосходят $\ep /2$  (их конечное число).

\item Событие $\Om_{n}$, которое ранее было связано с последовательностью $a_{0}, a_{1},\ldots ,a_{R}$,
теперь определим так:
$$
\Om_{n} =\hc{\maxl{1\le\, k\le K-1} \Big[|F_{n}(b_{k}+0)-F(b_{k}+0)|,
|F_{n}(b_{k}-0)-F(b_{k}-0)|\Big]<\frac{\ep }{2}}.
$$

По теореме Бернулли (как и раньше), для достаточно больших $n$
$$
P(\Om_{n})>1-\delta
$$
\end{points}
С этим изменением доказательство проходит также, как и раньше.
\end{proof}

Мы доказали, что $F_n$ равномерно сходится к $F$ по вероятности.
Более сильная форма этой теоремы (которая и была доказана ее
авторами:  Гливенко\т для непрерывного случая, Кантелли\т для общего) утверждает
сходимость с вероятностью 1.

Соотношение между этими двумя теоремами о сходимости $F_{n}$ к $F$
такое же, как между просто законом больших чисел и усиленным законом
больших чисел. (Теорема Гливенко\ч Кантелли и есть закон больших чисел
в функциональном пространстве).

Впрочем, для практики, имеющей дело с конечными выборками,
сходимость с
 вероятностью 1 дает не больше, чем сходимость по вероятности:
\begin{itemize}
\item
Если $\xi_{n}\longrightarrow\xi$ (почти наверно или по вероятности), то для данной нам выборки (для данного
$n$) это означает лишь, что $\xi_{n}$ приближенно равна $\xi$ (если, к тому же, <<$n$ достаточно велико>>).
\end{itemize}

Поэтому мы будем рассматривать только <<слабые>> предельные теоремы, утверждающие сходимость по вероятности,
даже если известны их усиленные варианты.

\section{Статистические оценки}

\subsection{Абстрактная статистическая модель, решающие правила}

Имеется наблюдение $X$ (так мы обозначаем имеющийся статистический
материал. Его математическая природа не важна: это может быть набор
чисел; числовая последовательность; запись, сделанная самописцем, и
т.п.), К имеющемуся наблюдению $X$ мы примысливаем множество $\Xc$, $X\in\Xc$, называемое \emph{выборочным пространством}. Выборочное
пространство\т это совокупность таких исходов, которые могли бы
появиться в нашем опыте вместо $X$. Мы предполагаем, что элемент $X$
был выбран из множества $\Xc$ случайно (случайный выбор),
согласно некоторому распределению вероятностей на $\Xc$.

Это вероятностное распределение $P$, на множестве $\Xc$ нам,
как правило, не известно. Исходя из условий опыта, мы можем указать
лишь некоторые свойства $P$. Иначе говоря, мы можем указать
совокупность ${\cal P}$ вероятностных мер на $\Xc$, которой
принадлежит распределение $P$.

В этой схеме задачей математической статистики являются выводы о
распределении $P$, которые можно получить на основании наблюдения
$X$.

Во многих (но не всех!) практически важных случаях множество ${\cal
P}$ имеет естественную параметризацию, так что ${\cal
P}=\{P_{\ta}: \ta\in\Ta\}$,
 где заданное параметрическое множество $\Ta$ принадлежит конечномерному
 (арифметическому) пространству.

Статистические задачи часто представляют в параметрической форме. В
этом случае нас интересуют выводы о значении  $\ta$.

\subsection{Постановка задачи}

В этой главе мы будем обсуждать задачу оценивания параметра $\ta$
и/или функций от  $\ta$. <<Оценить>> здесь означает <<указать
приближенное значение, опираясь на наблюдение $X$>>. Надо найти
правило $\delta(\cdot)$, по которому каждое возможное наблюдение
$X\in\Xc$ пересчитывается в значение $\delta(X)$, которое далее
выступает как приближенное значение неизвестного параметра $\ta:
\delta(X)\approx\ta$. [Либо как приближенное значение для
 $\tau(\ta)$ , если нас интересует не сам параметр  $\ta$, а некоторая
 функция от него. В этом случае функция $\tau(\cdot)$ должна быть задана.]
Задача статистики: выбрать правило $\delta(\cdot)$ так, чтобы
оценить $\ta$ как можно лучше (точнее).

Можно предложить очень много способов, измеряющих близость $\delta(X)$ и  $\ta$. Общая точка зрения: есть
функция потерь $L(\ta,d)\ge 0$, принимающая определенное числовое значение, когда в качестве оценки истинного
$\ta$ выступает величина $d$. В случае наблюдения $X$ и правила оценивания $\delta(\cdot)$ величина  потерь
составляет $L(\ta,\delta(X))$. Например, может быть
$$L(\ta,\delta(X))=|\ta - \delta(X)| \text{ или } L(\ta,\delta(X))=|\ta-\delta(X)|^{2}.$$

В каждом отдельном опыте величина потерь случайна. В статистике
принято характеризовать статистические правила средними
результатами, достигаемыми при многократном применении.

По закону больших чисел это:
$$
\Ef_{\ta}L(\ta,\delta(X))
$$
(Разъяснение обозначений: так как мы должны держать в уме все
возможные
 значения параметра  $\ta\in\Ta$, нам следует указывать, по какой
 именно мере мы производим усреднение, \те вычисляем математическое
ожидание. Индекс  $\ta$ около символа усреднения $\Ef$ или
вероятности $P$ явно указывает на это) Таким образом, точность (а,
скорее, неточность) правила $\delta$ описывает теперь {\it функция
риска}
$$
R(\ta,\delta ):=\Ef_{\ta}L(\ta,\delta )
$$

Ясно, что правило $\delta_{1}(\cdot)$ лучше, чем правило
$\delta_{2}(\cdot)$,
 если
$$
R(\ta,\delta_{1} )\le R(\ta,\delta_{2} ) \eqno (*)
$$
при всех $\ta\in\Ta$ (а для некоторых значений  $\ta$ это
соотношение
 есть строгое неравенство). Наилучшим следует назвать такое правило
$\delta(\cdot)$, которое превосходит любое другое правило.

К сожалению, наилучшего в этом смысле правила обычно не существует,
ибо здесь
 речь идет о сравнении функций. В множестве функций от  $\ta$ вида
 $ R(\ta,\delta )$ (где $\delta(\cdot)$\т функция от наблюдений) обычно нет
 минимального элемента. (Хотя бы потому, что правило $\delta(X)=\ta_{0}$,
где $\ta_{0}$\т фиксированное значение, нельзя улучшить в точке $\ta=\ta_{0}$. Хотя при других  $\ta$ это
правило никуда не
 годится.)

Для преодоления этого затруднения есть две главные возможности. Первая\т это изучение {\it допустимых}
правил.

\begin{description}
\item[\underline{Определение:}]
 Правило $\delta_{1}(\cdot)$ называют
 {\it допустимым}, если не существует $\delta_{2}(\cdot)$, для которого
выполняется $(*)$.
\end{description}

Допустимые правила, по существу, совпадают с так называемыми \emph{байесовскими правилами}.
\begin{description}
\item[\underline{Определение:}] \emph{Байесовские правила}\т это оптимальные
правила в ситуации, когда неизвестный параметр  $\ta$ получен
путем случайного выбора.
\end{description}

В этом случае риск $R(\ta,\delta )$ естественно усреднить еще и по  $\ta$\ по той (вероятностной) мере,
которая управляла выбором  $\ta$. Риск правила $\delta(\cdot)$ после этого превращается в число. Поэтому
задача о минимуме имеет решение.

 Взгляд на  $\ta$ как на случайную величину называют
{\it байесовским подходом} к статистике. Он имеет как горячих
сторонников,
 так и противников. Мы не будем касаться его в этом курсе.

Другая возможность\т продолжение поиска {\it оптимальных} (т.е. равномерно наилучших правил) $\delta(\cdot)$,
но в более узком множестве
 возможностей. Сужение поля выбора достигаются путем наложения на оценку
$\delta(\cdot)$ каких-либо дополнительных (и естественных)
требований.
 Наиболее важные результаты получены для {\it несмещённых} правил.

\begin{description}
\item[\underline{Определение:}]
Оценка $\delta(\cdot)$ параметра  $\ta$ (либо функции $\tau
(\ta )$)
 называется {\it несмещенной}, если  $\Ef_{\ta}\delta(X)=\ta$
(либо $\Ef_{\ta}\delta(X)=\tau(\ta)$) для всех
$\ta\in\Ta$.
\end{description}

Для важной с прикладной точки зрения линейной статистической модели удается найти наилучшие несмещённые
оценки, если выбрать квадратичную функцию потерь $L(\ta,d)=|\ta-d|^{2}$ (или даже функцию потерь с матричными
значениями $L(\ta,d)=(\ta -d)(\ta -d)^{T}$\т считая $\ta$ и $d$ векторами-столбцами). В следующей главе
линейная модель будет изучена нами подробно.

Из этого короткого рассказа видно, насколько неопределенным и зависящим от нашего произвола является путь к
оптимальным статистическим решениям. На его выбор влияют не только логические соображения (они недостаточны),
но и (в основном) конечный результат: удается ли получить в его конце явные и разумные статистические
правила.

Для несмещенных оценок и квадратичной функции потерь функция риска оценки $\delta (\cdot )$ превращается в
дисперсию (в векторном случае\т в матрицу ковариаций):
$R(\ta,\delta)=\Ef_{\ta}(\delta(X)-\ta)^{2}=\Ef_{\ta}(\delta(X)-\Ef_{\ta}\delta(X))^{2}$ .Задача теперь
выглядит очень естественно: надо найти несмещенную оценку с наименьшей дисперсией. Однако подробнее этой
задачей мы займемся несколько позже.

А сейчас приведем важные для теории неравенства, которые в так называемом <<регулярном случае>> ограничивают
снизу дисперсию (для многомерного параметра\т матрицу ковариаций) каждой оценки. Для несмещенных оценок
именно дисперсия (матрица ковариаций) служит естественной мерой точности оценивания. Поэтому обсуждаемые
неравенства показывают, что для точности оценивания есть граница снизу. Эта граница зависит от структуры
статистической модели (и ее параметризации).

\subsection{Неравенство Крамера\ч Рао для одномерного параметра}

Это неравенство еще называется неравенством информации или неравенством Фреше.

Так называют неравенство для дисперсии статистических оценок одномерного параметра, которое можно вывести при
многочисленных условиях гладкости, налагаемых на зависимость вероятностного распределения от меняющегося
параметра. Такой тип зависимости от параметра, который ниже будет описан подробнее, часто называют {\it
регулярным}. Впрочем, содержание этого термина будет меняться от задачи к задаче.

Пусть $X$\т наблюдение (конечномерный вектор), распределение которого зависит от неизвестного параметра
$\ta$, причем $\ta\in\Ta\subset \R^1$, где $\ta$\т заданное открытое множество.

Отдельно будем рассматривать две возможности:

\begin{description}
\item[(a)]
$X$ имеет плотность $p(x,\ta)$ (относительно меры Лебега)
\item[(b)]
наблюдение $X$ имеет дискретное распределение; в этом случае
$p(x,\ta)$ означает вероятность события $X$; $p(x,\ta)>0$
только для счетного множества значений $x$.
\end{description}

Выкладки в обоих случаях идут одинаково\т с той разницей, что в случае (a)
 для математических ожиданий мы пишем интегралы, а случае (b)\т суммы (ряды).
Поэтому достаточно разобрать в подробностях какую-либо одну из этих
двух
 возможностей, скажем, (a).

Пусть $T(X)$\т некоторая статистика, принимающая значения в $\R^1$, для которой существует математическое
ожидание и дисперсия.

Пусть
$$
\tau(\ta):=\Ef_{\ta}T(X)
$$

\begin{center}
{\bf Предположения о плотности $p(x,\ta)$}
\end{center}
(взятые вместе они и составляют условия регулярности).
\begin{description}
\item[(a)]
Множество $A=\{x:p(x,\ta)>0\}$ не зависит от  $\ta$ (это наиболее важное условие).
\item[(b)]
При всех $x\in A$, $\ta\in\Ta$ существует
$$
\la(x,\ta):=\frac{\pd}{\pd\ta}\ln p(x,\ta)
$$
\item[(c)]
(Возможность дифференцирования под знаком интеграла)
$$
\frac{\pd}{\pd\ta}\int\limits_{A} p(x,\ta)dx=
\int\limits_{A} \frac{\pd}{\pd\ta} p(x,\ta)dx (=0),
$$
$$
\frac{\pd}{\pd\ta}\int\limits_{A} T(x)p(x,\ta)dx=
\int\limits_{A}T(x)\frac{\pd}{\pd\ta} p(x,\ta)dx
(=\tau'(\ta)).
$$

Введем важное понятие информации по Фишеру, точнее, количества
информации о параметре  $\ta$, содержащейся в наблюдении $X$:
$$
I(\ta):=\Ef_{\ta}\left[\frac{\pd}{\pd\ta} \ln p(X,
\ta)\right]^{2}=\Ef_{\ta}\la^{2}(X,\ta)
$$

Последнее из условий регулярности:
\item[(d)]
$$0<I(\ta)<\infty $$
\end{description}

\begin{theorem}[неравенство Крамера\ч Рао]
В перечисленных условиях (a)-(d)
$$
\Df _{\ta}T(X)\ge\frac{[\tau'(\ta)]^{2}}{I(\ta)}\eqno (*)
$$
Для несмещенных оценок параметра  $\ta$, когда
$\tau(\ta)=\ta$,
 из этого неравенства следует, что
$$
\Df _{\ta}T(X)\ge\frac{1}{I(\ta)}
$$
\end{theorem}
\begin{proof}
\begin{points}{-2}
\item Заметим, что $\Ef_{\ta}\la(X,\ta)=0$. Действительно, из (c)
мы
 заключаем, что:
$$
0=\int\limits_{A} \frac{\pd}{\pd\ta} p(x,\ta)dx=
\int\limits_{A} \left[\frac{\pd}{\pd\ta} \ln
p(x,\ta)\right] p(x,\ta)dx=\Ef_{\ta}\la(X,\ta).
$$
\item
Аналогично, из второго равенства (c) мы получаем, что
$$
\tau'(\ta)=\int\limits_{A}
T(x)\left[\frac{\pd}{\pd\ta} \ln p(x,\ta)\right]
p(x,\ta)dx=\Ef_{\ta}T(X)\la(X,\ta)=
\Ef_{\ta}[T(X)-\tau(\ta)]\la(X,\ta).
$$
Последнее равенство\т благодаря тому, что $\Ef_{\ta}\la(X,\ta)=0$.
\item
Неравенство Коши\ч Буняковского:
$$
(\Ef\xi\eta)^{2}\le \Ef\xi^{2}\Ef\eta^{2}
$$
применим к полученному в 2) равенству, полагая
$\xi=T(X)-\tau(\ta)$, $\eta=\la(X,\ta)$. Получим, что:
$$
[\tau'(\ta)]^{2}\le I(\ta)\Df _{\ta}T(X).
$$
\end{points}
Отсюда и следует указанное в теореме неравенство.
\end{proof}

{\bf\underline{Замечание 1.}} Пусть $X=(X_{1}\sco X_{n})$\т выборка. Можно говорить о количестве
информации, заключённой в выборке $X$\т пусть это $I_{X}(\ta)$, и о количестве информации, содержащейся в
отдельных наблюдениях (элементах выборки) пусть это $i(\ta)$.

В этих условиях
$$
I_{X}(\ta)=ni(\ta)
$$

{\it Доказательство:}

Совместная плотность $X=(X_1,\ldots,X_n)$ равна $\prod\limits_{i=1}^{n}f(X_{i},\ta)$, где через
$f(\cdot,\ta)$ обозначена плотность вероятностей отдельных $X_i$.
$$
\la(X,\ta)=\sum\limits_{i=1}^{n}\frac{\pd}{\pd\ta}\ln
f(X_{i},\ta); \leqno \mbox{ Отсюда:}
$$
$$
\Df _{\ta}\la(X,\ta)=\sum\limits_{i=1}^{n}\Ef\left[\frac{\pd}{\pd\ta}\ln
f(X_{i},\ta)\right]^{2}=ni(\ta).\eqno{\Box}
$$
Из сказанного можно вывести важное качественное следствие о
возможной скорости уменьшения дисперсии несмещенной оценки при
возрастании числа независимых наблюдений $n$: $$\Df _{\ta}T(X)\ge
C/n, \qquad\mbox{  где  } C=[i(\ta)]^{-1}.$$

{\bf\underline{Замечание 2.}}
$$
I(\ta)=-\Ef_{\ta}\frac{\pd^{2}}{\pd\ta^{2}}\ln
p(X,\ta).
$$

\subsection{Экспоненциальные семейства}

Случай, когда неравенство Крамера\ч Рао $(*)$ выполняется в виде
равенства, заслуживает особого рассмотрения. При выводе $(*)$ мы
применили неравенство Коши:
$$
(\Ef\xi\eta)^{2}\le \Ef\xi^{2}\Ef\eta^{2}\eqno(2.4.1)
$$
в котором равенство достигается т. и т.т., когда между случайными
величинами $\xi$ и $\eta$ существует линейная связь. Иначе говоря,
когда существуют такие постоянные (такие числа) $A, B, C$, что с
вероятностью 1 выполняется равенство
$$
A\xi+B\eta+C=0\eqno (2.4.2)
$$
В нашем случае $\xi=\la(X,\ta)$, $\eta=T(X)-\tau(\ta)$.
Для них приведенное выше равенство превращается в
$$
T(X)=\tau(\ta)+a(\ta)\la(X,\ta) \eqno (2.4.3)
$$
где $a(\ta)$\т некоторая функция  $\ta$. Постоянная $C=0$, т.к. здесь математические ожидания $\xi$ и $\eta$
равны нулю.

Оценка $T(X)$, для которой в $(*)$ (или, что эквивалентно, в
(2.4.3)) имеет место равенство (при всех ${\ta\in\Ta}$),
называется {\it эффективной}. Существуют эффективные оценки лишь для
особых параметрических семейств распределений и лишь для некоторых
функций $\tau$.

Вид этих параметрических семейств мы сейчас установим. Исходим из
равенства (2.4.3). Это равенство для плотности (вероятности)
$p(x,\ta)$ дает уравнение
$$
\frac{\pd}{\pd\ta}\ln p(x,\ta)=
\frac{1}{a(\ta)}T(X)+\frac{\tau(\ta)}{a(\ta)}
$$
для всех $x\in A$ (см. условия регулярности) и всех
$\ta\in\Ta$. Интегрируя, для $p(x,\ta)$ получаем выражение:
$$
p(x,\ta)=\exp{\{(c(\ta)T(x)+d(\ta)+S(x))\}}I_{A}(x) \eqno
(2.4.4)
$$

Здесь $c(\ta), d(\ta), S(X)$\т некоторые функции, зависящие только
 от указанных аргументов, $I_{A}(x)$\т индикаторная функция множества $A$.
(Заметим, что представление плотности в виде (2.4.4) не
единственно).

Семейство распределений, плотности (вероятности) которого имеют вид
(2.4.4), называют {\it экспоненциальным семейством}. Для
экспоненциального семейства
 эффективная оценка существует для функции
 $\tau(\ta)=-\frac{d'(\ta)}{c'(\ta)}$.

Распределение выборки из экспоненциального семейства, т.е.
распределение
 совокупности $n$ независимых реализаций $(X_{1}\sco X_{n})$
 случайной величины, принадлежащей экспоненциальному семейству (2.4.4),
 очевидным образом, в свою очередь, принадлежит экспоненциальному
 семейству с плотностью (вероятностью):
$$
p(x_{1}\sco x_{n},\ta)=
\exp\left[c(\ta)\sumiun T(x_{i})+nd(\ta)+ \sumiun S(x_{i})\right]I_{A\st A}(x_{1},
\ldots, x_{n}).
$$

Многие практически важные параметрические распределения входят в
этот класс.
 Например:

\begin{items}{-2}
\item \textbf{Биномиальное распределение}, где:
$$
p(x,\ta)=\Cb_n^x \ta^{x}(1-\ta)^{n-x}=
\exp\hr{{x\ln{\frac{\ta}{1-\ta}}+n\ln (1-\ta)+\ln \Cb_n^x}}
$$
для $x=0, 1, \ldots, n; 0<\ta<1$ . Есть эффективная оценка $X/n$
для параметра  $\ta$.

\item \textbf{Показательное распределение} с параметром $\ta > 0$, где
$$
p(x,\ta)=\case{\frac{1}{\ta}\exp\left(-\frac{x}{\ta}\right)
& \text{ для } x \ge 0\\
0 & \text{ для } x \le 0}
$$
Для выборки
$$
p(x_{1}, \ldots, x_{n},\ta)=\left(\frac{1}{\ta}\right)^{n}
\exp\left(-\frac{1}{\ta}\sum\limits_{i=1}^{n}x_{i}\right), x\ge
0, \ta > 0.
$$
Для параметра  $\ta$ есть эффективная оценка
$\sum\limits_{i=1}^{n}X_{i}/n$.
\end{items}

В заключение отметим, что эффективная оценка может быть только одна
(то есть только для одной функции $\tau(\ta)$ и ее линейных
комбинаций). Чтобы доказать это, допустим противоположное: для
некоторого параметрического семейства есть два равенства вида
(2.4.3):
$$
\case{T_1=\tau_1(\ta)+a_1(\ta)\la(X,\ta); \\
T_2=\tau_2(\ta)+a_2(\ta)\la(X,\ta).} \eqno (2.4.5)
$$

Умножив второе равенство на $\frac{a_1(\ta)}{a_2(\ta)}$ и
вычтя результат из первого, получим, что:
$$
T_{1}(X)=\tau_{1}(\ta)-\frac{a_{1}(\ta)}{a_{2}(\ta)}\tau_{2}(\ta)+\frac{a_{1}(\ta)}{a_{2}(\ta)}T_{2}(X)
\eqno (2.4.6)
$$
Равенство (2.4.6) возможно, только если:
$$
\frac{a_1 (\ta)}{a_{2}(\ta)}=\const,\\
 \tau_{1}(\ta)-\frac{a_{1}(\ta)}{a_{2}(\ta)}\tau_{2}(\ta)=\const
\eqno (2.4.7)
$$

Действительно,
$T_{1}(X)-\frac{a_{1}(\ta)}{a_{2}(\ta)}T_{2}(X)$ не должно
изменяться, когда изменяется $X, X\in A$. Это возможно, только если
 $a_{1}(\ta)/a_{2}(\ta)$ не изменяется, когда изменяется
 $\ta\in\Ta$.

Из (3.6) следует, что все эффективные оценки линейно выражаются одна
через другую (см. (3.5)), как и соответствующие функции
$\tau(\ta)$.

\subsection{Статистические оценки для многомерных параметров}

\subsubsection{Случайные векторы, их средние и дисперсии}

Пусть $X$\т случайный объект (случайная величина, случайный вектор и т.п.),
 распределение которого \, определено параметром $\ta$.

Предположим, что $\ta$\т $r$-мерный параметр, который мы будем представлять в виде столбца: $\ta=(\ta_{1},
\ldots, \ta_{r})^{T}$, $\ta\in\Ta\subset \R^r$,
 где $\Ta$\т заданное открытое множество. Рассмотрим задачу оценивания
$\ta$ или функций от $\ta$ по наблюдению $X$. Ясно, что в
качестве
 оценки $\ta$ или $\tau(\ta)$ должны выступать случайные векторы
соответствующей размерности (функции от $X$).

Поэтому предварительно надо напомнить, что такое случайный вектор,
случайная матрица, их математические ожидания и ковариации, вместе с
некоторыми свойствами этих объектов. Случайный вектор при этом есть
частный случай
 случайной матрицы.
\begin{description}
\item[\underline{Определение 1.}]
Случайная матрица $Z$ есть матрица, элементы $z_{ij}$ которой суть
 случайные величины, заданные на общем пространстве элементарных исходов,
т.е. имеющие совместное распределение вероятностей.
\item[\underline{Определение 2.}]
Математическое ожидание случайной матрицы $Z=\|z_{ij}\|$ есть
$$
\Ef Z=\|\Ef z_{ij}\|
$$
\item[{\it\underline{Утверждение 1.}}]
Пусть $Z$\т случайная матрица, а постоянные матрицы
 $A$, $B$ и $C$ таковы, что матрица $AZB+C$ существует, то есть
 Размерности матриц $A, B, Z$ и $C$ согласованы. Тогда:
$$
\Ef(AZB+C)=A(\Ef Z)B+C
$$
В частности, если $Y$\т случайный вектор, $A$\т постоянная матрица и $b$\т постоянный вектор, то
$$
\Ef(AY+b)=A(\Ef Y)+b,
$$
когда указанные операции (умножения и сложения) осуществимы.
\item[{\it\underline{Утверждение 2.}}]
Пусть $Z_{1}$ и $Z_{2}$\т две случайные матрицы, определенные на общем пространстве элементарных исходов.
Пусть их размерности совпадают, так что матрица $Z_{1}+Z_{2}$ существует. Тогда:
$$
\Ef(Z_1+Z_2)=\Ef Z_1+\Ef Z_2.
$$

Утверждения 1 и 2 вместе показывают, что операция взятия
математического ожидания для случайных матриц обладает привычными
для этой операции над случайной величиной \underline{линейными
свойствами}. Правда, с учетом того, что умножение матриц не
коммутативно.

Пусть $X$ и $Y$\т два случайных вектора (произвольных размерностей, не обязательно одинаковых), имеющие
совместное распределение. Векторы мы
 предпочтительно будем представлять в виде векторов-столбцов (одностолбцовых
 матриц).

\item[\underline{Определение 3.}]
Ковариационная матрица (она же\т дисперсионная матрица) векторов $X$ и $Y$ есть
$$
\cov (X, Y)=\Ef(X-\Ef X)(Y-\Ef Y)^{T}.
$$

Если $X=(\xi_{1}, \xi_{2}, \ldots)^{T}$, $Y=(\eta_{1}, \eta_{2},
\ldots)^T$, то элемент $(i,j)$ матрицы $\cov (X, Y)$ есть ковариация
случайных величин $\xi_{i}$ и $\eta_{j}$:
$$
\Ef(\xi_{i}-\Ef\xi_{i})(\eta_{j}-\Ef\eta_{j}).
$$

Ясно, что:
$$
\cov (X, Y)=\Ef XY^{T}-(\Ef X)(\Ef Y)^{T}.
$$
\item[\underline{Определение 4.}]
Ковариационная матрица случайного вектора $X$ определяется как:
$$
\cov (X, X)=\Ef(X-\Ef X)(X-\Ef X)^{T}=\Ef XX^{T}-(\Ef X)(\Ef X)^{T}.
$$

Диагональные элементы этой матрицы суть дисперсии случайных
величин $\xi_i$. Обозначение $\cov(X, X)$ мы будем заменять коротким $\Df X$.
\item[{\it\underline{Утверждение 3.}}]
Пусть $X$\т случайная величина, $A$\т неслучайная (постоянная) матрица,
 $b$\т неслучайный (постоянный) вектор. Тогда:
$$
\Df (AX+b)=A(\Df X)A^{T},
$$
если $AX+b$ существует (если указанные операции осуществимы, т.е.
размерности
 $A, X$ и $b$ согласованы).

Частный случай: скалярное произведение. Пусть $A$\т матрица, состоящая из одной строки. Рассмотрим $A$ как
результат транспонирования некоторого вектора $a$ (вектора-столбца): $A=a^{T}$. При этом $AX=a^{T}X$\т есть
скалярное произведение векторов $a$ и $X$.

\item[{\it\underline{Утверждение 4.}}]
$$
\Df (a^{T}X)=a^{T}(\Df X)a
$$

\end{description}

\subsubsection{Квадратичный риск в многомерном случае}
Вернемся к поставленной в начале этого параграфа задаче. Пусть $\ph(\cdot)$\т некоторая вектор-функция,
$\ph(X)$\т оценка  $\tau(\ta)$ (это векторы-столбцы), и пусть $\Ef_{\ta}\ph(X)=\tau(\ta)$, где
$\tau(\ta)=(\tau_{1}(\ta)\sco \tau_{d}(\ta))^{T}$, $\ta\in\Ta\subset \R^{r}$.

Как и в одномерном (однопараметрическом) случае мы готовимся указать границу снизу для квадратичного риска
несмещенной оценки. Но прежде надо уточнить, что такое квадратичный риск в многомерном случае и как следует
сравнивать квадратичные риски\т например, двух разных оценок.

Пусть $\ph(X)$, $\psi(X)$\т две несмещенные оценки $\tau(\ta)$. Какая из них лучше? Попробуем найти ответ,
обратившись к уже изученному одномерному случаю. Выберем произвольный неслучайный вектор. Перейдем от
$\ph(X)$, $\psi(X)$, $\tau(\ta)$ к линейным формам (скалярным произведениям) $\xi:=z^{T}\ph(X)$,
$\eta:=z^{T}\psi(X)$, $t(\ta):=z^{T}\tau(\ta)$.
 Ясно, что
$$
\Ef_{\ta}\xi=\Ef_{\ta}\eta=t(\ta),
$$
так что $\xi$ и $\eta$ суть несмещенные (одномерные) оценки
$t(\ta)$.
 В одномерном случае (при квадратичной функции потерь) из двух несмещенных
 оценок лучше та, чья дисперсия меньше. В частности, $\xi$ не хуже, чем $\eta$,
 если $\Df \xi\le \Df \eta$ или:
$$
z^{T}[\Df _{\ta}\ph(X)]z\le z^{T}[\Df _{\ta}\psi(X)]z \eqno (*)
$$

Мы можем принять такое определение:
 $\ph(X)$ лучше, чем $\psi(X)$, если $(*)$ выполняется для
 \underline{любого} вектора $z\in \R^d$ (и для некоторых $z$ это неравенство
строгое).

По отношению к переменному $z\in \R^{d}$ выражения $z^{T}[\Df _{\ta}\ph(X)]z$ и
 $z^{T}[\Df _{\ta}\psi(X)]z$ представляют собой квадратичные формы
(неотрицательно определенные). Неравенство $(*)$, если оно
выполняется для всех $z$, линейная алгебра истолковывает как
соотношение между матрицами
 квадратичных форм. В данном случае, между матрицами ковариаций
$\Df _{\ta}\ph(X)$ и $\Df _{\ta}\psi(X)$:
 $\Df _{\ta}\ph(X)\le \Df _{\ta}\psi(X)$

Итак, мы пришли к заключению, что {\it квадратичным риском} статистики $\ph(X)$, несмещённо оценивающей
$\tau(\ta)$, можно назвать ее матрицу ковариаций:
\equ{\Df_{\ta}\ph=\Ef_{\ta}[\ph(X)-\tau(\ta)][\ph(X)-\tau(\ta)]^{T}.}

Из двух несмещенных оценок лучше та, чья матрица ковариаций меньше
 (в указанном выше смысле). Заметим, что две оценки могут быть несравнимы.

Теперь понятно, что многомерное обобщение неравенства Крамера\ч Рао
должно
 устанавливать границу снизу для матрицы ковариаций несмещенной оценки.

\subsubsection{Многомерное неравенство Крамера\ч Рао}

Переходим к выводу неравенства.

Введем оператор частного дифференцирования по $\ta$, который (в виде исключения) запишем как строку:
$$
\frac{\pd}{\pd\ta}=\left(\frac{\pd}{\pd\ta_{1}}\sco \frac{\pd}{\pd\ta_{r}}\right)
$$

Определим матрицу информации (обобщение количества информации
$I(\ta)$):
$$
I(\ta)=\Ef_{\ta}\left[\frac{\pd}{\pd\ta}\ln p(X,
\ta)\right]^{T}\left[\frac{\pd}{\pd\ta}\ln p(X,
\ta)\right]
$$

Легко видеть, что $I(\ta)$\т неотрицательно определенная матрица, что мы
 будем записывать в виде $I(\ta)\ge 0$. Предположим, что $I(\ta)^{-1}$
существует для всех $\ta\in\Ta$.

Введем матрицу $\rbmat{\pf{\tau}{\ta}}$ размера $d\times r$, положив:
$$
\frac{\pd\tau}{\pd\ta}=\left(\begin{array}{cccc}
\frac{\pd\tau_{1}}{\pd\ta_{1}}& \frac{\pd\tau_{1}}{\pd\ta_{2}}& \ldots& \frac{\pd\tau_{1}}{\pd\ta_{r}}\\
\frac{\pd\tau_{2}}{\pd\ta_{1}}& \frac{\pd\tau_{2}}{\pd\ta_{2}}& \ldots& \frac{\pd\tau_{2}}{\pd\ta_{r}}\\
\vdots& \vdots& \ddots& \vdots\\
\frac{\pd\tau_{d}}{\pd\ta_{1}}&
\frac{\pd\tau_{d}}{\pd\ta_{2}}& \ldots&
\frac{\pd\tau_{d}}{\pd\ta_{r}}
\end{array}\right)
$$

Покажем, что при принятых в пункте 1 <<условиях регулярности>>:
$$
\Ef_{\ta}(\ph(X)-\tau(\ta))(\ph(X)-\tau(\ta))^{T}\ge
\frac{\pd\tau}{\pd\ta}
I^{-1}\left(\frac{\pd\tau}{\pd\ta}\right)^{T}.\eqno(1)
$$

{\it Доказательство:}

Рассмотрим вектор-строку:
$$
\la(X,\ta)=\frac{\pd}{\pd\ta}\ln p(X, \ta).
$$

Так же, как и в одномерном случае, находим, что
$$
\Ef_{\ta}\la(X,\ta)=0. \eqno(2)
$$

Дифференцируем по $\ta$ тождество
$$
\int\limits_{A}\ph(x)p(x,\ta)dx=\tau(\ta);
$$
получаем, что:
$$
\int\limits_{A}\ph(x)\frac{\pd}{\pd\ta}p(x,\ta)dx=
\frac{\pd\tau}{\pd\ta},
$$
или
$$
\int\limits_{A}\ph(x)\left[\frac{\pd}{\pd\ta}\ln
p(x,\ta)\right]p(x,\ta)dx=
\frac{\pd\tau}{\pd\ta}.
$$

Последнее равенство означает, что:
$$
\Ef_{\ta}\ph(X)\la(X,\ta)=\frac{\pd\tau}{\pd\ta}.\eqno(3)
$$

Теперь рассмотрим (неотрицательно определенную) матрицу ковариаций
вектора
$$
\ph(X)-\tau(\ta)-\frac{\pd\tau}{\pd\ta}I^{-1}(\ta)\la^{T}(X,
\ta).
$$

(Обратите внимание на то, что размерности перемножаемых матриц
согласованы таким образом, что умножение возможно).

Рассмотрим очевидное неравенство:
$$
\Ef_{\ta}\left[(\ph-\tau)-\frac{\pd\tau}{\pd\ta}I^{-1}\la^{T}\right]\left[(\ph-\tau)-\frac{\pd\tau}{\pd\ta}I^{-1}\la^{T}\right]^{T}\ge
0
$$

Левую часть тождественно преобразуем:
$$
\Ef_{\ta}(\ph - \tau)(\ph - \tau)^{T}- \Ef_{\ta}(\ph - \tau) \hs{\frac{\pd\tau}{\pd\ta}I^{-1}\la^{T}}^{T}-
\Ef_{\ta}\hs{\frac{\pd\tau}{\pd\ta}I^{-1}\la^{T}}(\ph-\tau)^T+\Ef_{\ta}\hs{\frac{\pd\tau}{\pd\ta}I^{-1}\la^{T}}
\left[\frac{\pd\tau}{\pd\ta}I^{-1}\la^{T}\right]^T\ge 0 \eqno (4)
$$

Второе слагаемое в (4):
$$
\Ef_{\ta}(\ph-\tau)\la
I^{-1}\left(\frac{\pd\tau}{\pd\ta}\right)^{T}=
\frac{\pd\tau}{\pd\ta}
I^{-1}\left(\frac{\pd\tau}{\pd\ta}\right)^{T},\eqno (5)
$$
ибо $\Ef_{\ta}\ph\la=\frac{\pd\tau}{\pd\ta}$
(см. (3)), $\Ef_{\ta}\la=0$ (см. (2)).

Третье слагаемое отличается от второго лишь транспонированием (третье слагаемое\т это транспонированное
второе). А так как (5) симметрично, то третье слагаемое тоже равно (5).

Наконец, четвертое слагаемое даст:
$$
\frac{\pd\tau}{\pd\ta}I^{-1}\left[\Ef_{\ta}\la^{T}\la\right]I^{-1}
\left(\frac{\pd\tau}{\pd\ta}\right)^{T}=
\frac{\pd\tau}{\pd\ta}
I^{-1}\left(\frac{\pd\tau}{\pd\ta}\right)^{T}
$$

Приведя в (4) подобные члены, получим отсюда (1), что и требовалось.
$\Box$

Заключим тему неравенств информации и эффективных оценок
определением многопараметрических \\ экспоненциальных семейств.
Плотность (вероятность) для них имеет вид:
$$
p(x,\ta)=\exp\hs{\suml{i=1}{r}c_i(\ta)T_i(x)+d(\ta)+S(X)}I_{A}(x).
$$
Наиболее важный пример\т гауссовское распределение, где плотность зависит от двумерного параметра
$(a,\si^{2})$:
$$
p(x,a,\si^{2})=\frac{1}{\sqrt{2\pi\si^{2}}} \exp\left\{-\frac{(x-a)^{2}}{2\si^{2}}\right\}.
$$

\underline{Вопрос:} Для какой (двумерной) функции $\tau(\ta)=(\tau_{1}(a,\si^{2}),\tau_2(a,\si^{2}))^{T}$
существует эффективная оценка?

\subsection{Достаточные статистики}

Напомним, что мы рассматриваем следующую статистическую модель:
наблюдение $X$ получено случайным выбором из множества $\Xc$;
случайный выбор управляется распределением вероятностей
$P_{\ta}$, где $\ta$\т некоторый (неизвестный) параметр,
причем $\ta\in\Ta$; $\Ta$\т заданное множество возможных значений этого параметра.

\subsubsection{Определение}

Статистика $T=T(X)$ называется {\it достаточной} для параметра
$\ta$, $\ta\in\Ta$,  если условное распределение $X$ при
данном значении $T(X)$ одно и то же для всех $\ta\in\Ta$.
(Иначе говоря, если упомянутое условное распределение не меняется
(не зависит от $\ta$), когда $\ta$ пробегает множество $\Ta$).

\subsubsection{Дискретный случай}

Когда распределение $X$ дискретно, понятие условного распределения
$X$ вводится  элементарно:
$$
P_{\ta}(X=x|T(X)=t)=\frac{P_{\ta}(X=x,T(X)=t)}{P_{\ta}(T(X)=t)}=
\case{\frac{P_{\ta}(X=x)}{P_{\ta}(T(X)=t)}, & \text{ если } T(X)=t \\
0, & \text{ если } T(X)\neq t}
$$

\underline{Пример: испытания Бернулли.}

Пусть $X=(X_{1}\sco X_{n})$\т результаты испытаний Бернулли, в которых вероятность успеха есть
$\ta$, $\ta\in (0,1)$. В качестве статистики $T(X)$ возьмем $T=\sum\limits_{i=1}^{n}X_{i}$.

Здесь $X_{i}$ принимает значения 0 или 1 (число успехов в испытании номер $i$), $T$\т общее  число успехов в
$n$ испытаниях.

Элементарная выкладка показывает, что в этом примере (где $x=(x_{1}\sco x_{n})$\т заданная
последовательность нулей и единиц):
$$
P_{\ta}(X=x|T(X)=t)=\case{\frac{1}{C_{n}^{t}}, & \text{ если }
\sum\limits_{i=1}^{n}x_{i}=t \\ 0, & \text{ если }
\sum\limits_{i=1}^{n}x_{i}\neq t}
$$

Как видно из формулы, $T=\sum\limits_{i=1}^{n}X_{i}$ есть
достаточная статистика для $\ta$,  $\ta\in (0, 1)$.

\subsubsection{Непрерывный случай}

Так, для краткости, назовем статистическую модель, в которой
распределение $P_{\ta}$ может  быть задано \; с помощью плотности
$p(x,\ta)$ относительно некоторой меры. Для простоты предположим,
что $X$ принимает значения в конечномерном пространстве
 и что $p(x,\ta)$\т плотность относительно лебеговской меры.
 В этом случае значения статистики $T$ выделяют {\it множества уровня} $\{x: T(x)=t\}$.

Условное распределение $X$ на множестве уровня $\{x: T(x)=t\}$ в
этом случае можно задать с  помощью плотности (относительно меры
Лебега на множестве уровня).
 Эта условная плотность пропорциональна $p(x,\ta)$. Поскольку интеграл от плотности составляет 1,
эта условная плотность $X$ при данном $T(X)=t$, т.е. на множестве
уровня $\{x: T(x)=t\}$, равна
$$
\frac{p(x,\ta)}{\int\limits_{\{y: T(y)=t\}} p(y,\ta)dy}
$$
(Выражение в знаменателе\т это интеграл по поверхности уровня).
\subsubsection{Достаточные разбиения}

Из определения достаточной статистики следует, что, если случайная
функция $S=S(T)$ находится во  взаимно однозначном соответствии с
достаточной статистикой $T=T(X)$, то $S$ тоже является достаточной
статистикой. Поэтому правильнее было бы говорить не о достаточных
статистиках, а о производимых ими разбиениях выборочных пространств
(разбиениях на множества уровня достаточных статистик). Условные
распределения $X$ на элементах этих разбиений одинаковы для всех
распределений $\ta$, когда $\ta\in\Ta$.
 Достаточная статистика $T=T(X)$ разбивает выборочное пространство $\Xc$ на множества уровня
 $\{x: T(x)=\const\}$.

\underline{Пример} Пусть $X=(X_{1}, \ldots, X_{n})$\т выборка из показательного распределения, где плотность
отдельного наблюдения $X_{i}$ равна
$$
f(u,\ta)=\case{\frac{1}{\ta}\exp\left(-\frac{u}{\ta}\right)
&  \text{ для } u\ge 0 \\ 0 & \text{ для } u<0}
$$
Параметр $\ta$\т неотрицательное число, т.е. $\ta\in (0,\infty)$.  Покажем, что
$T=\sum\limits_{i=1}^{n}X_{i}$\т достаточная статистика для $\ta$ в этой модели. Плотность $X$ в точке
$u=(u_{1},\ldots , u_{n})$ есть:
$$
\prodl{i=1}{n}f(u,\ta)=\case{\hr{\frac{1}{\ta}}^n \exp\hr{-\frac{T}{\ta}} & \text{ где } T = \suml{i=1}{n}u_i, \text{ и } u_i \ge 0; \\
0 & \text{ в противном случае}.}
$$
В следующей формуле $S := \suml{i=1}{n}y_i$. Условная плотность $X$ при фиксированном $T$ равна (в точке $u$
такой, что $\suml{i=1}{n}u_i=T$ и $u_1\sco u_n\ge 0$):
$$
\frac{\hr{\frac{1}{\ta}}^n \exp\hr{-\frac{T}{\ta}}}{\ints{\hc{y\cln S=T, y\ge 0}}\hr{\frac{1}{\ta}}^{n}
\exp\hr{-\frac{S}{\ta}}
dy}=
\frac{\hr{\frac{1}{\ta}}^n\exp \hr{-\frac{T}{\ta}}}{\hr{\frac{1}{\ta}}^n\exp\hr{-\frac{T}{\ta}}
\ints{\hc{y\cln S=T, y\ge 0}}\,dy}=\const.
$$
Здесь оказалось, что условная плотность (на множестве уровня)  не
только не  зависит от $\ta$,\т что доказывает, что статистика $T$
достаточна, но не зависит  и от координаты $y$. Это  означает, что
указанное условное распределение~$X$ равномерно.

Выкладки, которые мы проделали в двух рассматриваемых примерах, по
существу повторяются при доказательстве следующей теоремы:

\subsubsection{Теорема факторизации}

\begin{theorem}
Статистика $T=T(X)$ достаточна для параметра $\ta$, $\ta\in\Ta$, тогда и только тогда, когда существуют функции
$g(t, \ta)$ и $h(x)$ такие, что
$$p(x,\ta)=g\br{T(X),\ta}h(x)\eqno (*)$$
при всех $\ta\in\Ta$.
\end{theorem}

\underline{Замечание:}

Величина $p(x, \ta)$ обозначает либо плотность наблюдения $X$ в
точке $x$, если модель непрерывна, либо вероятность точки $x$, если
модель дискретна.

\begin{proof}
Доказательство проведем отдельно для дискретного случая; в непрерывном случае оно слабо отличается.
\begin{points}{-2}
\item
Если выполнено $(*)$, то $T=T(X)$\т достаточная статистика для $\ta$.
Надо показать, что $P(X|T(X))$ не зависит от $\ta\in\Ta$.

Сначала вычислим:
$$
\begin{array}{l}
P_{\ta}(T=t)=\sum\limits_{x: T(x)=t} p(x,
\ta)=\sum\limits_{x: T(x)=t} g(T(x), \ta)h(x)=
g(t, \ta)\sum\limits_{x: T(x)=t} h(x).
\end{array}
$$

Теперь для $x$ такого, что $T(x)=t$ получаем, что:
$$
\begin{array}{l}
P_{\ta}(X=x|T(X)=t)=\frac{P_{\ta}(X=x,T(X)=t)}{P_{\ta}(T(X)=t)}=
\frac{P_{\ta}(X=x)}{P_{\ta}(T(X)=t)}=\\
\frac{g(T(x),\ta)h(x)}{g(t, \ta)\sum\limits_{y:
T(y)=t} h(y)}= \frac{h(x)}{\sum\limits_{T(x)=t} h(x)} -
\mbox{результат не зависит от}\; \ta\in\Ta.
\end{array}
$$

Если же $x$ таково, что $T(x)\neq t$, то обсуждаемая условная
вероятность равна 0, вне зависимости от $\ta$. Достаточность
условия $(*)$ доказана.

\item Если $T$\т достаточная статистика, то $(*)$ выполнено.
Если $T$ достаточна, то для таких $x$, что $T(x)=t$, и для всех
$\ta\in\Ta$
$$
P_{\ta}(X=x|T(X)=t)=h(x) \mbox{- результат не зависит от}\;
\ta, \mbox{обозначим его через}\; h(x) ,
$$
или
$$
\frac{P_{\ta}(X=x, T(X)=t)}{P_{\ta}(T(X)=t)}=h(x).
$$
Поскольку $T(x)=t$, то дробь в левой части есть:
$$
\frac{P_{\ta}(X=x)}{P_{\ta}(T(X)=t)}.
$$
Отсюда
$$
P_{\ta}(X=x)=P_{\ta}(T(X)=t)h(x)
$$
\end{points}
Обозначив $P_{\ta}(T(X)=t)$ через $g(t,\ta)$, получим то, что и требовалось доказать.
\end{proof}

Заметим, что $h(x)$\т это условная вероятность $X$ при данном $T$ (в точке $x$),
либо $h(x)$ пропорциональна этой условной вероятности.
Аналогично $g(x,\ta)$ лишь постоянным множителем может отличаться
от вероятности $P_{\ta}(T(X)=t)$.

\subsubsection{Пример: линейная модель}
\begin{description}
\item[{(a)}]
Линейная (гауссовская) модель\т важный объект исследований и приложений.
Сначала будет дана ее абстрактная формулировка, а затем одна из конкретных форм.

Наблюдаемый объект\т вектор $X$. Сейчас мы считаем его $n$\д мерным: $X=(X_1 \sco X_n)^T$\т вектор\д столбец.
 Его координаты считаем независимыми случайными величинами, распределенными
 по нормальному закону, причем $\Df X_{i}=\si^2$, $i=\overline{1, n}$.
 Значение  $\si^2$ неизвестно.

Относительно $\Ef X$ предположим, что $\Ef X$, будучи неизвестным,
принадлежит заданному линейному \\ подпространству $L$, $L\subset
\R^n$.

Если обозначить $\Ef X=l$, $\Ef(X-\Ef X)(X-\Ef X)^T=\Df _{\ta}X=\si^{2}I$ ($I$\т единичная матрица), то
$X\sim N(l, \si^{2}I)$, причем $l\in L$, $L$\т задано.

\item[{(b)}]

Покажем, что достаточной статистикой для (составного) параметра $\ta=(l,\si^2)$, причем $l\in L$, служит пара
$(\proj_{L}X, |\proj_{L^{\perp}}X|^2)$. Здесь через $\proj_{M}$ обозначен оператор проектирования (в
евклидовой метрике) на подпространство ${M\subset \R^n}$; $L^{\perp}$ обозначает ортогональное дополнение $L$
до $\R^n$, т.е. $\R^{n}=L\oplus L^{\perp}$.

Для доказательства достаточно указать плотность $X$ и затем ее преобразовать:
\begin{multline*}
p(X, \ta)=\hr{\frac{1}{\si\sqrt{2\pi}}}^n\exp\hc{-\frac{1}{2\si^2}\sumiun(X_{i}-l_{i})^2}=\\=
\hr{\frac{1}{\si\sqrt{2\pi}}}^n\exp\hc{-\frac{1}{2\si^{2}}|X-l|^2}=\\=
\hr{\frac{1}{\si\sqrt{2\pi}}}^n\exp\hc{-\frac{1}{2\si^{2}}\bm{(\proj_{L}X-l)+\proj_{L^{\perp}}X}^2}
\end{multline*}

По теореме Пифагора:
$$
|(\proj_{L}X-l)+\proj_{L^{\perp}}X|^{2}=|\proj_{L}X-l|^{2}+|\proj_{L^{\perp}}X|^{2},
$$
ибо $(\proj_{L}X-l)\perp \proj_{L^{\perp}}X$ , т.к. $l\in L$.

Поэтому плотность $X$ равна
$$
\left(\frac{1}{\si\sqrt{2\pi}}\right)^{n}\exp\left\{-\frac{1}{2\si^{2}}
|\proj_{L}X-l|^{2}\right\}\exp\left\{-\frac{1}{2\si^{2}}|\proj_{L^{\perp}}X|^{2}\right\}
$$

Мы видим, что плотность зависит от статистик $\proj_{L}X$ и
$|\proj_{L^{\perp}}X|^2$, но не от $X$ непосредственно. Эта пара и
составляет достаточную статистику. (Заметим, что функция $h(X)$
здесь
 равна $1$, точнее\т постоянна по отношению к $X$. Это означает, что условное
 распределение $X$ при фиксированном значении достаточной статистики\т равномерное.)

\item[{(c) Линейная регрессия.}]
Задача {\it линейной регрессии}\т одна из частных форм линейной модели. В простейшем случае это задача о
подборе функции одного переменного\т подборе по неточным наблюдениям (измерениям).

Предположим, что две переменные $t$ и $x$ связаны соотношением $x=f(t)$, где $f(\cdot)$\т некоторая функция.
При некоторых значениях переменной $t$ (называемой часто фактором) $t_{1}\sco t_{n}$ были
произведены измерения переменной $x$ (называемой откликом). Они дали значения $x_{1}\sco x_{n}$.
При этом $x_{i}=f(t_{i})+\ep_{i}$, где  $\ep_1\sco \ep_n$\т некоторые ошибки, сопровождающие измерения.
Основное предположение состоит в том, что мы считаем упомянутые $\ep_1\sco\ep_n$ независимыми случайными
величинами. Менее важные предположения: $\ep_{i}$ распределены одинаково
 и распределены по нормальному закону $N(0,\si^{2})$. Предположение $\Ef\ep_{i}=0$
 отражает представление о том, что систематических ошибок при измерении отклика в
 нашей схеме нет. Величина $\si$ обычно считается неизвестной (необязательно). Она
численно выражает неточность (изменчивость) измерений, т.е. масштаб
случайных ошибок.

Последнее предположение, превращающее задачу регрессии в линейную:
считаем, что $f(\cdot)$ можно (с достаточной аккуратностью) выразить
в виде линейной комбинации заданного конечного набора функций
(скажем $\ph_{1}\sco \ph_m$): существуют
параметры $\ta_{1}, \ldots, \ta_{m}$ такие, что
$$
f(t)=\ta_{1}\ph_{1}(t)+\ldots+ \ta_{m}\ph_{m}(t).
$$

В этом случае вектор $X=(x_{1}\sco x_{n})^T$
представляется в виде линейной комбинации  векторов:
$$
\Phi_{j}=\br{\ph_{j}(t_{1})\sco \ph_{j}(t_{n})}^{T}, j=\overline{1, m}
$$
и вектора $\ep$ случайных ошибок:
$\ep=(\ep_{1}, \ldots,  \ep_{n})^{T}$:
$$X=\sum\limits_{j=1}^{m}\ta_{j}\Phi_{j}+\ep.$$

Линейное подпространство $L$, которому заведомо принадлежит вектор
$\Ef X$, в данном случае порождено векторами $\Phi_{1}\sco \Phi_{m}$.
\item[{(d) Нормальная выборка.}]


Рассмотрим выборку $x_{1}\sco x_{n}$ из нормальной совокупности $N(a, \si^{2})$, где параметры $a\in\R$,
$\si^{2}\in (0, \infty)$ неизвестны. Теорема факторизации помогает найти достаточные статистики для $(a,
\si^{2})$. Выпишем плотность этой модели (пользуясь независимостью гауссовских случайных величин $x_{1}\sco
x_{n}$) и преобразуем ее:
$$
\prodl{i=1}{n}\frac{1}{\si\sqrt{2\pi}} \exp\hr{-\frac{(x_{i}-a)^{2}}{2\si^{2}}}
=\hr{\frac{1}{\si\sqrt{2\pi}}}^n \exp\left\{-\frac{1}{2\si^{2}} \left[\suml{i=1}{n}
x_{i}^{2}-2a\suml{i=1}{n}x_{i}+na^{2} \right]\right\}.
$$

Поскольку плотность зависит от переменных $x_{1}\sco x_{n}$ лишь посредством статистик
$\sum\limits_{i=1}^{n}x_{i}$ и $\sum\limits_{i=1}^{n} x_{i}^{2}$, эта пара и является достаточной статистикой
для  $(a, \si^{2})$. Мы уже обращали внимание на то, что главным в определении достаточной статистики
$T=T(X)$ является не ее конкретный вид, а то разбиение выборочного пространства на множества уровня вида
$\{T(X)=\const\}$, которое она производит. Любая другая статистика, если она порождает то же самое разбиение,
тоже является достаточной. В частности, достаточной окажется любая статистика, находящаяся во взаимно
однозначном соответствии с $T(X)$.

Для обсуждаемой нормальной выборки предпочитаемой достаточной
статистикой служит:
$$
\ol x=\frac{1}{n}\sum\limits_{i=1}^{n} x_{i}, \qquad
s^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n} (x_{i}-\ol x)^{2}
$$

Легко видеть, что $(\ol x, s^{2})$ взаимно однозначно связана с
$(\sum\limits_{i=1}^{n} x_{i}, \sum\limits_{i=1}^{n} x_{i}^{2})$.

О преимуществах, которые дает статистика $(\ol x, s^{2})$ перед другими статистиками для $(a,\si^{2})$, мы
подробнее будем говорить позже. Сейчас же отметим лишь то, что $\ol x$ и $s^2$ несмещенно оценивают $a$ и
$\si^2$:
$$
\Ef\ol x=a, \qquad \Ef s^{2}=\si^{2}
$$

Заметим, что эти соотношения справедливы для любой, не только
гауссовской, выборки (если $\Df x_{i}^{2}$ существуют).

Выборка из $N(a, \si^{2})$ является частным случаем линейной модели. Рассмотрим вектор $X=(x_{1}\sco
x_{n})^T$. Его математическое ожидание равно $(a, a, \ldots, a)^T$, и потому принадлежит линейному
подпространству $L$, порожденному вектором $(1, \ldots,1)^T$. Так как координаты вектора $X$ независимы и
одинаково распределены, то $\Df X=\si^{2}I$. Таким образом, предпосылки линейной модели соблюдены.

Достаточные статистики общей линейной модели в данном случае суть:
$$
\proj_{L}X=\ol x(1, 1, \ldots, 1)^{T},
$$

$$
|\proj_{L^{\perp}}X|=\sum\limits_{i=1}^{n} (x_{i}-\ol
x)^{2}=(n-1)s^{2}.
$$

\item[{(e)}]
При обсуждении гауссовской линейной модели мы отмечали, что условное
распределение $X$ при фиксированном значении достаточной статистики
- равномерное. Из этого обстоятельства можно извлечь интересные
следствия. В данном примере упомянутое  условное распределение
сосредоточено на $(n-2)$-мерной сфере:
$$
\{y: y\in R^{n}, \sum\limits_{i=1}^{n}y_{i}=\ol x,
\sum\limits_{i=1}^{n} (y_{i}-\ol y)^{2}=(n-1)s^{2}\}
$$

Рассмотрим вектор
$$
Y=\left(\frac{x_{1}-\ol x}{s\sqrt{n-1}}, \frac{x_{2}-\ol
x}{s\sqrt{n-1}}, \ldots, \frac{x_{n}-\ol x}{s\sqrt{n-1}},
\right)^{T}
$$

При фиксированном значении достаточной статистики $(\ol x, s^{2})$
вектор $Y$ является линейным (и взаимно-однозначным) преобразованием
вектора $X$. Поэтому условное (при фиксированных $\ol x, s^{2}$)
распределение $Y$ тоже является равномерным. Это условное
распределение сосредоточено на $(n-2)$-мерной единичной сфере
$$
S_{n-2}=\hc{y\cln y\in \R^{n}, \sum\limits_{i=1}^{n} y_{i}=0, \sum\limits_{i=1}^{n}y_{i}^{2}=1}.
$$

Теперь заметим, что сказанное условное распределение $Y$ при данных $\ol x, s^{2}$\т одно и то же (а именно
равномерное на $S_{n-2}$) при любых значениях $\ol x, s^{2}$. Значит:
\begin{enumerate}
\item
вектор $Y$ как случайный элемент не зависит от $\ol x, s^{2};$
\item
(безусловное) распределение $Y$ совпадает с условным, т.е. является
уже известным равномерным распределением на $S_{n-2}$.
\end{enumerate}

Из сказанного следует, что для нормальной выборки такие (часто
применяемые на практике) статистики, как выборочная асимметрия
$\sum\limits_{i=1}^{n}\left(\frac{(x_{i}-\ol x)}{s}\right)^3$ и
выборочный эксцесс $\sum\limits_{i=1}^{n}\left(\frac{(x_{i}-\ol x)}{s}\right)^4$ не зависят от $(\ol x, s^{2})$. А их распределения не зависят от $X$  и могут быть вычислены (табулированы).

Упомянутые статистики обычно в виде выборочного коэффициента
асимметрии
$$\beta_{1}=\frac{1}{n}\sum\limits_{i=1}^{n}(x_{i}-\ol x)^{3}/s^{3}$$
и выборочного коэффициента эксцесса
$$\beta_{2}=\frac{1}{n}\sum\limits_{i=1}^{n}\left(\frac{(x_{i}-\ol x)}{s }\right)^4-3$$
могут служить для проверки нормальности имеющейся выборки, \те для проверки предположения о том,
что данная выборка извлечена из некоторой нормальной совокупности.
Нормальность выборки дает возможности для ее детального анализа (в дальнейшем будет видно, какие).

Для общей линейной гауссовской модели утверждение о равномерном
распределении случайного вектора $(\proj_{L^{\perp}}X)/
|\proj_{L^{\perp}}X|$ (на единичной сфере размерности $n-r$, где
$r=\dim L$) и его статистической зависимости от пары $(\proj_{L}X,
|\proj_{ L^{\perp}}X|^{2})$ доказывается аналогично.

Аналогичным поря\!дком мы можем составить коэффициенты асимметрии и
эксцесса, и тоже использовать их для проверки нормальности
распределения $X$ в линейной модели.
\end{description}

\subsection{Наилучшие несмещенные оценки}
\subsubsection{Наилучшие несмещенные оценки}


Так обычно называют несмещенные оценки с минимальным квадратичным
риском.

Для скалярного параметра (и для скалярных функций от параметра) это несмещенные оценки с минимальной
дисперсией; для векторного (конечномерного) параметра и функций от него\т это несмещенные оценки с наименьшей
матрицей ковариаций. В некоторых случаях указать наилучшую несмещенную оценку помогают неравенства Крамера\ч Рао:
если оценка эффективная, то она и наилучшая в указанном выше смысле, так как имеет наименьшую возможную
дисперсию.

Но даже для экспоненциальных семейств распределений, для которых
только и существуют эффективные оценки, эффективно оценить можно
лишь одну какую-то функцию от параметра. Скажем, для испытаний
Бернулли, в которых параметром $\ta$ служит вероятность успеха,
эффективная оценка есть только для $\ta$ (это частота успехов).
Но каковы несмещенные оценки, например, для $\ta (1-\ta )$ или
$\ta^{2}$?

Вопрос тем более открыт для семейств распределений, не являющихся
экспоненциальными.

Известные к настоящему времени обобщения неравенства Крамера\ч Рао
расширяют наши возможности не слишком значительно.

Задачу о наилучших несмещённых оценках удается продвинуть (а часто\т полностью решить),
если для неизвестного параметра существует
достаточная статистика. Несмещённое оценивание при достаточной
статистике и будет нашей текущей темой. Для ее обсуждения нам
понадобится понятие условного
 математического ожидания одной случайной величины при фиксированном значении
 другой. В полном объеме оно будет введено и изучено в следующей главе. А сейчас,
чтобы завершить тему наилучшего несмещённого оценивания, мы
ограничимся неформальным толкованием этого понятия. А также укажем
некоторые его свойства, необходимые для упомянутой цели.

\subsubsection{Условные математические ожидания: предварительные сведения}

Пусть случайные величины $X$ и $Y$ заданы на одном вероятностном пространстве. (Содержательно это означает,
что значения переменных $X$, $Y$ получены в одном эксперименте). Понятие условного математического ожидания
$X$ при данном значении $Y$\т далее $\Ef(X|Y)$ \т можно ввести элементарными средствами, если при каждом
(почти каждом) значении $Y$ существует условное распределение $X$. Рассмотрим условное распределение $X$ при
данном $Y$. Усредним значения $X$ (при данном $Y$) по этому условному распределению. Полученный результат
(число, если $X$ принимает числовые значения, вектор-столбец, если значения $X$ суть векторы-столбцы и т.д.)
зависит от фиксированного значения $Y$, т.е. является функцией $Y$. Его называют {\it условным математическим
ожиданием} $X$ при данном $Y$ и обозначают как $\Ef(X|Y)$. Поскольку $Y$ - случайная величина, $\Ef(X|Y)$
тоже является случайной величиной.

Если совместное распределение $(X, Y)$ имеет плотность $p(x, y)$
(либо дискретно), то формулу для $\Ef(X|Y)$ можно получить явно. В
этом случае условное распределение $X$ при данном $Y$ имеет
плотность (в точке $x$), равную
$$
\frac{p(x, Y)}{\int p(x, Y)\,dx}.
$$

Отсюда
$$
\Ef(X|Y)=\frac{\int xp(x, Y)\,dx}{\int p(x, Y)\,dx}.
$$

Аналогичная формула (с заменой интегрирования суммированием)
действует и в дискретном случае.

В общем случае соотношение между условным распределением и условным
математическим ожиданием\т обратное по отношению к описанному:
$\Ef(X|Y)$ первично и вводится непосредственно, а понятие условного
распределения $X$ при данном $Y$ может быть определено на его
основе.

Укажем некоторые свойства условных математических ожиданий, которые
нам сейчас понадобятся. Линейные свойства вполне ожидаемы и
естественны:

\begin{enumerate}
\item
$$
\Ef(X_{1}+X_{2}|Y)=\Ef(X_{1}|Y)+\Ef(X_{2}|Y)
$$
(Здесь случайные величины $X_{1}$ и $X_{2}$ должны быть заданы на
том же пространстве элементарных исходов, что и $Y$).
\item
$$
\Ef(kX|Y)=k\Ef(X|Y),
$$
где $k$\т постоянный (неслучайный) множитель.
\item
$$
\Ef[f(Y)X|Y]=f(Y)\Ef(X|Y),
$$
где $f(Y)$\т функция $Y$. Это свойство тоже естественно, ибо при фиксированном значении $Y$ функция $f(Y)$
постоянна, а постоянный множитель можно выносить за знак математического ожидания.

Надо оговорить, что перечисленные выше равенства выполняются с
вероятностью 1, ибо они соединяют случайные величины. Нужно также,
чтобы существовало $\Ef|X|$ (в первом пункте должны существовать
$\Ef|X_{1}|$ и $\Ef|X_{2}|$).

Наиболее важным является свойство
\item
$$\Ef\{\Ef(X|Y)\}=\Ef X.$$
\end{enumerate}
\subsubsection{Улучшение несмещенных оценок}

Вернемся к обсуждавшейся задаче о несмещенных оценках с минимальной
дисперсией. В ее решении можно сделать шаг вперед, если в
статистической модели есть достаточная статистика.

Пусть $X$\т наблюдаемая случайная величина, распределенная по некоторому закону $P_{\ta}$, где $\ta$\т
неизвестный параметр, $\ta\in\Ta$, $\Ta$\т задано.

Пусть $d=d(X)$\т несмещенная оценка $\tau(\ta)$, где $\tau(\ta)$\т заданная функция, т.е.:
$$
\Ef_{\ta}d(X)=\tau(\ta) \qquad\mbox{для всех}\; \ta\in\Ta,
$$
причем $\Ef_{\ta}|d(X)|$ существует.

Пусть $T$\т достаточная статистика для параметра $\ta$.

Рассмотрим условное математическое ожидание $d(X)$ при данном $T$:
$$
\ph(T)=\Ef(d(X)|T)
$$

Заметим, что $\Ef(d(X)|T)$ не зависит от $\ta$, так как от $\ta$
не зависит условное распределение $X$ при данном $T$\т в силу
определения достаточной статистики.

\begin{theorem}[Blackwell\ч Rao, 1947-1949]
При указанных выше условиях
$$\Ef_{\ta}\ph(T)=\tau(\ta) \text{ и } \Df_{\ta}\ph(T)\le \Df _{\ta}d(X),$$
причем равенство достигается, если и только если $\ph(T)=d(X)$ (с вероятностью 1, для каждого $\ta\in\Ta$).
\end{theorem}
\begin{proof}
\begin{points}{-2}
\item Первое утверждение выполняется в силу свойства условных
математических ожиданий $\Ef\Ef(X|Y)=\Ef X$:
$$
\Ef_{\ta}\Ef[d(X)|T]=\Ef_{\ta}d(X)=\tau(\ta).
$$
\item Доказательство второго свойства для одномерных $\ph$, $d$ и
$\tau$:
\begin{multline*}
\Df _{\ta}d(X)=\Ef_{\ta}[d(X)-\tau(\ta)]^{2}=\Ef_{\ta}[(d(X)-\ph(T))+(\ph(T)-\tau(\ta))]^{2}=\\
=\Ef_{\ta}(d-\ph)^{2}+\Ef_{\ta}(\ph-\tau)^{2}+2\Ef_{\ta}(d-\ph)(\ph-\tau)=
\Ef_{\ta}(d-\ph)^{2}+\Df _{\ta}\ph,
\end{multline*}
поскольку
$$
\Ef_{\ta}(d-\ph)(\ph-\tau)=
\Ef_{\ta}\Ef[(d-\ph)(\ph-\tau)|T]=\Ef_{\ta}{(\ph-\tau)\Ef[(d-\ph)|T]}=0,
$$
ибо
$\Ef_{\ta}[(d(T)-\ph(X))|T]=\Ef(d|T)-\Ef(\ph|T)=\ph-\ph=0$.
(Последнее равенство выполняется с вероятностью 1 для каждого распределения $P_{\ta}$).

Равенство в $(b)$ достигается, если и только если
$$\Ef_{\ta}[d(T)-\ph(T)]^{2}=0 \quad \fa \ta.$$
Это возможно, если и только если
$$d(X)=\ph(T) \qquad\mbox{с вероятностью 1}$$
для всех $P_{\ta}$ распределений.

\item Многомерный случай: пусть $d(X)$, $\tau(\ta)$ принимают значения в $\R^{p}$,
записываем их в виде столбцов, $\Df _{\ta}d<\infty$.

Пусть $z\in \R^{p}$, $z$\т произвольный дисперсионный вектор. Рассмотрим скалярные величины:
$$\xi=\xi(X):=z^{T}d(X),$$
$$\eta=\eta(T):=\Ef[\xi(X)|T]=z^{T}\Ef[d(X)|T]=z^{T}\ph(T),$$
$$t=t(\ta):=z^{T}\tau(\ta)$$

Ясно, что $\Ef_{\ta}\xi(X)=t(\ta)=\Ef_{\ta}\eta(T)$. По одномерной теореме Блеквелла\ч Рао
$$\Df _{\ta}\eta(T)\le \Df _{\ta}\xi(X).$$
Отсюда
$$\Df _{\ta}(z^{T}\ph)\le \Df _{\ta}z^{T}d(X) \quad \Lra \quad
z^{T}\left(\Df _{\ta}\ph\right)z\le z^{T}\left(\Df _{\ta}d\right)z \quad \Lra \quad
\Df _{\ta}\ph\le \Df _{\ta}d,$$
что и требовалось доказать. Равенство будет, если
$$P_{\ta}[\eta(T)=\xi(X)]=1$$
или
$$P_{\ta}\{z^{T}\br{\ph(T)-d(X)}=0\}\qquad \fa \ta\in\Ta \text{ и } \fa z\in \R^p.$$
\end{points}
\hfill\end{proof}
\subsubsection{Полные достаточные статистики}

Из теоремы Блеквелла\ч Рао можно сделать, по меньшей мере, два вывода:
\begin{itemize}
\item
Эта теорема дает способ улучшить несмещенную оценку, если мы такой
оценкой уже располагаем;
\item
Она говорит, что при поиске наилучшей несмещенной оценки можно
ограничить себя функциями от достаточной статистики. Если такая
(зависящая от достаточной статистики) несмещенная оценка
единственна, то она автоматически оказывается наилучшей.
\end{itemize}

Единственность зависящей от достаточной статистики несмещенной
оценки обеспечивается так называемой \underline{полнотой}
достаточной статистики.
\begin{description}
\item[\underline{Определение}]
Достаточная статистика $T=T(X)$ называется {\it полной}, если
уравнение относительно функции $f$
$$
\Ef_{\ta}f(T)=0\qquad\mbox{для всех $\ta\in\Ta$}
$$
имеет только тривиальное $f\equiv 0$ решение.
\end{description}
Полнота очевидно является свойством семейства распределений
статистики $X$. Поэтому часто говорят о полных семействах
распределений (зависящих от $\ta$, $\ta\in\Ta$).

\underline{{\bf Теорема}}(Леман, Шефаре, 1955)
\begin{quote}
Если $T=T(X)$\т полная достаточная статистика и $\ph=\ph(T)$\т несмещенная оценка $\ta$, $\ta\in\Ta$, то
$\ph(T(X))$\т наилучшая несмещенная оценка $\tau(\ta)$.
\end{quote}

{\it Доказательство}

Достаточно доказать единственность такой оценки $\ph$.

Предположим, что существует другая (отличная от $\ph(T)$)
несмещенная оценка $\psi(T)$, так что
$$
\Ef_{\ta}\psi(T)=\Ef_{\ta}\ph(T)=\tau(\ta)\qquad\mbox{для
всех $\ta\in\Ta$}
$$

В этом случае
$$
\Ef_{\ta}[\psi(T)-\ph(T)]=0\qquad\mbox{для всех
$\ta\in\Ta$}
$$

Поскольку статистика $T$\т полная, отсюда следует, что
$$
\psi(T)-\ph(T)=0
$$
почти наверное, для всех $\ta\in\Ta$.

Т.е. оценка $\ph$ единственна (с точностью до множества меры нуль), что и требовалось доказать. $\Box$

\underline{Пример 1.} Испытания Бернулли.
\begin{quote}
Число успехов $S_{n}$ (частота) в $n$ испытаниях Бернулли является
полной достаточной статистикой для вероятности успеха $\ta$,
когда эта вероятность $\ta$ рассматривается как неизвестный
параметр, $\ta\in (0, 1)$.
\end{quote}

Как известно, распределение $S_{n}$ является биномиальным:
$$
P_{\ta}(S_{n}=m)=C_{n}^{m}\ta^{m}(1-\ta)^{n-m}\qquad\mbox{для}\;
m=\overline{0,n}.
$$

Поэтому речь идет о полноте семейства биномиальных распределений,
зависящих от параметра $\ta$, $\ta\in (0, 1)$. Рассмотрим
уравнение относительно $f(\cdot)$:
$$
\forall\ta\in (0,1)\qquad \Ef_{\ta}f(S)=0\eqno (*)
$$

В данном случае функция $f(\cdot)$ должна быть определена на
множестве $(0, 1, 2, \ldots, n)$, так что можно говорить о
последовательности $f(0), f(1), \ldots, f(n)$.

Уравнение $(*)$ имеет вид:
$$
\forall\ta\in (0,1)\qquad
\sum\limits_{m=0}^{n}C^{m}_{n}f(m)\ta^{m}(1-\ta)^{n-m}=0.
\eqno (**)
$$

Введем переменную $z=\frac{\ta}{1-\ta}$. Очевидно, что $z\in (0, \infty)$ и пробегает это множество, когда
$\ta$ пробегает множество (0, 1). Сократив $(**)$ на множитель $(1-\ta)^n$, получаем уравнение для
последовательности $f(0), f(1), \ldots, f(n)$, \те для функции $f(\cdot)$:
$$\sum\limits_{m=0}^{n}C^{m}_{n}f(m)z^{m}=0,\qquad z\in(0, \infty).$$

Многочлен (от $z$) степени $n$ может тождественно (на открытом
множестве) обращаться в нуль, только если все его коэффициенты равны
нулю.

Отсюда следует, что $f(0)=f(1)=\ldots=f(n)=0$.

Таким образом, уравнение $(*)$ имеет лишь тривиальное решение, т.е. статистика $S_{n}$ полная.

Получили, что частота $\frac{S_{n}}{n}$ является для испытаний
Бернулли \underline{наилучшей} несмещённой оценкой вероятности
успеха. %$\\Df iamond$

\underline{Пример 2.} Выборка из показательного распределения.
\begin{quote}
Пусть $x_{1}\sco x_{n}$\т выборка из распределения с плотностью
$$
p(x, \ta)=\case{\frac{1}{\ta}\exp\left(-\frac{x}{\ta}\right), & \text{ для } x\ge 0 \\
0, & \text{ для } x<0,}
$$
где $\ta\in (0, \infty)$\т неизвестный параметр. Нам уже известно, что $T=\sum\limits_{i=1}^{n}x_{i}$
является достаточной статистикой для $\ta$. Покажем, что статистика $T$\т полная.
\end{quote}

Нетрудно показать, что $T$ имеет плотность, задаваемую формулой:
$$
q_{n}(x,
\ta)=\left(\frac{1}{\ta}\right)^{n}\frac{x^{n-1}}{(n-1)!}\exp\left(-\frac{x}{\ta}\right)\qquad\mbox{для}\;
x\ge 0.
$$

Это распределение называют {\it гамма-распределением}, в котором
$\ta$ служит масштабным параметром. (Случайная величина $T$ по
распределению совпадает со случайной величиной $\ta\gamma$, где
случайная величина $\gamma$ имеет так называемое <<стандартное>>
гамма\ч распределение с плотностью
$$
\frac{x^{n-1}}{(n-1)!}\exp\left(-x\right) \qquad\mbox{для}\; x\ge
0,
$$
где $n$ может принимать натуральные значения).

Полнота статистики $T$ означает полноту относительно $\ta$
семейства гамма-распределений.

Рассмотрим уравнение
$$
\Ef_{\ta}f(T)=0 \qquad\mbox{для всех}\; \ta >0
$$
или
$$
\int\limits_{0}^{\infty}f(x)\frac{x^{n-1}}{(n-1)!}\frac{1}{\ta^n}e^{-\frac{x}{\ta}}dx=0\qquad\mbox{для}\; \ta
>0
$$

Введем новую переменную $t=\frac{1}{\ta}$; после сокращений
получим уравнение
$$
\int\limits_{0}^{\infty}\widetilde{f}(x)e^{-{tx}}dx=0\qquad\mbox{для
всех}\; t>0
$$
$$
(\mbox{где }\widetilde{f}(x)=x^{n-1}f(x)).
$$

Левая часть этого уравнения\т это преобразование Лапласа функции $\widetilde{f}(\cdot)$. Оно тождественно
(относительно $t$) равно нулю только для $\widetilde{f}(\cdot)=0$, или, что эквивалентно,
$f(\cdot)=0$. Отсюда следует, что статистика $T$\т полная. %$\\Df iamond$

\underline{Пример 3.}
\begin{quote}
Пусть $\{P_{\ta}, \ta\in\Ta\}$\т $k$-параметрическое экспоненциальное семейство распределений, где плотность
$$
p(x,
\ta)=\bbc{\exp\bbr{\sum\limits_{j=1}^{k}c_{j}(\ta)T_{j}(x)+d(\ta)+S(x)}}I_{A}(x)
\eqno (***)
$$
По теореме факторизации $T(X)=(T_{1}(X)\sco T_{k}(X))$ есть достаточная статистика для $\ta$,
$\ta\in\Ta$.
\end{quote}

\underline{{\bf Теорема}}
\begin{quote}
Если область значений векторной функции $(c_{1}(\ta)\sco c_{k}(\ta))$, которую она
заполняет, когда $\ta$ пробегает параметрическое множество $\Ta$, содержит какое-либо открытое множество, то
статистика $T$\т полная. (Семейство распределений с плотностями $(***)$ полное).
\end{quote}

Доказательства этой теоремы мы не приводим. Оно может быть основано
на свойствах преобразований Лапласа и Фурье (на обратимости этих
преобразований), подобно \underline{Примеру 2}.

Из этой теоремы можно извлечь много результатов, относящихся ко
многим известным семействам распределений. В частности, утверждения
\underline{Примеров 1 и 2}. Еще одним следствием этой теоремы
является полнота статистики $(\ol x, s^{2})$, достаточной дл я
параметров нормального распределения
 $N(a, \si^{2})$ в случае выборки из этого распределения. %$\\Df iamond$

\underline{Пример 4.} Линейная гауссовская модель.
\begin{quote}
Линейная гауссовская модель $X\sim N(l, \si^{2}I), l\in L, L$\т задано. Следствием приведенной выше теоремы
является утверждение о полноте достаточной статистики $(\proj_{L}X,
|\proj_{L^{\perp}}X|^{2})$ для $(l, \si^{2}I)$.%$\\Df iamond$
\end{quote}

\section{Условное математическое ожидание}

\subsection{Сведения из других курсов}
\subsubsection{Вероятностное пространство и случайные величины}

\begin{itemize}
\item
{\it Вероятностной моделью}, или {\it вероятностным пространством} называют набор $(\Om, \Ac, P)$, где

$\Om$\т это множество точек $\Om $; $\Ac$\т $\si$-алгебра подмножеств из $\Om$, а $P$\т вероятностная мера на
$\Ac$.
\item
Множество $\Om$ называют {\it пространством элементарных исходов}
(или элементарных событий).
\item
Множества из $\Ac$ называют {\it исходами} или {\it событиями}.
\item
Множество $A\subset\Om$ называют {\it $\Ac$-измеримым}, если $A\in \Ac$.
\item
Для всякого $A$ из $\Ac$ значение функции $P$ на $A$, т.е. величину $P(A)$, называют {\it вероятностью
события $A$}.
\end{itemize}

На числовой прямой выделяют $\si$-алгебру борелевских множеств $\Bc$. Это минимальная $\si$-алгебра
подмножеств числовой прямой, которая содержит произвольные интервалы, полуинтервалы и отрезки числовой
прямой.
\begin{itemize}
\item
Действительная функция $\xi=\xi (\Om ) $, определенная на
$\Om$, называется {\it случайной величиной}, если множества вида
$$
\{\Om :\xi (\Om )\in B\} \eqno (1)
$$
являются событиями (т.е. принадлежат $\Ac$) для любых борелевских множеств $B$, $B\in\Bc$.
\end{itemize}

Каждая случайная величина $\xi $ определяет в пространстве $\Om$ некоторую совокупность подмножеств,
образующих $\si$-алгебру, далее обозначаемую как $A_{\xi }$, состоящую из событий вида (1), когда $B$
пробегает множество~$\Bc$.

\subsubsection{Производная Радона\ч Никодима}

Пусть на некоторой $\si$-алгебре ${\cal F}$ подмножеств из $\Om$ заданы меры $\mu$ и $\la $.

\begin{itemize}
\item
Меру $\la $ называют {\it абсолютно непрерывной} относительно
меры $\mu$, если из равенства $\mu (A)=0$ следует, что и $\la
(A)=0$ (для множеств $A$ из ${\cal F}$).
\item
Меру $\mu$ называют {\it $\si$-конечной}, если $\Om$ можно представить в виде объединения счетной
совокупности измеримых множеств, $\mu$-меры которых конечны, т.е., если
$$
\Om =\bigcup\limits^{\infty}_{i=1}A_{i},
$$
причем $\mu (A_{i})<\infty , i=1,2,\ldots$
\end{itemize}


\underline{\bf Теорема Радона-Никодима}
\begin{quote}
Предположим, что на измеримом пространстве $(\Om, {\cal F})$ задана $\si$-конечная мера $\mu$ и мера $\la $,
абсолютно непрерывная относительно $\mu$.

Тогда существует ${\cal F}$-измеримая функция $f(\Om )$ такая,
что для всякого $A\in{\cal F}$
$$
\la (A)=\int\limits_{A}f(\Om )\mu (d\Om ).
$$

С точностью до множества $\mu$-меры нуль, функция $f(\Om)$ единственная.
\end{quote}
\begin{itemize}
\item
Функцию $f(\Om )$ называют {\it производной Радона\ч Никодима} меры
$\la $ по мере $\mu$, или {\it плотностью} меры $\la $
относительно меры $\mu$:
$$
f(\Om )=\frac{d\la }{ d\mu}(\Om )
$$
\end{itemize}


\subsection{Определение условного математического ожидания}

Пусть на вероятностном пространстве $(\Om, \Ac, P)$ заданы две случайные величины $X=X(\Om )$ и $Y=Y(\Om )$.

Мы хотим определить математическое ожидание $X$ при данном $Y$, в
дальнейшем обозначаемое как $\Ef(X|Y)$.

Введем несколько более общее определение условного математического ожидания $X$ относительно произвольной
$\si$-подалгебры данной нам $\si$-алгебры $\Ac$. Это математическое ожидание мы затем свяжем с $\Ef(X|Y)$.

Пусть $\Gc$\т некоторая $\si$-подалгебра $\si$-алгебры $\Ac$. (Это означает, что, если множество $A$ входит в
$\Gc$, оно также входит и в $\Ac$). Определим условное математическое ожидание $X$ относительно $\Gc$, в
дальнейшем обозначаемое как $\Ef(X|\Gc)$.

Представим $X$ в виде
$$
X=X^{+}-X^{-},
$$
где $X^{+}\ge 0$, $X^{-}\ge 0$.

Определим $\Ef(X^{+}|\Gc)$ и $\Ef(X^{-}|\Gc)$ и затем положим
по определению:
$$
\Ef(X|\Gc)=\Ef(X^{+}|\Gc)-\Ef(X^{-}|\Gc), \eqno (1)
$$
если хотя бы одно из этих условных математических ожиданий конечно.

Таким образом, $\Ef(X|\Gc)$ может принимать значения $+\infty$
или $-\infty$. (Такую возможность имеет и $\Ef X$ при этом способе
определения.) Впрочем, можно ограничиться случаем, когда
$\Ef|X|<\infty$.

Итак, надо определить $\Ef(X|\Gc)$ для $X\ge 0$.

На $\si$-алгебре $\Gc$ рассмотрим две меры: $P(\cdot )$ и $Q(\cdot )$, положив для произвольного $A\in \Gc$
$$
Q (A)=\int\limits_{A}XP(d\Om ) \eqno (2)
$$

Ясно, что мера $Q$ абсолютно непрерывна относительно меры $P$.
Поэтому, по теореме Радона-Никодима, существует функция $f=f(\Om
)$, измеримая относительно $\Gc$ и такая, что
$$
Q (A)=\int\limits_{A}f(\Om )P(d\Om ) \eqno (3)
$$

Функцию $f(\Om )$ из (3) назовем {\it условным математическим ожиданием $X$} (здесь $X\ge 0$) {\it
относительно $\si$-алгебры $\Gc$}, т.е.:
$$
\Ef(X|\Gc)(\Om )= f(\Om ).
$$

Определив $\Ef(X^{+}|\Gc)$ и $\Ef(X^{-}|\Gc)$, по формуле (1)
определим $\Ef(X|\Gc)$ для произвольной случайной величины $X$.

Таким образом, $\Ef(X|\Gc)$\т это случайная величина, измеримая относительно $\si$-алгебры $\Gc$. Она
определена единственным образом, с точностью до множеств нулевой вероятности.

Пусть сейчас $\Gc=\Ac_{Y}$. Так как $\Ef(X|\Ac_{Y})$ измерима относительно $\Ac_{Y}$, как функция от $\Om $,
эта случайная величина с вероятностью 1 постоянна на множествах вида $\{\Om : Y(\Om )=\const\}$. Поэтому
$\Ef(X|\Ac_{Y})$ можно рассматривать как функцию от $Y=Y(\Om )$, и, по определению, можно положить
$$
\Ef(X|Y)=\Ef(X|\Ac_{Y}).
$$

\subsection{Некоторые свойства условного математического ожидания}

\begin{enumerate}
\item
$$
\int\limits_{A}\Ef(X |\Gc)P(d\Om )=\int\limits_{A}XP(d\Om )
$$
для всякого $A\in \Gc$.

Это свойство\т всего лишь другая запись определения (3.2.3).

Заметим различие между $X$ и $\Ef(X|\Gc)$: случайная величина $X$, вообще говоря, не измерима относительно
$\Gc$ (она измерима относительно более <<богатой>> $\si$-алгебры $\Ac$, $\Gc\subset \Ac$).
\item
$$
\Ef\Ef(X|\Gc)=\Ef X.
$$

Для доказательства надо положить $A=\Om$ в свойстве 1.

Тогда:
$$
\Ef[\Ef(X|\Gc)]=\int\limits_{\Om}\Ef(X, \Gc)\,dP=\int\limits_{\Om}X\,dP=\Ef X,
$$
что и требовалось.
\item
Линейное свойство:
$$
\Ef(aX+bY|\Gc)=a \Ef(X|\Gc)+b \Ef(Y|\Gc)
$$
для произвольных случайных величин $X$, $Y$ и постоянных $a$, $b$.
При этом левая часть существует, если существует правая часть.

Для доказательства достаточно показать, что для любого $A\in \Gc$
$$
\int\limits_{A} \Ef(aX+bY|\Gc)\,dP=\int\limits_{A}[ a \Ef(X|\Gc)+b \Ef(Y|\Gc)]\,dP \eqno(1)
$$
и что $ a \Ef(X|\Gc)+b \Ef(Y|\Gc)$ измеримо относительно
$\Gc$. Последнее, впрочем, очевидно.

Преобразуем левую часть (1):
$$
\int\limits_{A} \Ef(aX+bY|\Gc)\,dP=\int\limits_{A}[aX+bY]\,dP=
$$
$$
a\int\limits_{A}[\Ef(X|\Gc)]\,dP+b\int\limits_{A}[\Ef(Y|\Gc)]\,dP
=\int\limits_{A}[ a \Ef(X|\Gc)+b \Ef(Y|\Gc)]\,dP,
$$
что и требовалось.
\item
Если $X$ измерима относительно $\Gc$, то $\Ef(X|\Gc)=X$.

В частности,
$$
\Ef(X|\Ac_{X})=X.
$$
\item
Если $X$ и $Y$ независимы, то
$$
\Ef(X|Y)=\Ef X.
$$

Для доказательства достаточно проверить, что для любого $A\in \Ac_{Y}$:
$$
\int\limits_{A}\Ef(X|Y)\,dP=\int\limits_{A}(\Ef X)\,dP \eqno (2)
$$

Обозначим через $I_{A}=I_{A}(\Om )$ индикаторную функцию
множества $A$.

Как случайная величина, $I_{A}$ измерима относительно $\Ac_{Y}$. При этом случайные величины $X$ и $I_{A}$
независимы, ибо независимы две $\si$-алгебры $\Ac_{X}$ и $\Ac_{Y}$.

Преобразуем левую часть (2), заметив предварительно, что правая
часть (2) равна $(\Ef X)P(A)$.

Имеем:
$$
\int\limits_{A}\Ef(X|Y)\,dP=\int\limits_{A}X\,dP=\Ef[XI_{A}]=(\Ef X)\Ef I_{A}=(\Ef X)P(A)
$$

(в силу независимости $X$ и $I_{A}$), что и требовалось.

\item
Условные вероятности.

Как мы только что вспомнили, $P(A)=\Ef I_{A}$. По аналогии с этим равенством, условную вероятность события
$A$ относительно $\si$-алгебры $\Gc$ определим как $P(A|\Gc)=\Ef(I_{A}|\Gc)$. Соответственно, условная
вероятность события $A$ относительно случайной величины $Y$ (при данном $Y$) есть $P(A|Y):=P(A|\Ac_{Y})$.

\item
Условные распределения.

Напомним, что {\it распределением} случайной величины $X$ мы
называем совокупность вероятностей вида
$$
P_{X}(B) : =P(X\in B) ,   B\in \Bc,
$$
когда $B$ пробегает $\si$-алгебру борелевских множеств числовой прямой. При этом $P_{X}(B)$ как функция $B\in
\Bc$ образует на $\Bc$ вероятностную меру.

По аналогии с этим условным распределением случайной величины $X$ относительно $\si$-алгебры $\Gc$
естественно называть совокупность условных вероятностей
$$
P_{X}(B|\Gc) := P(X\in B \vl \Gc)(\Om), B\in \Bc. \eqno (3)
$$

Из дальнейших свойств условного математического ожидания будет следовать, что с вероятностью 1 эти условные
распределения вероятностей $\si$-аддитивны.

Не следует забывать, что (3)\т это случайная величина, определенная с точностью до множества меры нуль. Можно
показать, что существует такой вариант ее определения, что (3) как функция $B$, $B\in \Bc$, с вероятностью 1
образует на $\Bc$ (случайную) вероятностную меру. В этом случае
$$
\Ef(X|\Gc)(\Om )=\int\nolimits X(\Om')P_{X}(d\Om'|\Gc)(\Om )
$$
почти наверное.

Впрочем, в простой ситуации, которую мы рассмотрим в следующем
параграфе, мы определим условное математическое ожидание,
отправляясь от условного распределения. Подобно тому, как
математическое ожидание случайной величины мы обычно вводим,
отправляясь от распределения.
\end{enumerate}

\subsection{Случай простых случайных величин}

В этом параграфе мы рассмотрим $\Ef(X|Y)$ для простых случайных
величин $X$ и $Y$. В этом случае условное математическое ожидание
можно ввести элементарными средствами.

Случайная величина $Y$ называется {\it простой}, если $Y$ можно
представить в виде
$$
Y=\sum y_{j}I(D_j), \eqno (1)
$$
где $I(D )=I_{D}(\Om)$\т индикаторная  функция множества $D$. (Для удобства обозначения $I(D)$
предпочтительнее здесь, чем $I_{D}=I_{D}(\Om )$.)
 Можно считать, что числа $y_{1}, y_{2},\ldots$ различны и что совокупность множеств
$D_j$, $j=1,2,\ldots$ в (1) образует разбиение пространства $\Om$: $D_j\bigcap D_i=\es$, если $j\ne i$;
$\bigcup\limits_{j}D_j=\Om$. Когда случайная величина $Y$ простая, то порожденная ею $\si$-алгебра $\Ac_{Y}$
порождается разбиением $D_1, D_2, \ldots$. (Здесь $D_j$, $j=1,2,\ldots$\т это множества уровня функции
$Y=Y(\Om )$, $D_j=\hc{\Om\cln Y(\Om)=y_j}$.)

Далее мы будем рассматривать $\si$-алгебры, порожденные конечными (или счетными) разбиениями.

Пусть $\Gc$\т такая $\si$-алгебра. Порождающее ее разбиение обозначим, как и выше, через $D_1, D_2, \ldots$

Пусть $X$\т простая случайная величина. Тогда для $\Ef(X|\Gc)$ можно дать элементарное определение.

Начнем с определения условной вероятности.

Положим по определению для всякого $A\in \Ac$
$$
P(A|\Gc)=P(A|\Gc)(\Om
)=\sum\limits_{j}P(A|D_j)I(D_j). \eqno (2)
$$

Ясно, что $P(A|\Gc)$ есть измеримая относительно $\Gc$
случайная величина.

Главное свойство условной вероятности (2):
$$
\Ef P(A|\Gc)=P(A). \eqno (3)
$$

Доказательство очевидно :
$$
\Ef P(A|\Gc)=\sum\limits_{j}P(A|D_j)\Ef I(D_j)=\sum\limits_{j}P(A|D_j)P(D_j)=P(A).
$$

Пусть
$$
X=\sum\limits_{i}x_{i}I(A_{i}). \eqno (4)
$$

По аналогии с $\Ef X=\sum\limits_{i}x_{i}P(A_{i})$, определим
$\Ef(X|\Gc)$ формулой:
$$
\Ef(X|\Gc)=\sum\limits_{i}x_{i}P(A_{i}|\Gc). \eqno (5)
$$

Отметим, что так определенное $\Ef(X|\Gc)$\т измеримая относительно $\Gc$ случайная величина и что
$$
\Ef\Ef(X|\Gc)=\Ef X. \eqno (6)
$$

Доказательство (6) очевидно:
$$
\Ef\Ef(X|\Gc)=\sum\limits_{i}x_{i}\Ef P(A_{i}|\Gc)=\sum\limits_{i}x_{i}P(A_{i}).
$$

Покажем, что определение (5) совпадает с общим определением
математического ожидания из пункта 3.2.

Для этого достаточно проверить, что для любого $B\in\Gc$:
$$
\int\limits_{B}\Ef(X|\Gc)\,dP=\int\limits_{B}X\,dP. \eqno (7)
$$

Так как $B\in \Gc$, то $B$ можно представить в виде объединения
некоторой совокупности множеств $D_j$:
$$
B=\sum\limits_{j\in K}D_j,
$$
где $K$\т некоторое множество индексов.

Далее заметим, что
$$
\int\limits_{B}\Ef(X|\Gc)\,dP= \sum\limits_{j\in
K}\int\limits_{D_j}\Ef(X|\Gc)\,dP,
$$
$$
\int\limits_{B}X\,dP= \sum\limits_{j\in K}\int\limits_{D_j}X\,dP.
$$

Поэтому (7) достаточно доказать для множеств $D_j$, $j=1,2,\ldots$

Итак, положив $B=D_k$, преобразуем левую часть (7), используя (5)
и (2):
$$
\int\limits_{D_k}\Ef(X|\Gc)\,dP
=\sum\limits_{i}x_{i}\int\limits_{D_k}P(A_{i}|\Gc)\,dP
=\sum\limits_{i}x_{i}\sum\limits_{j} P(A_{i}|D_j)\Ef I(D_k)I(D_j)
$$
$$
=\sum\limits_{i}x_{i} P(A_{i}|D_k)P(D_k) =\sum\limits_{i}x_{i}
P(A_{i}D_k).
$$

Преобразование правой части (7) дает тот же результат:
$$
\int\limits_{D_k}X\,dP =\Ef I(D_k)[\sum\limits_{i}x_{i} I(A_{i})]
=\sum\limits_{i}x_{i}\Ef I(A_{i}D_k) =\sum\limits_{i}x_{i}
P(A_{i}D_k),
$$
что и требовалось.

{\it Усреднением} набора чисел $x_1 \sco x_n$ с неотрицательными весами $p_1 \sco p_n$, $\sum\limits_{i=1}^{n}p_{i}=1$
называют число $\sum\limits_{i=1}^{n}x_{i}p_{i}$.
(С вероятностной точки зрения, усреднение\т это математическое ожидание случайной
 величины, принимающей значения $x_{1}, \ldots , x_{n}$ с вероятностями $p_{1}, \ldots , p_{n}$.)

Покажем, что значения, которые принимает случайная величина
$\Ef(X|\Gc)$, суть усреднения значений $X$.

Действительно,
$$
\Ef(X|\Gc)=\sum\limits_{i}x_{i} P(A_{i}|\Gc)
=\sum\limits_{i}x_{i} \sum\limits_{j}P(A_{i}|D_j)I(D_j)
=\sum\limits_{j}\left[\sum\limits_{i}x_{i}
P(A_{i}|D_j)\right]I(D_j).
$$

На множестве $D_j$ случайная величина $\Ef(X|\Gc)$ принимает
значение
$$
y_{j}=\sum\limits_{i}x_{i} P(A_{i}|\Df _{j}).
$$

Отметим, что $ P(A_{i}|D_j)\ge 0$ и что $\sum\limits_{i}P(A_{i}|D_j)=1$, ибо $A_{1},A_{2},\ldots$\т это
разбиение всего пространства. Таким образом, $y_{j}$\т это усреднение набора $x_{1}, \ldots , x_{n}$
значений, принимаемых $X$, с весами $p_{i}=P(A_{i}|D_j)$.

\subsection{Вынесение множителя, постоянного при данном условии}

Следующее свойство условных математических ожиданий\т возможность вынести за знак математического ожидания
случайный множитель, постоянный при данном условии:
$$
\Ef[\ph (Y)X|Y]\stackrel{\mbox{п.н.}}{=}\ph (Y)\Ef(X|Y) \eqno
(1)
$$

Предпочтительнее сформулировать это свойство в более общем виде:

Если $Y$ измерима относительно $\Gc$, то
$$
\Ef(XY|\Gc)\stackrel{\mbox{п.н.}}{=}Y\Ef(X|\Gc) \eqno (2)
$$
при условии, что эти математические ожидания существуют.

Доказательство этого равенства начнем с простых случайных величин.

\subsubsection{Доказательство для случая простых случайных величин}

Пусть $Y$\т простая случайная величина, измеримая относительно $\si$-алгебры $\Gc$. Тогда верно (2).

{\it Доказательство.}

По предположению $Y =\sum\limits_{i}y_{i} I(B_{i})$, причем
$B_{i}\in \Bc$, $i=1,2,\ldots$ Теперь
$$
\Ef(XY|\Gc) =\sum\limits_{i}y_{i} \Ef(I(B_{i})X|\Gc).
$$

Чтобы получить (2), достаточно показать, что
$$
\Ef(I(B)X|\Gc)=I(B)\Ef(X|\Gc),
$$
если $B\in \Bc$.

Поскольку $ I(B)\Ef(X|\Gc)$ измерима относительно $\Gc$, для
этого достаточно показать, что для любого $A\in \Gc$
$$
\int\limits_{A} I(B)\Ef(X|\Gc)\,dP=\int\limits_{A} I(B)X\,dP \eqno
(3)
$$

Преобразуя левую часть, докажем, тем самым, (3):
$$
\int\limits_{A} I(B)\Ef(X|\Gc)\,dP=\int\limits_{A\cap B} \Ef(X|\Gc)\,dP =\int\limits_{A\cap B} X\,dP =\int\limits_{A} I(B)X\,dP ,
$$
что и требовалось. $\Box$

\subsubsection{Общий случай}

Пусть $Y$ измерима относительно $\Gc$, $\Ef|X|<\infty$,
$\Ef|Y|<\infty$, $\Ef|XY|<\infty$. Тогда верно (2).

{\it Доказательство.} Основывается на пункте 3.5.1 и обобщенной
теореме Лебега о мажорированной сходимости, которая будет дана
позже.

Выбираем последовательность простых случайных величин $Y_{n}$ так,
чтобы $Y_{n}\uparrow Y$ п.н. при $n\to\infty$. В таком случае
$$
\Ef(XY_{n}|\Gc)\stackrel{\mbox{п.н.}}{=}Y_{n}\Ef(X|\Gc)
$$
в силу 3.5.1.

По упомянутой теореме
$$
\Ef(XY_{n}|\Gc)\stackrel{\mbox{п.н.}}{\longrightarrow} \Ef(XY|\Gc)
$$

Кроме того,
$$
Y_{n}\Ef(X|\Gc)\stackrel{\mbox{п.н.}}{\longrightarrow}Y \Ef(X|\Gc)
$$

Это и доказывает (2). $\Box$

\underline{Следствие:}
$$
\Ef[\ph (Y)X|Y]\stackrel{\mbox{п.н.}}{=}\ph (Y)\Ef(X|Y).
$$

\underline{\bf Лемма (обобщенная теорема Лебега о мажорируемой сходимости).}
\begin{quote}
Пусть $|\al_{n}|\le\eta$, $\Ef\eta <\infty$ и
$\al_{n}\stackrel{\mbox{п.н}}{\to}\al$ при $n\to\infty$.

Тогда
\begin{itemize}
\item[(a)]
$$
\Ef(\al_{n}|\Gc) \stackrel{\mbox{п.н.}}{\longrightarrow}
\Ef(\al|\Gc)
$$
\item[(b)]
$$
\Ef(|\al_{n}-\al|\, \Big|\, \Gc)
\stackrel{\mbox{п.н.}}{\longrightarrow} 0
$$
\end{itemize}

\end{quote}

Сравним с (обычной) \underline{теоремой Лебега} (о мажорированной
сходимости):
\begin{quote}
Пусть $|\xi_{n}|\le\eta$, $\Ef\eta <\infty$ и
$\xi_{n}\stackrel{\mbox{п.н}}\to\xi$ при $n\to\infty$.

Тогда
\begin{itemize}
\item[(a)]
$$
\Ef\xi_{n} \stackrel{\mbox{п.н.}}{\longrightarrow} \Ef\xi\mbox{  ($\Ef\xi
$ существует)}
$$
\item[(b)]
$$
\Ef(|\xi_{n}-\xi|) \stackrel{\mbox{п.н.}}{\longrightarrow} 0
$$
\end{itemize}
\end{quote}

{\it Доказательство.}

Положим
$$
\xi_{n} :=\supl{m: m\ge n} |\al_{m}-\al|.
$$

Ясно, что $\xi_{n}\ge |\al_{n}-\al| $.

Так как $\al_{n}\stackrel{\mbox{п.н}}\to\al$, то
$\xi_{n}\downarrow 0 $ п.н.

Теперь
$$
|\Ef(\al_{n}|\Gc)-\Ef(\al|\Gc)|=|
\Ef\big[(\al_{n}-\al)\,\Big|\,\Gc\big]|\le
\Ef(|\al_{n}-\al|\,\Big|\,\,\Gc)\le \Ef(\xi_{n}|\Gc).
\eqno (*)
$$

Докажем, что
$$
\Ef(\xi_{n}|\Gc) \stackrel{\mbox{п.н.}}{\longrightarrow}0.
$$

Из этого вытекает утверждение леммы.

Заметим, что
$$
0\le \Ef(\xi_{n+1}|\Gc)\le \Ef(\xi_{n}|\Gc)\mbox{ п.н.}
$$

Поэтому существует предел (почти наверное):
$$
h :=\lim\limits_{n\to\infty} \Ef(\xi_{n}|\Gc)\ge 0
$$

Далее,
$$
0\le\ints{\Om}h\,\,dP\le\ints{\Om} \Ef(\xi_{n}|\Gc)\,\,dP = \ints{\Om} \xi_{n}\,\,dP=\Ef\xi_{n}\longrightarrow 0.
$$


Последнее заключение есть следствие цитированной теоремы Лебега, ибо
$$
0\le\xi_{n}\le 2\beta , \Ef\beta <\infty, \xi_{n}
\stackrel{\mbox{п.н.}}{\longrightarrow}0 .
$$

Получили, что $\int\limits_{\Om}h\,dP=0$.

Т.к. $h\ge 0$, то $h=0$ п.н. Следовательно:
$$
\Ef(\xi_{n}|\Gc) \stackrel{\mbox{п.н.}}{\longrightarrow}0
$$

Это и доказывает лемму. $\Box$

\subsection{$\si$-аддитивность условной вероятности}

Пусть $A=\sum\limits_{i}A_{i}$, причем $A_{i}\bigcap
A_{j}=\emptyset$, если $i\ne j$.

Тогда
$$
P(A|\Gc) \stackrel{\mbox{п.н.}}{=}\sum\limits_{i} P(A_{i}|\Gc).
$$


Для доказательства достаточно положить в предыдущей лемме
$\al_{n}=\sum\limits_{i=1}^{n}I(A_{i}) $, $\al =I(A)$ и
заметить, что $\al_{n}\uparrow\al$ при $n\to\infty$. Прочие
условия леммы тоже соблюдены.

\subsection{Условная дисперсия}

По аналогии с определением дисперсии $\Df X=\Ef(X-\Ef X)^{2}$, введем
условную дисперсию $X$ относительно ${\Gc}$, положив, по
определению,
$$
\Df (X|\Gc)=\Ef\{[X-\Ef(X|\Gc)]^{2}|\Gc\}.
$$

Покажите, что
$$
\Df X=\Ef \Df (X|\Gc)+ \Df \Ef(X|\Gc).
$$
(при условии, что $\Df X$ существует).

\subsection{Наилучший квадратичный прогноз}

(Формулируется в виде задачи.)

Пусть случайные величины $\xi $ и $\eta$ заданы на одном
вероятностном пространстве. Надо найти для $\eta$ наилучший прогноз
по наблюдаемой случайной величине $\xi $. Иначе говоря, надо найти
такую функцию $f(\xi )$, что для любой функции $g(\xi )$:
$$
\Ef(\eta -f(\xi ))^2\le \Ef(\eta -g(\xi ))^2.
$$

\underline{Ответ:}
$$
f(\xi )=\Ef(\eta |\xi) .
$$

\subsection{Пример вычисления условного математического ожидания}

Рассмотрим пример одновременно типичный и вычислительно несложный. Пусть вероятностная тройка $(\Om, \Ac, P)$
такова:
\begin{itemize}
\item
$\Om=\{\Om :\Om =(x,y), 0\le x\le 1, 0\le y\le 1\}$;
\item
$\Ac$\т $\si$-алгебра борелевских множеств $\Om$;
\item
$P$\т мера Лебега на $\Om$.
\end{itemize}

Рассмотрим две случайные величины $\xi =\xi (\Om )$ и $\eta=\eta
(\Om )$:
$$
\xi =\xi (x, y)=x, \eta =\eta (x, y)=x+y.
$$

Вычислим $\Ef(\xi|\eta )$.

Отметим, что $A_{\xi }$ ($\si$-алгебра подмножеств $\Om$, порожденная случайной величиной $\xi $) - это
совокупность цилиндрических множеств из $\Om$ вида $B\times [0,1]$, где $B$ - произвольное борелевское
множество из [0,1].

Сигма-алгебра $A_{\eta }$ устроена схожим образом. Ее составляют
(пересеченные с $\Om$) прямые произведения борелевских множеств,
лежащих на прямой $x=y$, и прямой $\{(x,y): x+y=0\}$. (См. чертеж)

% TODO: add picture
%\begin{picture}(500,150)
%\end{picture}


Хорошо видно, что $\xi $ не измерима относительно $A_{\eta }$, и
обратно.

По определению, $\Ef(\xi|\eta )$ - такая измеримая относительно
$A_{\eta }$ функция $f(x,y)$ от $\Om =(x,y)$, для которой
$$
\iint\limits_{(x,y)\in A}f(x,y)\,dP=\iint\limits_{(x,y)\in A}x\,dP \eqno
(1)
$$
для любого $A\in A_{\eta }$.

Так как $f(x,y)$ измерима относительно $A_{\eta }$, она должна
зависеть от $(x,y)$ через посредство $\eta =x+y$. Это означает, что
в качестве $f(x,y)$ здесь следует взять, пока произвольную, функцию
$g(x+y)$, где $g(\cdot )$ - измеримая функция одного переменного.

В (1) достаточно рассматривать только множества $A$ вида
$$
A=\{(x,y): x+y\le z, (x, y)\in\Om\},
$$
где $z$ - произвольно.

При таком выборе $f(x,y)$ и $A$ условие (1) примет вид:
$$
\iint\limits_{\stackrel{x+y\le z}{(x,y)\in
\Om}}g(x+y)\,dP=\iint\limits_{\stackrel{x+y\le
z}{(x,y)\in \Om}}xdxdy \eqno (2)
$$

В интегралах (2) следует сделать замену переменных $(x,y)\to (u,
v)$, положив $u=x+y$.

Выбор второй переменной не очень важен, положим, например, $v=x-y$.

После этой замены двойные интегралы в (2) представим в виде
повторных.

Для простоты возьмем $z\in [0,1]$. (Случай $z\in [1,2]$ легко
сводится к рассматриваемому.) Получим уравнение для $g(\cdot)$
$$
\frac{1}{2}\int\limits^{z}_{0}\left(g(u)\int\limits^{u}_{-u} d
v\right)du=\frac{1}{2}\int\limits^{z}_{0}\left(\int\limits^{u}_{-u}\frac{u+v}{2}dv\right)
d u.
$$

Отсюда
$$
\int\limits^{z}_{0}ug(u)\,du=\intl{0}{z}\frac{1}{2}u^{2}du,
$$
или $$g(z)=\frac{z}{2}.$$

Таким образом, здесь
$$
\Ef(\xi|\eta )=\eta /2,
$$
или
$$
\Ef(x|x+y)=\frac{x+y}{2}.
$$

Заметим, что при вычислении $\Ef(X|X+Y)$, если $X$ и $Y$ независимы и
одинаково распределены (как в рассмотренном выше примере), можно
обойтись практически без вычислений, если вспомнить некоторые из
перечисленных выше свойств условных математических ожиданий.

Во-первых, в силу симметрии,
$$
\Ef(X|X+Y)=\Ef(Y|X+Y).
$$

Затем
$$
X+Y= \Ef(X+Y|X+Y)=\Ef(X|X+Y)+ \Ef(Y|X+Y).
$$

Отсюда
$$
\Ef(X|X+Y)=\frac{1}{2}(X+Y).
$$

\section{Линейная гауссовская модель}

В абстрактной форме - это статистическая модель о (векторном)
наблюдении $X$, $X\in \R^{n}$, $X$ - вектор-столбец, $X=(X_{1}\sco X_{n})^T$.

Предположим, что $X$ - случайный вектор, распределенный по нормальному закону, причем математическое ожидание
$X$, т.е. вектор $\Ef X$, принадлежит заданному линейному подпространству $L, L\subset \R^{n}$, а матрица
ковариаций вектора $X$ равна $\si^{2}I$ (скалярная матрица).

Вектор $l:=\Ef X$ и скаляр $\si^{2}$, $\si^{2}>0$ неизвестны. Короткая запись: наблюдаемый вектор $X$ случаен
и $X\sim N(l, \si^{2}I)$, причем $l\in L$, где $L$ - заданное линейное подпространство.

Статистические задачи в этой модели - выводы о неизвестных параметрах $l$ и $\si^{2}$.

\subsection{Несмещенное оценивание параметров}

В лекциях о достаточных статистиках было сказано, что для параметра $\ta:=(l; \si^{2})$ в этой модели есть
достаточная статистика. Это пара $T=(\proj_{L}X; |\proj_{L^{\perp}}X|^{2})$.

Согласно примеру 2.7.4.4 эта статистика $T$ полна.

Поэтому наилучшая (имеющая наименьшую матрицу ковариаций)
несмещенная оценка параметра $\ta $ должна быть функцией
достаточной статистики (такая оценка единственна).

Заметим, что $\Ef\proj_{L}X=\proj_{L}\Ef X=\proj_{L}l=l$, ибо:
\begin{itemize}
\item
операцию усреднения (вычисления математического ожидания) и
проектирования $X$ можно поменять местами (проектирование $X$ на
подпространство - линейная операция, а усреднение обладает
свойствами линейности);
\item
так как $l\in L$, то $\proj_{L}l=l$.
\end{itemize}

Следовательно, наилучшая несмещенная оценка $l$ уже найдена - это
$\proj_{L}X$.

Чтобы найти наилучшую несмещенную оценку $\si^{2}$, надо подробнее изучить статистические свойства
$\proj_{L}X$ и $\proj_{L^{\perp}}X$.

\subsection{$\chi^2$-распределение}
\begin{description}
\item[\underline{Определение 1 ($\chi^2$-распределение).}]
Пусть $\eta_{1}\sco \eta_{r}$ суть независимые
случайные величины, распределенные каждая по стандартному
нормальному закону $N(0,1)$. Случайной величиной {\it хи-квадрат с
$r$ степенями свободы} называют
$$
\chi^{2} (r):=\eta_{1}^{2}+\ldots+\eta_{r}^{2}.
$$
\end{description}

Распределение случайной величины $\chi^{2} (r)$ для любого
натурального $r$ может быть вычислено во всех подробностях
(плотность, функция распределения, квантили и т.д.). Явный его вид
нам не понадобится. Достаточно сказать, что таблицы распределений и
квантилей есть в сборниках статистических таблиц.

Случайную величину $\chi^{2}(r)$ можно толковать как квадрат длины
случайного вектора ${\vec \eta}=(\eta_{1}\sco \eta_{r})\sim N_{r}(0, I)$, составленного из независимых
одномерных стандартных гауссовских величин $\eta_{i}\sim N (0,1),
i=\overline{1, r}$.

Распределение $N_{r}(0, I)$ часто называют стандартным $r$-мерным
гауссовским распределением, а вектор ${\vec \eta}$ - $r$-мерным
стандартным гауссовским вектором.

\begin{description}
\item[\underline{Определение 2 (нецентральное $\chi^2$-распределение).}]

Пусть ${\vec a}=(a_{1}\sco a_{r})$ - заданный вектор.
Рассмотрим случайную величину
$$
\chi^{2}(r,\De):=(\eta_{1}+a_{1})^{2} \spl (\eta_{r}+a_{r})^{2}
$$

Здесь $\De=a_{1}^{2}\spl a_{r}^{2}$. Из леммы 4.3.1
(которую мы докажем в следующем разделе) следует, что распределение
случайной величины $\sum\limits_{i=1}^{r}(\eta_{i}+a_{i})^{2}$
зависит от $\De:=|\vec a|^{2}$, но не от $\vec a$. Это
обстоятельство отражено в обозначении $\chi^{2}(r,\De)$. Величина
$\De=\sum\limits_{i=1}^{r} a_{i}^{2}$ называется {\it параметром
нецентральности} распределения хи-квадрат. Если $\De=0$,
распределение хи-квадрат называют {\it центральным}.
\end{description}
Нецентрально распределенную случайную величину $\chi^{2}(r,\De)$
можно толковать как квадрат длины $r$-мерного гауссовского вектора
$\vec \eta +\vec a$, причем $\De=|a|^{2}$.

Нетрудно показать, что семейство случайных величин $\chi^{2}
(r,\De)$ стохастически упорядочено по параметру $\De,
\De>0$ , если $r$ - фиксировано.

Иными словами, если $0\le \De_{1}\le \De_{2}$, то для любого
$z>0$
$$
P(\chi^{2}(r,\De_{1})\ge z)\le P(\chi^{2}(r,\De_{2})\ge z)
$$
(о доказательстве скажем позже.)

Графики функций распределения $y= P(\chi^{2}(r,\De_{1})\ge z)$
при разных $\De >0$ выглядят примерно так:

% TO\Df O: add picture
%\begin{picture}(500,150)
%
%\end{picture}

\subsection{Две леммы о круговых нормальных распределениях}

{\underline{\bf Лемма 4.3.1.}}
\begin{quote}
Пусть $X\sim N(l, \si^{2}I)$, $C$ - ортогональная матрица. Тогда
$$
Y:=CX\sim N(Cl, \si^{2}I)
$$

(Cловесная форма: при ортогональных преобразованиях круговое
нормальное распределение остается круговым.)
\end{quote}

{\it Доказательство.}

Для доказательства достаточно вычислить матрицу ковариации вектора
$Y=CX$. Поскольку для любой матрицы $A$ матрица ковариаций вектора
$AX$ есть
$$
\Df (AX)=A(\Df X)A^{T}
$$
(где $\Df \xi$ обозначает матрицу ковариаций вектора $\xi$), то
$$
\Df Y=C(\Df X)C^{T}=C(\si^{2}I)C^{T}=\si^{2}I,
$$
что и требовалось. $\Box$

\begin{description}
\item[\underline{Следствие.}]
Пусть $\eta_{1}\sco \eta_{r}$ суть независимые
$N(0,1)$. Тогда:
$$
(\eta_{1}+a_{1})^{2}\spl (\eta_{r}+a_{r})^{2} \stackrel{d}=(\eta_{1}+\sqrt{\De})^{2}\spl \eta_{r}^{2},
$$
где $\De=a_{1}^{2}\spl a_{r}^{2}.$
\end{description}

Это утверждение доказывает правильность употребления выражения
$\chi^{2}(r,\De)$ для распределения квадрата длины вектора $\vec
\eta +\vec a$. Здесь ${\vec \eta}=(\eta_{1}\sco \eta_{r})$.

{\it Доказательство.}

Доказательство основывается на том, что вектор $\vec \eta +\vec a$
можно ортогональным преобразованием (скажем, $C$) перевести в вектор
с координатами $ (\tilde\eta_{1}+\sqrt{\De}, \tilde\eta_{2},
\ldots, \tilde\eta_{r})^{T}$. При ортогональных преобразованиях
длина вектора не меняется; распределение $C\eta$, так же как и
распределение $\eta$, есть $N(0, I)$. $\Box$

{\underline{\bf Лемма 4.3.2.}}
\begin{quote}
Пусть $L_{1}, L_{2},\ldots$ - попарно ортогональные подпространства,
прямая сумма которых составляет все пространство $\R^{n}$:
$$
L_{1}\oplus L_{2}\oplus\ldots = \R^{n}.
$$

Пусть $\proj_{L}X$ обозначает проекцию вектора $X$ на подпространство $L$ (в евклидовой метрике). Пусть,
скажем, $X\sim N(l, \si^{2}I)$. Тогда:
\begin{itemize}
\item[(a)]
Случайные векторы $\proj_{L_{1}}X, \proj_{L_{2}}X,\ldots$ независимы
(в совокупности) и распределены нормально, причем
$\Ef\proj_{L_{i}}X=\proj_{L_{i}}l, i=1,2,\ldots ;$

\item[(b)]
$$
|\proj_{L_{i}}X|^{2}=\si^{2}\chi^{2}(r_{i},\De_{i})
$$
где $r_{i}=\dim L_{i}, \De_{i}=|\frac{1}{\si}\proj_{L_{i}}l|^{2}$.
\end{itemize}
\end{quote}


{\it Доказательство.}

Рассмотрим в $\R^{n}$ новый ортонормированный базис, который строим,
объединяя ортонормированные базисы подпространств $L_{1},
L_{2},\ldots$

Ради определенности введем соответствующие обозначения:
$$
f_{1}, f_{2},\ldots, f_{r_{1}}  -\mbox{базис } L_{1};
$$
$$
f_{r_{1}+1},f_{r_{1}+2},\ldots, f_{r_{1}+r_{2}} -\mbox{базис }L_{2};
$$
$$
\dotsc \qquad \mbox{и т.д.}
$$

Рассмотрим координаты вектора $X=(X_{1},\ldots, X_{n})$ в базисе
$\{f\}$. Обозначим их через $Y_{1}\sco Y_{n}$.

Как известно векторы-столбцы $Y=(Y_{1}\sco Y_{n})$ связаны с помощью матрицы $C$ перехода соотношением
$Y=CX$. Заметим, что $C$\т ортогональная матрица, и поэтому $Y\sim N(Cl, \si^{2}I)$.

Следовательно, случайные величины $Y_{1}\sco Y_{n}$ независимы, распределены нормально и имеют одну и ту же
дисперсию $\si^{2}$.

Заметим, что
$$
\proj_{L_{1}}X=Y_{1}f_{1}+\ldots+Y_{r_{1}}f_{r_{1}},
$$
$$
\proj_{L_{2}}X=Y_{r_{1}+1}f_{r_1+1}+\ldots+Y_{r_{1}+r_{2}}f_{r_{1}+r_{2}},
$$
и т.д.

Из этих представлений для $\proj_{L_{i}}X, i=1,2,\ldots, n$ и
отмеченных свойств
 случайных величин $Y_{1}, Y_{2}, \ldots$ следует утверждение $(a)$.

Для доказательства $(b)$ заметим, что
$$
|\proj_{L_{1}}X|^{2}=Y_{1}^{2}+\ldots+Y_{r_{1}}^{2}=
$$
$$
\si^{2}\hr{\frac{Y_1^2}{\si^2}\spl \frac{Y_{r_{1}}^2}{\si^2}}=\si^{2}\chi^{2}(r_1,\De_1),
$$
ибо $\frac{Y_1}{\si}\sco \frac{Y_{r_1}}{\si}$ суть независимые случайные величины, распределенные по нормальному
закону.

Параметр нецентральности - это квадрат длины математического
ожидания вектора
$$
\frac{1}{\si}\left(Y_{1}, Y_{2}, \ldots, Y_{r_{1}}\right)^T.
$$

По сказанному выше,
$$
\Ef\left[\frac{1}{\si}\left(Y_{1}, Y_{2}, \ldots, Y_{r_{1}}\right)^T\right]=\frac{1}{\si}\proj_{L_{1}}\Ef X.
$$

Лемма 4.3.2 доказана. $\Box$

\subsection{Линейная модель}

Вернемся к линейной модели $X\sim N(l, \si^{2}I)$, причем $l\in L$, где $L$ задано. Для оценивания $\si^2$
рассмотрим вторую составляющую достаточной статистики: случайную величину $|\proj_{L^{\perp}}X|^{2}$.

Согласно лемме 4.3.2,
$$
|\proj_{L^{\perp}}X|^{2}=\si^{2}\chi^{2}(n-r,\De),
$$
где $n-r=\dim L^{\perp}=n-\dim L$. Параметр нецентральности $\De$ здесь равен
$$
\De=\frac{1}{\si^{2}}|\proj_{L^{\perp}}\Ef X|^{2}=0,
$$
ибо $\Ef X\in L$ по условиям модели, так что $\proj_{L^{\perp}}\Ef X=0$.


Поскольку $\Ef\chi^{2}(m)=m$, наилучшей несмещенной оценкой параметра $\si^{2}$ служит
$$
\frac{1}{n-r}|\proj_{L^{\perp}}X|^{2}=\frac{1}{n-r}|X-\proj_{L}X|^{2}.
$$

Последнее выражение для $\proj_{L^{\perp}}X$ зачастую бывает удобнее
(особенно когда подпространство $L$ задано своим базисом).

Отметим также, что в силу леммы 4.3.2, статистически $\proj_{L}X$ и
$\proj_{L^{\perp}}X$ независимы (как случайные векторы).

\begin{center}
\underline{Замечание о вычислении $\proj_{L}X$ и
$\proj_{L^{\perp}}X$.}
\end{center}

По определению, проекцией точки (вектора) $X$ на множество $L$
называют такую \underline{точку} множества $L$, на которой
достигается минимум расстояния:
$$
\proj_{L}X:=arg\min_{Z\in L}|X-Z|=arg\min_{Z\in L}|X-Z|^{2};
$$
$$
\proj_{L}X= arg\min_{Z\in L}\sum\limits_{i=1}^{n}(X_{i}-Z_{i})^{2}.
$$

Последнее равенство объясняет название оценок в этой задаче: оценки
наименьших квадратов (как и всего метода: метод наименьших
квадратов).

Отметим также, что
$$
\min_{Z\in
L}\sum\limits_{i=1}^{n}(X_{i}-Z_{i})^{2}=|\proj_{L^{\perp}}X|^2=|X-\proj_{L^{\perp}}X|^2.
$$

\subsection{Выборка из нормального закона}

Простой пример гауссовской модели - выборка из нормального закона $N(a, \si^{2})$:
$$
X=(X_{1}\sco X_{n})^{T}, \mbox{ где } X_{i}\sim N(a, \si^{2}I).
$$

При этом $X\sim N(l, \si^{2}I)$, где $l=a(1, 1,\ldots, 1)^{T}$.

Таким образом, подпространство $L$ здесь одномерное; оценивая $l$,
мы, тем самым, оцениваем $a$.

Наилучшие несмещенные оценки $a$ и $\si^{2}$ суть $\ol X=\frac{1}{n}\sum\limits_{i=1}^{n}X_{i}$ и
$s^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(X_{i}-\ol X)^{2}$. Эта же пара $(\ol X, s^{2})$ и служит
достаточной статистикой для $(a, \si^{2})$.

Статистики $\ol X$ и $s^{2}$  независимы, $\ol X\sim N(a, \frac{1}{n}\si^{2})$;
$$
(n-1)s^{2}=\si^{2}\chi^{2}(n-1).
$$
\subsection{Факторные модели (факторные эксперименты)}

В этих экспериментах {\it отклик} (регистрируемый результат опыта),
точнее - его неслучайная, закономерная часть, - есть результат
действия одного или нескольких известных {\it факторов}.

Регистрируемый результат опыта может отличаться от ожидаемого
благодаря присутствию случайной ошибки.

\subsubsection{Однофакторная гауссовская модель}

Некий фактор может принимать несколько различных значений,
называемых уровнями: $A_{1}\sco A_r$. При каждом
значении $A_{i}, i=\overline{1,r}$ производится несколько (скажем
$n_{i}$) независимых опытов. Их результаты обозначим через
$X_{ij},i= \overline{1,n_{j}}$ - это номер опыта в серии $j$,
$j=\overline{1,r}$ - серия $j$ соответствует уровню $A_{j}$.

\underline{Статистическая модель:}
$$
x_{ij}=a_{j}+\ep_{ij},\qquad j=\overline{1,r},
$$
где $a_{1}\sco a_r$\т некие числа (обычно неизвестные
экспериментатору), $\ep_{ij}$ - независимые случайные
величины (<<ошибки>>).

В гауссовской модели дополнительно предполагается, что $\ep_{ij}\sim N(0, \si^{2})$; параметр $\si$ (масштаб
случайных отклонений) обычно неизвестен.

Представление однофакторной модели в каноническом виде $X\sim N(l, \si^{2}I)$ очевидно: в качестве $X$ можно
взять столбец (размерности $n_{1}\spl  n_{r}$), в котором последовательно записаны элементы всех $r$ выборок:
$$
X=(x_{11}, x_{21}, \ldots, x_{n_{1}1}, x_{12}, x_{22}, \ldots,
x_{n_{2}2},\ldots)^{T}.
$$

Линейное подпространство $L$ (которому принадлежит $\Ef X$), порождено
$r$ векторами вида:
$$
(\underbrace{1,\ldots,1}_{n_{1}},0,\ldots,0)^{T},
$$
$$
(\underbrace{0,\ldots,0}_{n_{1}},\underbrace{1,\ldots,1}_{n_{2}},0,\ldots,0)^{T}\mbox{
и т.д.}
$$


Оценки параметров $a_{1}\sco a_r$ и $\si^{2}$ мы получим в этой модели, применяя общие результаты. Здесь:
$a_{j}^{*}=\frac{1}{n_{j}}\sum\limits_{i=1}^{n_{j}}x_{ij}$ для $j=\overline{1,r};$
$$
s^{2}=\frac{1}{\sum\limits_{j=1}^{r}(n_{j}-1)}\sum\limits_{j=1}^{r}\sum\limits_{i=1}^{n_{j}}(x_{ij}-a_{j}^{*})^{2}
$$

Статистики $a_{1}^{*}\sco a_{r}^{*}, s^{2}$ независимы.

\subsubsection{Аддитивная двухфакторная модель}

К двух- (и более) факторной модели приходится прибегать, когда кроме
главного фактора $A$ приходится учитывать действие еще одного (или
нескольких) факторов. Пусть, как выше, $A_{1}\sco A_r$\т
суть уровни фактора $A$, a фактор $B$ принимает уровни $B_{1}\sco B_s$.

Планы эксперимента в этой схеме могут быть более разнообразны, чем в
факторной модели. В данном случае, план опыта указывает, какое
количество независимых повторений $n_{ij}$ надо произвести для
комбинации $A_{i}$ и $B_{j}$ $i=\overline{1,r}, j=\overline{1,s}$
уровней факторов $A$ и $B$.

Наиболее простой и популярный план: $n_{ij}=1$. (Специальное
выражение: <<одно наблюдение в клетке>>).

Результаты опыта можно записать таблицей

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$A\left\backslash B\right.$ & $B_{1}$ & &$B_{j}$ & & $B_{s}$\\
\hline
$A_{1}$ & $x_{11}$ &  & $x_{1j}$ &  & $x_{1s}$\\
\hline
 & & & & & \\
\hline
$A_{i}$ & $x_{i1}$ &  & $x_{ij}$ &  & $x_{is}$\\
\hline
 & & & & & \\
\hline
$A_{r}$ & $x_{r1}$ &  & $x_{rj}$ &  & $x_{rs}$\\
\hline
\end{tabular}
\end{center}

\underline{Статистическая модель (аддитивная):}
$$
x_{ij}=a_{i}+b_{j}+\ep_{ij}, i=\overline{1,r},
j=\overline{1,s}.
$$

Здесь $a_{i}$, $b_{j}$ истолковываются как результаты действия
факторов $A$ и $B$, находящихся на уровнях $A_{i}$ и $B_{j}$. Модель
отражает представление о том, что факторы действуют на отклик, не
взаимодействуя друг с другом, и что их воздействия суммируются.
Величины $\ep_{ij}$ истолковываются как независимые
случайные ошибки.

Если мы предполагаем, что $\ep_{ij}\sim N(0, \si^{2})$, модель называют {\it гауссовской} (хотя автор этого
статистического направления отнюдь не К.\,Ф.\,Гаусс, а Р.\,Фишер).

В приведенном выше представлении аддитивной двухфакторной модели
параметры $(a_{i},b_{j})$ не идентифицируемы: даже если ошибки
отсутствуют ($\ep_{ij}\equiv 0$), по результатам опыта (в
данном случае по суммам $a_{i}+b_{j}$) нельзя однозначно
восстановить величины $a_{i}$, $b_{j}$.

Есть две возможности преодолеть это затруднение:
\begin{itemize}
\item
Ставить вопросы и делать выводы только о таких функциях параметров,
которые определяются однозначно.

К таким относятся, например, попарные результаты $a_{i}-a_{i'}$,
$b_{j}-b_{j'}$ и их комбинации.
\item
Но, по моему мнению, предпочтительней второй путь: иная
параметризация модели. Представим ожидаемое значение отклика (ранее
это было $ a_{i}+b_{j}$) в виде:
$$
\Ef x_{ij}=\mu+\al_{i}+\beta_{j}, i=\overline{1,r},
j=\overline{1,s},
$$
дополнительно наложив на параметры $(\al_{i}, \beta_{j})$ связи:
$$
\sum\limits_{i=1}^{r}\al_{i}=0
,\quad\sum\limits_{j=1}^{s}\beta_{j}=0.
$$

С учетом связей параметры $\mu, \al_{1}, \ldots, \al_{r},
\beta_{1}, \ldots, \beta_{s}$ однозначно восстанавливаются по
матрице $\|\mu+\al_{i}+\beta_{j}\|$.
\end{itemize}

В двухфакторной аддитивной модели (как и в однофакторной) результаты
наблюдений можно представить в виде вектора-столбца.

Удобнее, впрочем, сохранить для $(x_{ij})$ естественную структуру
матрицы (прямоугольной, размера $r\times s$).

Итак, пусть теперь:
$$
X=\|x_{ij}, i=\overline{1,r}, j=\overline{1,s}\|.
$$

Матрицы фиксированного размера образуют линейное подпространство.
Подпространство $L$, которому принадлежит $\Ef X$, имеет размерность
$r+s-1$. Оно порождено $r+s$ матрицами (размера $r\times s$). Каждая
из таких матриц имеет либо строку, либо столбец из единиц; прочие их
параметры равны нулю. Симметрии ради (не изменяя $L$) к
перечисленным матрицам можно присоединить матрицу, сплошь состоящую
из единиц.

Оценки параметров $\mu$, $\al$, $\beta$ получают, проецируя
случайный вектор $X$ на подпространство $L$, т.е. по методу
наименьших квадратов. Иначе говоря, решая экстремальную задачу:
$$
\sum\limits_{i=1}^{r}\sum\limits_{j=1}^{s}(x_{ij}-\mu-\al_{i}-\beta_{j})^{2}\longrightarrow
\min (\mu, \vec\al, \vec\beta),
$$
$$
\vec\al: \sum\limits_{i=1}^{r}\al_{i}=0 , \quad\vec\beta:
\sum\limits_{j=1}^{s}\beta_{j}=0.
$$

Ответ можно записать в компактной форме, если употребить (широко
принятую) символику:
$$
x_{\cdot j}=\frac{1}{r}\sum\limits_{i=1}^{r}x_{ij} , \qquad
x_{i\cdot}=\frac{1}{s}\sum\limits_{j=1}^{s}x_{ij}, \qquad
x_{\cdot\cdot}=\frac{1}{rs}\sum\limits_{i=1}^{r}\sum\limits_{j=1}^{s}x_{ij}.
$$

(Точка замещает индекс, по которому произведено усреднение отклика).

В этих обозначениях наилучшие несмещенные оценки параметров суть:
$$
\mu^{*}=x_{\cdot\cdot},
$$
$$
\al_{i}^{*}=x_{i\cdot}-x_{\cdot\cdot},
$$
$$
\beta_{j}^{*}=x_{\cdot j}-x_{\cdot\cdot},
$$
$$
s^{2}=\sum\limits_{i=1}^{r}\sum\limits_{j=1}^{s}(x_{ij}-x_{i\cdot}-x_{j
\cdot}+x_{\cdot\cdot})^{2}/(r-1)(s-1).
$$

При этом
$$
(r-1)(s-1)s^{2}=\si^{2}\chi^{2}(r-1)(s-1).
$$

Указанные выше оценки можно получить как прямым решением приведенной
ранее экстремальной задачи, так и на основе тождества
$$
\sum\limits_{i=1}^{r}\sum\limits_{j=1}^{s}(x_{ij}-\mu-\al_{i}-\beta_{j})^{2}=
$$
$$
\sum\limits_{i=1}^{r}\sum\limits_{j=1}^{s}\left[(x_{ij}-x_{i\cdot}-x_{j
\cdot}+x_{\cdot\cdot})^{2}+(x_{i\cdot}-x_{\cdot\cdot}-\al_{i})^{2}+(x_{\cdot
j}-x_{\cdot\cdot}-\beta_{j})^{2}+(x_{\cdot\cdot}-\mu)^{2}\right],
$$
$$
\mbox{если}\qquad\sum\limits_{i=1}^{r}\al_{i}=0 ,
\sum\limits_{j=1}^{s}\beta_{j}=0.
$$

\subsection{Линейная регрессия}

В линейной модели вычисление наилучших несмещенных оценок сводится к
вычислению проекции вектора $X$ на заданное линейное подпространство
$L$. Ход вычислений зависит от того, каким образом задано (описано)
подпространство $L$. Сейчас мы рассмотрим частый на практике случай,
когда $L$ порождено заданным набором векторов. Ради определенности,
будем говорить о линейной модели в ее канонической форме, когда
вектор наблюдений $X$ и его ожидаемое значение $l=\Ef X$ - это
$n$-мерные векторы-столбцы.

Пусть векторы (столбцы) $F_{1}\sco F_r$ порождают
подпространство $L$. Эта совокупность векторов может быть как
линейно независимой (базис $L$), так и нет.

Так как $l\in L$, то
$$l=\ta_{1}F_{1}\spl \ta_{r}F_r$$
при некоторых коэффициентах $\ta_{1}\sco \ta_{r}\in \R$. Это представление $l$ можно записать в матричной
форме. Для этого введем матрицу $F$ (размера $n\times r$), столбцами
которой служат векторы $F_1\sco F_r$:
$$F:= \rbmat{\vec F_1 & \vec F_2 & \cdots & \vec F_r}.$$

Определим $r$-мерный вектор-столбец $\ta $, положив $\ta := (\ta_1 \sco \ta_r)^T$.
Тогда $l=F\ta$, а исходная линейная модель представима в виде
$$
X=F\ta+\ep,
$$
где $\ep=(\ep_{1}\sco  \ep_{n})^{T} \sim N(0, \si^{2})$, $\ta\in \R^{r} $, матрица $F$ задана. Линейную
модель в такой форме часто называют регрессионной моделью (задачей линейной регрессии).

В регрессионной модели достаточно  оценить вектор параметров
$\ta$.
 Проекцию $X$ на подпространство $L$ теперь можно найти, решив экстремальную задачу
$$
|X-F\ta|^{2}\longrightarrow\min_{\ta\in \R^{r}}.
$$

Для этого достаточно сначала найти градиент функции
$$
Q(\ta):= |X-F\ta|^{2}=(X-F\ta)^T(X-F\ta),
$$
а затем, приравняв его к нулю, найти точку минимума функции
$Q(\ta)$. Условимся считать оператор частного дифференцирования
$\frac{\pd}{\pd\ta}$ строкой:
$$
\frac{\pd}{\pd\ta}=\hr{\frac{\pd}{\pd\ta_{1}}\sco \frac{\pd}{\pd\ta_{r}}}.
$$

При таком соглашении
$$
Q(\ta +d\ta)=Q(\ta)+ \frac{\pd
Q}{\pd\ta}d\ta+o(d\ta).
$$

Далее,
$$
Q(\ta +d\ta)=\left[X-F(\ta
+d\ta)\right]^T\left[X-F(\ta +d\ta)\right]
=Q(\ta)-(X-F\ta)^{T}Fd\ta-(Fd\ta)^{T}(X-F\ta)+o(d\ta).
$$

Отсюда следует, что
$$
\displaystyle\frac{\pd Q}{\pd\ta}=-2(X-F\ta)^{T}F.
$$

По отношению к неизвестному вектору $\ta$ это дает уравнение
$$
F^{T}X=(F^{T}F)\ta.
$$

Это уравнение всегда имеет решение (по смыслу исходной задачи). Это
решение единственно тогда и только тогда, когда система $F_{1}\sco F_r$ линейно независима. В этом и только в этом
случае матрица $F^{T}F$ невырождена~и
$$
\hat\ta=(F^{T}F)^{-1}F^{T}X;
$$

при этом
$$
\proj_{L}X=F\hat\ta=F(F^{T}F)^{-1}F^{T}X.
$$

Можно указать и свойства $\hat\ta$ как оценки $\ta$:
$$
\hat\ta\sim N(\ta, \si^{2}(F^{T}F)^{-1}).
$$

Оценкой (несмещенной, наилучшей) $\si^{2}$ служит
$$
s^{2}=\frac{1}{n-r}|X-F\hat\ta |^{2}.
$$

Статистики $\hat\ta$ и $s^{2}$ независимы.

Отметим, что вычисление $\hat\ta$ значительно упрощается, если
базис подпространства $L$ выбран ортогональным: в этом случае
матрица $F^{T}F$ - диагональная. Важным достоинством ортогонального
базиса служит также статистическая независимость оценок
$\hat\ta_{1}\sco \hat\ta_{r}$. Это
облегчает интерпретацию результатов.

\section{Доверительное (интервальное) оценивание}
\subsection{Введение}

Знакомство с оцениванием завершим рассказом о доверительных
границах, доверительных интервалах и доверительных областях для
оцениваемых параметров. С прикладной точки зрения, статистическая
оценка - это статистическое приближение к неизвестному параметру или
его функции, это его приближенное значение, полученное из опыта. До
сих пор мы стремились к тому, чтобы путем статистической обработки
получить как можно более точное приближение. О\!днако способа
измерить точность приближения у нас не было.

Между тем, точность приближения - это общенаучное понятие, так же,
как и способ ее количественного выражения. Всякий раз, когда точное
значение какой-либо величины мы замещаем приближенным значением, нам
следует сопровождать такую замену также и сообщением о точности
этого приближения.

К примеру, 288 приблизительно равно 300; но также 288 приблизительно
равно 290. Однако точность этих приближений различна. Так, в первом
случае, точность приближения не ниже 15, а во втором - меньше 5:
$|288-300|<15$ и $|288-290|<5$.

В задачах статистического оценивания мы получаем аналогичное
приближенное равенство $\hat\ta(X)\approx \ta$. (Либо
$\hat\ta(X)\approx\ph(\ta)$, если мы оцениваем функцию от
параметра). Здесь $\ta$ - неизвестное истинное значение
параметра, $\hat\ta (X)$ - его оценка по наблюдению $X$. Для
статистического приближения, как правило, не существует
гарантированной точности: нет такого $\ep >0$, для которого
бы достоверно выполнялось соотношение $|\hat\ta
(X)-\ta|<\ep$. Мы можем говорить лишь о вероятности, с
которой выполняется это неравенство. Если эта вероятность близка к
1, можно говорить, что статистическая погрешность в определении
$\ta$ не превосходит $\ep$.

В этих примерах для неизвестной величины $a$ мы указываем ее
приближенное значение $x$, причем $|x-a|<\ep$ для некоторого
определенного $\ep >0$. Здесь $\ep$ -
гарантированная точность приближения $x\approx a$.

Рассмотрим на примере нормальной выборки, как реализуются эти
соображения.

\subsection{Нормальная выборка с известной дисперсией}

Пусть $x_{1}, \ldots, x_{n}$ суть независимые измерения некоторой величины $a$, причем $x_{i}\sim N(a,\si^2)$
для $i=\overline{1, n}$. Оценкой для $a$ может служить $\ol x=\frac{1}{n}\sum\limits_{i=1}^{n}x_{i}$, так что
$\ol x\approx a$.
 Как можно судить о точности этого приближения, то есть о $|\ol x-a|$? С какой вероятностью для данного $\ep >0$ выполняется неравенство $|\ol x -a|<\ep$? Каким надо взять $\ep$, чтобы вероятность этого неравенства была бы 0.95?
Или 0.99? И т.д.

Пусть, для начала, $\si^2$ известно. Рассмотрим случайную величину $\sqrt{n}\;\frac{\ol x -a}{\si}\sim N(0,
1)$. Зададимся какой-либо (обычно близкой к 1) вероятностью, для удобства обозначив ее через $1-2\al$. Здесь
$\al$ задано, $0<\al <\frac{1}{2}$. Пусть $z_{1-\al}$ обозначает $(1-\al)$-квантиль стандартного нормального
распределения. Иными словами, $z_{1-\al}$ удовлетворяет уравнению $\Phi(z_{1-\al})=1-\al$, где $\Phi(\cdot)$
- функция стандартного нормального распределения, или функция Лапласа.

Ввиду симметрии (относительно нуля) $z_{1-\al}=-z_{\al}$.

Поэтому для $\sqrt{n}\;\frac{\ol x -a}{\si}$ справедливо утверждение
$$
P\{|\sqrt{n}\;\frac{\ol x -a}{\si}|<z_{1-\al}\}=1-2\al\eqno (*)
$$
или
$$
P\{|\ol x -a|<\frac{\si}{\sqrt{n}}z_{1-\al}\}=1-2\al.
$$

Итак, с вероятностью $1-2\al$ точность приближения $\ol x\approx a$ не хуже, чем $\frac{\si}{\sqrt{n}}
z_{1-\al}$.

Соотношение $(*)$ можно преобразовать далее и написать, что
$$
P\{\ol x-\frac{\si}{\sqrt{n}}z_{1-\al}<a<\ol x+\frac{\si}{\sqrt{n}}z_{1-\al}\}=1-2\al.
$$

Интервал (случайный)
$$
(\ol x-\frac{\si}{\sqrt{n}}z_{1-\al}, \ol x+\frac{\si}{\sqrt{n}}z_{1-\al})\eqno(1)
$$
содержит неизвестное $a$ (часто говорят\т <<накрывает>> неизвестное
$a$) с вероятностью $1-2\al$.

Эту вероятность $1-2\al$ называют {\it доверительной
вероятностью} (иногда - коэффициентом доверия), а упомянутый
случайный интервал - {\it доверительным интервалом}.

На практике не следует ограничиваться одной какой-либо доверительной
вероятностью и одним доверительным интервалом. Чтобы лучше передать,
как связаны $\ol x$ и $a$, следует вычислить доверительные
интервалы для нескольких доверительных вероятностей, скажем, для
0.50, 0.90, 0.95 и 0.99. Чертеж, на котором выделены эти
доверительные интервалы, дает нам наглядное представление о точности
статистического приближения $\ol x\approx a$.

Отметим некоторые очевидные, но важные свойства полученных
доверительных интервалов.
\begin{itemize}
\item
Эти интервалы тем лучше, чем меньше~$\si$.

В нашем примере $\si^2$ - дисперсия ошибки при измерении $a$. Ясно, что чем больше эта дисперсия, тем ниже и
точность статистического вывода.
\item
Интервалы тем шире, чем больше $z_{1-\al}$, которая, в свою
очередь, возрастает при приближении $1-\al$ к 1. (И скорость
роста тем выше, чем ближе $\al$ к нулю).

Это свойство тоже легко объяснимо: чем выше требования к
достоверности суждения, тем менее содержательно и информативно самое
это суждение.
\item
Наконец, на точность приближения $\ol x\approx a$ влияет число
наблюдений $n$: чем больше $n$, тем \'уже доверительный интервал,
т.е. тем выше точность.

Заметим, однако, что длина доверительного интервала пропорциональна
$1/\sqrt{n}$. Так что если мы хотим повысить статистическую точность
 вдвое, нам придется увеличить количество независимых измерений вчетверо. (А если в 10 раз, то - в 100). Притом, все эти измерения надо проводить в неизменных условиях. На практике большие выборки встречаются не часто.
\end{itemize}

\subsection{Нормальная выборка с неизвестной дисперсией. Распределение Стьюдента}

Предыдущие результаты верны, но бесполезны, когда $\si$ неизвестно, что чаще всего на практике и бывает.

Естественная мысль: заместить неизвестное $\si$ его оценкой $s$, где
$s^{2}=\frac{1}{n-1}\sum\limits_{i=1}^{n}(x_{i}-\ol x)^2$, и рассмотреть случайную величину
$$
t=\sqrt{n}\;\frac{\ol x -a}{s}\eqno (1)
$$

Ее называют {\it отношением Стьюдента} ({\it Student's ratio} - стьюдентова дробь, стьюдентово отношение).
Легко видеть, что распределение (1) не зависит от неизвестных параметров нормальной выборки $(a, \si^2)$ и
совпадает с распределением отношения стандартной нормальной величины $N(0,1)$ к случайной величине
$\sqrt{\frac{1}{n-1}\;\chi^2(n-1)}$, причем эти случайные величины независимы (см. пункт 4.5).

Распределение случайной величины (1) называют {\it распределением
Стьюдента с $(n-1)$ степенями свободы}.

Приведем общее определение.
\begin{description}
\item[\underline{Определение:}]

Пусть $\xi_{0}, \xi_{1}, \ldots, \xi_{m}$ ($m$ - натуральное) суть
независимые стандартные гауссовские случайные величины (т.е.
$\xi_{0}, \xi_{1}, \ldots, \xi_{m}\sim N(0,1)$). {\it Стьюдентовским
отношением} ({\it стьюдентовской дробью}) называют случайную
величину
$$
t=t(m,
\mu)=\frac{\xi_{0}+\mu}{\sqrt{\frac{1}{m}(\xi_{1}^2+
\cdots+\xi_{m}^2)}},\eqno(2)
$$
где $\mu\in \R$ - произвольное число.

Распределение случайной величины $t(m, \mu)$ называют {\it
распределением Стьюдента}; число $m$ называют {\it числом степеней
свободы}, а число $\mu$ - {\it параметром нецентральности}
распределения Стьюдента.

Если $\mu =0$, то распределение случайной величины $t(m)=t(m,0)$
называют {\it центральным распределением Стьюдента}. Обычно этот
эпитет опускают и распределение $t(m)$ называют просто
распределением Стьюдента (с $m$ степенями свободы).
\end{description}

Распределение Стьюдента (центральное) снабжено разнообразными и
подробными таблицами. Есть, в частности, таблицы квантилей. Пакеты
статистических программ содержат команды, позволяющие получить всю
необходимую информацию о распределении $t(m)$.

Функции плотности вероятности для $t(m)$ и $t(m, \mu)$ известны (их
можно найти в справочниках). Их аналитическими выражениями мы
пользоваться не будем. Для информации, приведу формулу плотности для
$t(m)$:
$$
\frac{1}{\sqrt{m}B(\frac{1}{2},\frac{m}{2})}(1+\frac{x^2}{m})^{-\frac{m+1}{2}}
$$

(Из этой формулы и (2) при $m=1$ следует, что распределение
Стьюдента с одной степенью свободы совпадает с распределением Коши).

Отметим важное для дальнейшего свойство распределений Стьюдента:
\begin{quote}
при каждом $m$ семейство $t(m, \mu)$ стохастически упорядочено
(стохастически монотонно возрастает) относительно $\mu$. Это
означает, что для любого $x\in \R$
$$
P(t(m,\mu_{1})>x)<P(t(m, \mu_{2})>x),
$$
если $\mu_1<\mu_{2}$.
\end{quote}

{\it Доказательство.}

Доказательство почти очевидно:

Из (2) следует, что
$$
P(t(m,\mu_{1})>x)=P(\xi_{0}+\mu_{1}
>x\sqrt{\frac{1}{m}\chi^{2}(m)})=
$$
$$
=\Ef(\xi_{0}+\mu_{1} >z|z=x\sqrt{\frac{1}{m}\chi^{2}(m)}).
$$

Для завершения доказательства остается заметить, что для любого
$z\in \R$
$$
P(\xi_{0}+\mu_{1}>z)<P(\xi_{0}+\mu_{2}>z),
$$
если $\mu_{1}<\mu_{2}$, $\xi_{0}\sim N(0,1)$. $\Box$

Вернемся к поставленной задаче: построению доверительных интервалов для $a$ (для среднего) по нормальной
выборке (по выборке из $N(a,\si^2)$). Ее решение теперь почти не отличается от рассмотренного в первом
пункте.
 Единственное, что надо изменить: вместо нормальных квантилей ввести
 квантили распределения Стьюдента.

Все же, повторим необходимые шаги.

Выбираем доверительную вероятность $1-2\al$. По таблицам находим
$(1-\al)$-квантиль распределения Стьюдента, с $(n-1)$ степенями
свободы, которую обозначим через $t_{1-\al}(n-1)$, т.е. решение
уравнения
$$
P(t(n-1)<t_{1-\al})=1-\al.
$$

Ввиду симметрии распределения Стьюдента, можно утверждать, что
$$
P\left(|\sqrt{n}\frac{\ol x -a}{s}|<t_{1-\al}\right)=1-2\al.
$$

Преобразуя, получаем оценку точности для приближения $\ol x\approx
a$
$$
P\left(|\ol x -a|<\frac{s}{\sqrt{n}}t_{1-\al}\right)=1-2\al
$$
и доверительный интервал (с доверительной вероятностью $1-2\al$)
для $a$
$$
P\left\{\ol x-\frac{s}{\sqrt{n}}t_{1-\al}<a<\ol
x+\frac{s}{\sqrt{n}}t_{1-\al}\right\}=1-2\al.
\eqno (3)
$$

Все сделанные в предыдущем пункте замечания о свойствах
доверительного интервала (5.2.1), остаются верными и для (3). Равно
как и рекомендации не ограничиваться каким-либо одним доверительным
интервалом (и какой-либо одной доверительной вероятностью), но
вычислять
 их несколько - для нескольких коэффициентов доверия.

Тем же приемом можно выводить для $a$ и другие доверительные
утверждения.


\underline{\bf Пример:} {\it Доверительные пределы} (границы сверху
или снизу).

Выбираем доверительную вероятность $1-\al$. Если мы хотим
получить для $a$ границу сверху, берем $\al$-квантиль
$t_{\al}= t_{\al}(n-1)$; для границы сверху берем
$(1-\al)$-квантиль $ t_{1-\al}(n-1)$. (Заметим, что из-за
симметрии $ t_{\al}= - t_{1-\al}$).

Далее, заметим, что для (1) выполняется соотношение
$$
P\left(t_{\al}<\sqrt{n}\;\frac{\ol x -a}{s}\right)=1-\al.
$$

Отсюда, поскольку $ t_{\al}=- t_{1-\al}$, следует, что
$$
P\left\{a<\ol
x+\frac{s}{\sqrt{n}}t_{1-\al}\right\}=1-\al,
\eqno (2.9)
$$
так что $\ol x+\frac{s}{\sqrt{n}}t_{1-\al}$ - это
верхняя доверительная граница для $a$ с коэффициентом доверия
$1-\al$.

Нижняя $(1-\al)$-доверительная граница для $a$, равная $\ol
x-\frac{s}{\sqrt{n}}t_{1-\al}$, получается
аналогично.

Пересечение двух полученных доверительных областей дает для $a$ уже
известный доверительный интервал (3) с доверительной вероятностью
$1-2\al$.

\subsection{Центральные величины}

Обсудим в общем виде тот прием, который мы применяли в пунктах 5.2 и
5.3.

Пусть распределение наблюдения $X$ определяется неизвестным
параметром $\ta, \ta\in\Ta$. Предположим, что существует
случайная переменная $G(X, \ta)$, $G(\cdot, \cdot)$ - известная
функция от $X$ и $\ta$, распределение которой нам известно
 и не зависит от $\ta$, когда $\ta\in\Ta$. (В предыдущем примере это было
 $\sqrt{n}\;\frac{\ol x -a}{s}$). $G(X, \ta)$ называют
 {\it центральной случайной величиной}, а чаще (хоть и не совсем правильно) -
 {\it центральной статистикой}.

Предположим для простоты, что распределение $G(X, \ta)$
непрерывно и пусть $g_{\al}$, $\al\in (0,1)$,  обозначает
$\al$-квантиль $G(X, \ta)$. Теперь для всякого $\ta\in\Ta$ и $\al\in (0,1)$ справедливо соотношение
$$
P(g_{\al}<G(X, \ta))=1-\al. \eqno(1)
$$

(Точнее было бы в этом равенстве употребить символ $P_{\ta}$ для
распределения вероятностей, зависящих от $\ta, \ta\in\Ta$.
Но, поскольку (1) выполняется для всех таких $\ta$, индекс
$\ta$, которым мы обычно сопровождаем символ вероятности $P$,
здесь и далее можно опустить, не опасаясь недоразумений.)

Решаем неравенство $g_{\al}<G(X, \ta)$ относительно $\ta$.
Получим зависящее от $X$ множество
$$
S_{1-\al}(X):=\{\ta\in\Ta: g_{\al}<G(X, \ta) \}.
\eqno(2)
$$

Ясно, что для всякого $\ta\in\Ta$
$$
P(\ta\in S_{1-\al}(X))=1-\al,
$$
так что $S_{1-\al}(X)$ - это доверительная область для $\ta$ с
доверительной вероятностью $1-\al$.

Если мы не собираемся ограничивать себя какой-либо одной
доверительной областью (2), но использовать все семейство
$S_{1-\al}(\cdot)$, $\al\in (0,1)$, тогда разумно потребовать
от центральной величины $G(X, \ta)$, чтобы семейство
$\{S_{1-\al}(X), \al\in (0,1)\}$ было бы монотонным по
вложению:
$$
\mbox{если}\; 0<\al_{1}<\al_{2}<1,\; \mbox{то}
$$
$$
S_{1-\al_{1}}(X)\supset S_{1-\al_{2}}(X) \eqno (3)
$$

Когда $\ta$ - одномерный параметр, достаточным условием для (3)
служит монотонность $G(X, \ta)$ по переменной $\ta$ (при
каждом фиксированном $X$). Точнее: для (3) нужно, чтобы $G(X,
\ta)$ монотонно убывала по $\ta$. В этом случае
$S_{1-\al}(X)$ - полуинтервал (точнее, это пересечение $\Ta$ с полуинтервалом); его правый конец - это верхняя
$(1-\al)$-доверительная граница для $\ta, \ta\in\Ta$.

Другая система доверительных областей возникает из аналогичного (1)
соотношения
$$
P(G(X, \ta)<g_{1-\al})=1-\al. \eqno(4)
$$

Действуя как выше, т.е. решая неравенство относительно $\ta$,
получим для $\ta$ доверительную область
$$
T_{1-\al}(X)=\{\ta\in\Ta: G(X, \ta)<g_{1-\al}\}.
$$

В оговоренном выше одномерном монотонном случае множество
$T_{1-\al}(X)$ - это полупрямая (пересеченная с $\Ta$). Ее
левый конец для $\ta$ дает $(1-\al)$-доверительную границу
сверху. Пересечение областей $S_{1-\al}(X)\bigcap
T_{1-\al}(X)$
 дает для $\ta$ доверительную область (как правило, ограниченную) с доверительной вероятностью $1-2\al$.

\subsection{Испытания Бернулли}

В этом случае нет точной центральной величины, но есть случайная
величина, распределенная асимптотически свободно (имеется в виду,
что распределение не зависит от неизвестных параметров,
\underline{свободно} от их влияния).


Пусть $\ta$ - неизвестная вероятность успеха, $\ta\in (0, 1)$;
$S_n$ - число успехов, случившееся в $n$ проведенных испытаниях
Бернулли.

По теореме Муавра - Лапласа, случайная величина
$$
\frac{S_{n}-\ta n}{\sqrt{n\ta
(1-\ta )}}\stackrel{d}{\longrightarrow} N(0, 1)\qquad\mbox{при}
\; n\rightarrow \infty.
$$

Как обычно, мы заключаем из этой теоремы, что для достаточно больших $n$ и $z\in \R$
$$
P\left(\left|\frac{S_{n}-n\ta}{\sqrt{n\ta
(1-\ta )}}\right|<z\right)\approx \Phi(z)-\Phi(-z).
$$

Пусть $1-2\al$ - выбранная нами доверительная вероятность,
$z_{1-\al}$ означает $(1-\al)$-квантиль стандартного
нормального распределения, так что $\Phi(z_{1-\al})=1-\al$.

Тогда
$$
P\left(\left|\frac{S_{n}-n\ta}{\sqrt{n\ta
(1-\ta )}}\right|<z_{1-\al}\right)\approx 1-2\al.
$$

Это неравенство надо разрешить относительно $\ta$, $\ta\in (0,
1)$. После тождественных преобразований получим для этого
неравенства эквивалентную форму
$$
(S_{n}-n\ta)^{2}-n\ta (1-\ta)z_{1-\al}^{2}<0.\eqno(1)
$$

Левая часть (1) - квадратный трёхчлен относительно $\ta$, причем
коэффициент при $\ta^{2}$ положителен.

Поэтому решение имеет вид
$$
\underline{\ta}(S_{n})<\ta<\overline{\ta}(S_{n}),
$$
где $\underline{\ta}(S_{n}), \overline{\ta}(S_{n})$ - суть
корни квадратного трехчлена в (1). Здесь
$$
\underline{\ta}(S_{n}),
\overline{\ta}(S_{n})=\frac{S_{n}+\frac{z_{1-\al}^{2}}{2}\mp
z_{1-\al}\sqrt{\frac{S_{n}(n-S_{n})}{n}
+\frac{z_{1-\al}^{2}}{4}}}{n+z_{1-\al}^{2}}.\eqno(2)
$$

Выражение (2) дает для $\ta$ доверительный интервал,
доверительная вероятность которого приближенно равна $1-2\al$.

\subsection{Регрессионная модель}

Метод центральных величин пригоден для того, чтобы строить
доверительные области
 для параметров гауссовских линейных моделей. Рассмотрим регрессионную модель
$$
X=F\ta +\ep, \eqno (1)
$$
где $X$ - наблюдаемый $n$-мерный вектор (столбец);
$\ta=(\ta_{1}, \ldots, \ta_{m})^T$ - неизвестный параметр,
$\ta\in \R^{m}$; $F$ - заданная $n\times m$ матрица,
 $F=\|F_{1}, \ldots, F_{m}\|$; все ее столбцы $F_{1}, \ldots, F_{m}$ будем
 предполагать линейно независимыми; $\ep\sim N(0, \si^2 I)$ - вектор случайных ошибок.

Как нам уже известно, в этой модели наилучшая несмещенная оценка
$\hat\ta$ получается по методу наименьших квадратов и равна
$$
\hat\ta =(F^TF)^{-1}F^TX. \eqno (2)
$$

Из теории гауссовских линейных моделей (точнее, из леммы 4.3.2 об
ортогональных разложениях) вытекает, что $|X-F\hat\ta |^{2}$ и
$\hat\ta$ статистически независимы, причем
$$
|X-F\hat\ta |^{2}=\si^{2}\chi^{2}(n-m), \eqno (3)
$$
$$
\hat\ta\sim N(\ta, \si^{2}(F^TF)^{-1}).
$$

Для построения центральной величины нам понадобится изложенная ниже
лемма, а также еще одно семейство распределений.

\underline{\bf Лемма.}
\begin{quote}
Пусть $\xi\sim N_{p}(a, A)$ , причем $A^{-1}$ существует. Тогда
$$
\xi^{T}A^{-1}\xi=\chi^{2}(p, \De),
$$
где параметр нецентральности $\De=a^{T}A^{-1}a$.
\end{quote}

{\it Доказательство.}

Из линейной алгебры известно, что квадратичную форму с матрицей $A$
линейным невырожденным преобразованием можно привести к
каноническому виду. В данном случае, преобразованная матрица
квадратичной формы - единичная (ибо $A\ge 0$ и $A$ невырожденная).

Иначе говоря, существует невырожденная квадратная матрица, скажем,
$B$, такая, что
$$
BAB^T=I.
$$

Заметим, что
$$
A^{-1}=B^{T}B.
$$

Рассмотрим случайный вектор $\eta=B\xi$. Ясно, что
$$
\eta\sim N_{p}(Ba, BAB^T)=N_{p}(Ba, I).
$$

Поэтому
$$
|\eta|^{2}=\chi^{2}(p, \De),\mbox{ где }
\De=|Ba|^{2}=(Ba)^TBa=a^TA^{-1}a.
$$

С другой стороны:
$$
|\eta|^{2}=\eta^T\eta =(B\xi)^TB\xi =\xi^TA^{-1}\xi.
$$

Лемма доказана. $\Box$

Применим эту лемму к гауссовскому вектору (2). Получим, что
$$
(\hat\ta -\ta )^T(F^TF)(\hat\ta - \ta )=\si^{2}\chi^{2}(m). \eqno (4)
$$

{\bf Эф - распределение.}

Называемое также распределением Снедекора, распределением Фишера,
распределением дисперсионного отношения Фишера, и т.д.

\begin{description}
\item[\underline{Определение}]
Пусть случайные величины $X_1$ и $X_2$ независимы и распределены по
закону хи-квадрат:
$$
X_1=\chi^{2}(m_1, \De), X_2=\chi^2(m_2, 0).
$$

Случайная величина
$$
F=F(m_1, m_2,
\De)=\frac{\frac{1}{m_{1}}X_1}{\frac{1}{m_{2}}X_2}
\eqno (5)
$$
называется {\it $F$ - отношением} (эф-отношением, дисперсионным
отношением Фишера). Распределение (5) называют {\it нецентральным
эф-распределением} с $m_1$ и $m_2$ степенями свободы и параметром
нецентральности $\De$. Если $\De =0$, распределение называют
{\it центральным}. Слово <<центральное>> часто опускают и
 говорят просто о эф-распределении с $m_1$ и $m_2$ степенями свободы и о случайной величине $F(m_1, m_2)$.
\end{description}

Плотность эф-распределения можем вывести из определения (5) и вида
плотности хи-квадрат. Мы не будем к ней обращаться, полагаясь на то,
что необходимые сведения об эф-распределении (например, квантили)
можно найти в таблицах.

Все же приведем плотность $F(m_1, m_2, 0)$:
$$
\frac{\left(\frac{m_1}{m_2}\right)^{\frac{m_1}{2}}}{B(\frac{m_1}{2},
\frac{m_2}{2})}\frac{x^{\frac{m_1}{2}-1}}{(1+\frac{m_1}{m_2}x)
^{\frac{m_1+m_2}{2}}}\mbox{ для } x\ge 0
$$

Легко видеть, что семейство распределений $F(m_1, m_2, \De)$
стохастически упорядочено по $\De$ при любых $m_1$ и $m_2$.
Доказывают этот факт тем же способом, то и упорядоченности семейства
$\chi^2(m, \De)$ по $\De$.

Вернемся к доверительному оцениванию $\ta$ в модели (1).

Из двух независимых случайных величин (3) и (4) составим
эф-отношение
$$
F(m, n-m)=\frac{\frac{1}{m}(\hat\ta -
\ta)^T(F^TF)(\hat\ta -\ta)}{\frac{1}{n-m}|X-
F\hat\ta|^2}. \eqno (6)
$$

Выбрав доверительную вероятность $1-\al$, с помощью таблицы
квантилей для $F(m, n-m)$ найдем $(1-\al)$-квантиль, которую
обозначим как $F_{1-\al}(m, n-m)$.

Теперь
$$
P\left\{\frac{\frac{1}{m}(\hat\ta -
\ta)^T(F^TF)(\hat\ta -\ta)}{\frac{1}{n-m}|X-
F\hat\ta|^2}< F_{1-\al}(m, n-m)\right\}=1-\al .
$$

Заметим, что
$$
s^2:= \frac{1}{n-m}|X- F\hat\ta|^2\eqno(7)
$$
  - это несмещенная оценка для $\si^2$.

Теперь видно, что $(1-\al)$-доверительное множество для $\ta$,
заданное неравенством
$$
\{\ta : (\hat\ta - \ta)^T(F^TF)(\hat\ta
-\ta)<ms^2F_{1-\al}(m, n-m)\}, \eqno (8)
$$
представляет собой внутреннюю часть (случайного) эллипсоида с
центром в точке $\hat\ta$. Эта область (внутренность эллипсоида)
накрывает неизвестное $\ta$ (точку $\ta\in \R^m$) с
вероятностью $1-\al$.

Можно указать доверительные интервалы и для отдельных параметров $\ta_{i}$, $\ta =(\ta_{1}, \ldots,
\ta_{m})^T$. Из (2) следует, что каждая координата $\hat\ta_{i}$ вектора $\hat\ta =(\hat\ta_{1}, \ldots,
\hat\ta_{m})^T$ распределена по нормальному закону $N(\ta_{i}, \si^2a_{ii})$, если положить
$(F^TF)^{-1}=\|a_{ij}\|$.

С учетом (7) (и независимости $\hat\ta_{i}$ и $s^2$) можно
утверждать, что случайная величина
$$
t:= \frac{\hat\ta_{i}-\ta }{s\sqrt{a_{ii}}} \eqno (5.9)
$$
распределена по Стьюденту, с $(n-m)$ степенями свободы. Исходя из
этого, можно строить для $\ta_{i}$ доверительные интервалы так
же, как мы делали это в пункте 5.3.

Отметим, что если матрица $F^TF$ не ортогональна, то координаты
вектора оценок $\hat\ta$ не независимы. Поэтому не являются
независимыми и доверительные утверждения для отдельных $\ta_{1},
\ldots, \ta_{m}$, когда эти утверждения основываются на
центральных величинах (9). В этом случае вероятность того, что
несколько доверительных утверждений выполняются одновременно, нельзя
получить, перемножая их индивидуальные доверительные вероятности.
Одновременные доверительные выводы о $\ta_{1}, \ldots,
\ta_{m}$ надо получать иначе. Например, по методу Шеффа (или
Тьюки).

\section{Проверка статистических гипотез}

\subsection{Постановка задачи, основные понятия}

Наблюдение $X$ получено случайным выбором из генеральной совокупности $\Xc$ по некоторому вероятностному
закону $Р$, который нам не известен. Относительно распределения $Р$ известно лишь, что оно является элементом
некоторого заданного множества ${\cal P}$ вероятностных распределений на измеримом пространстве $\Xc$.
Относительно истинного распределения $Р$ высказано предположение, которое мы хотим проверить, опираясь на
наблюдение $X$: $Р$ обладает некоторыми определенными свойствами. Эти свойства выделяют в множестве ${\cal
P}$ некоторое подмножество ${\cal P}_{0}$. Поэтому упомянутое подлежащее проверке предположение $Н_{0}$ (в
дальнейшем - гипотеза $Н_{0}$) звучит так: $Р\in{\cal P}_{0}$, где ${\cal P}_{0}\subset{\cal P}$.

Когда множество распределений ${\cal P}$ параметризовано с помощью
какого-либо параметра $\ta$, причем ${\cal
P}=\{P_{\ta }:\ta\in\Ta \}$, тогда гипотеза $Н_{0}$ тоже
приобретает параметрическую форму
$$
H_{0}: \ta\in\Ta_{0},
$$
где ${\cal P}_{0}=\{P_{\ta }:\ta\in\Ta_{0}\}$, $\Ta_{0}$ задано и $\Ta_{0}\subset\Ta$.

Гипотеза $Н_{0}$ либо верна, либо нет. В последнем случае выполнено
альтернативное
 предположение о распределении (альтернатива): $Р\in{\cal P}_{1}$.

При этом ${\cal P}_{0}\bigcap{\cal P}_{1}=\emptyset$, ${\cal
P}_{1}\bigcup{\cal P}_{0}={\cal P}$. (Последнее, впрочем, не
обязательно: гипотетическое и альтернативное множество распределений
не всегда в своем объединении составляют все возможные вероятностные
распределения).

В параметрической форме альтернатива $Н_{1}$ имеет вид
$$
Н_{1}: \ta \in \Ta_{1},
$$
где $\Pc_1 =\{Р_\ta: \ta \in \Ta_1\}$,
$\Ta_{1}$ задано, $\ta_{1}\in\Ta$ и
$\Ta_{0}\bigcap\Ta_{1}=\es$.

По наблюдению $X$ мы должны либо принять $Н_{0}$, либо $Н_{0}$
отвергнуть (иногда в этом случае говорят: {\it принять $Н_{1}$}). Мы
расширяем эту задачу так: на множестве $\Xc$ мы должны
определить функцию от $х$, $х\in \Xc$, значениями которой могут
 быть <<отвергнуть $Н_{0}$>> или <<не отвергать $Н_{0}$>>. Затем мы применим эту
функцию к наблюдаемому значению $X$ и в результате получим
конкретное решение.

Пусть
$$
S=\{х: х \in \Xc,\;\mbox {по наблюдаемому $х$ отвергаем
$Н_{0}$}\}.
$$

Множество $S$, $S\subset \Xc$, называют {\it критическим
множеством} для гипотезы $Н_{0}$, или {\it критерием}.

Поскольку гипотезы, о которых мы говорили, касаются распределения
вероятностей, такие гипотезы называются {\it статистическими}, а
критерии для их проверки - {\it статистическими критериями}.

С любыми статистическими критериями неразрывно связаны возможные
ошибки:
\begin{itemize}
\item
ошибка рода I: отвергаем $Н_{0}$, когда $Н_{0}$ верна;
\item
ошибка рода II: не отвергаем $Н_{0}$, когда $Н_{0}$ неверна.
\end{itemize}

По своим последствиям эти ошибки обычно не равнозначны: ошибка I
рода опаснее, т.к. она заставляет нас \underline{отказаться} от
правильного предположения. В то же время ошибка II рода (не
отвергнуть гипотезу, когда она не верна) не закрывает возможности
все же отвергнуть ложную гипотезу $Н_{0}$ в результате дальнейших ее
проверок. Поэтому при проверке статистических гипотез возможность
ошибки первого рода стараются \underline{уменьшить}. Желательно,
впрочем, иметь такие статистические критерии, для которых малы
(близки к 0) вероятности обеих ошибок. Но поскольку это обычно
невозможно, к выбору критерия $S$ выдвигают такие
 требования:
\begin{itemize}
\item
Вероятность ошибки первого рода не должна превосходить выбранной
(малой) величины, называемой уровнем значимости критерия $S$.
\item
При этом условии вероятность ошибки II рода надо сделать
\underline{как можно меньше}.
\end{itemize}
С большей определенностью говорить о свойствах статистического
критерия помогает его функция мощности. Ее аргументом служит
распределение вероятностей $Q$ на $\Xc$, $Q \in {\cal P}$.

\underline{Определение.}
\begin{quote}
{\it Мощностью} $\beta (Q)$ критерия $S$ называют
$$
\beta (Q, S)=\beta (Q)=Q \{Х\in S\},
$$
т.е. вероятность события $\{Х\in S\}$, когда случайный выбор $Х, Х
\in\Xc$,
 происходит согласно распределению вероятностей $Q$. (Напомним, что гипотезу
$Н_{0}$ мы отвергаем с помощью критерия $S$, если происходит событие
$Х\in S$). Функцию $\beta (\cdot )$, заданную на множестве
распределений ${\cal P}$, называют {\it функцией мощности} (критерия
$S$).

Согласно сказанному ранее, статистический критерий имеет уровень
значимости
 $\al$, если $\beta (Q)\le\al$ для всех $Q \in {\cal P}_{0}$. Поскольку
 каждый критерий уровня $\al$ есть одновременно и критерий уровня $\al'$,
 если $\al <\al'$, то полезно определить для критерия его минимальный
 уровень значимости
$$
\supl{Q\in {\cal P}_{0}} \beta (Q).
$$
Эту величину называют {\it размером} критерия.
\end{quote}

Когда множество ${\cal P}$ параметризовано, т.е. когда ${\cal P}=
\{Р_{\ta }: \ta\in\Ta \}$, мощность можно считать
функцией параметра $\ta$:
$$
\beta(\ta , S)=\beta(\ta )=Р_{\ta }(Х\in S).
$$
В этом случае размер критерия $S$ есть
$$
\supl{\ta\in\;\ta_{0}}Р_{\ta}(Х\in S).
$$

Желательные свойства любого статистического критерия,
предназначенного для проверки статистической гипотезы $Р \in {\cal
P}_{0}$:

\begin{itemize}
\item[(a)] малый размер,
\item[(b)] быстрое возрастание его функции мощности (при удалении распределения $Q$ от гипотетического множества распределений ${\cal P}_{0}$).
\end{itemize}




\subsection{Пример реальной проверки статистической гипотезы}
Математическая (статистическая) модель закона Менделя проста.
Гибриды первого поколения имеют генотип $Aa$ (и фенотип $A$). Они
производят гаметы (зародышевые клетки) $\underline{A}$ и
$\underline{a}$ в равных количествах. При слиянии гамет возникают
соматические клетки четырех генотипов: $\underline{A}\underline{A},
\underline{A}\underline{a}, \underline{a}\underline{A}$ и
$\underline{a}\underline{a}$ (здесь первым указан генотип
материнской клетки, вторым - отцовской, для определенности). Если в
оплодотворении нет селективности, если жизнеспособность гамет
одинакова, если жизнеспособность потомства (например, всхожесть
семян) одинакова и т.д., то наудачу взятое растение второго
поколения имеет один из трех генотипов $\underline{A}\underline{A},
\underline{A}\underline{a}, \underline{a}\underline{a}$
 с вероятностями $\frac{1}{4}, \frac{1}{2}, \frac{1}{4}$ соответственно.
 Отсюда следует, что вероятности фенотипов $A$ и $a$ суть $\frac{3}{4}$ и $\frac{1}{4}$ .
Поэтому в опыте частоты должны относиться (приблизительно) как 3:1.



Школа Т.\,Д.\,Лысенко в СССР в тридцатые годы пыталась бороться с менделевскими
 законами наследственности научными методами. Дальнейший рассказ\т об одном из
 эпизодов этой борьбы\т представляет собой извлечение из статьи
А.Н. Колмогорова (1940) <<Об одном новом подтверждении законов Менделя>>, ДАН СССР, том 27,
стр.38\т 42.

См. также:

А.\,Н. Колмогоров. Теория вероятностей и математическая статистика.\т М.: Наука, 1986.

В.\,Н.\,Тутубалин. Теория вероятностей и случайных процессов.\т М.: изд-во МГУ, 1992 (ч. 2, гл. 3, \S 1).

Работа Колмогорова основывается на экспериментальных данных Н.\,И.\,Ермолаевой:
<<Еще раз о гороховых законах>>, Яровизация (1939), N 2 (23).
Н.\,И.\,Ермолаева экспериментировала с томатами. В ее опытах результаты разделялись по семействам.

Например, семейство составляли все растения, выросшие в одном ящике.
Семейства мы занумеруем индексом $i$, $i = 1, \dots, N$; $N$ - их
общее число. Чистые линии, которые подвергались скрещиванию
(гибридизации),
 отличались внешне: одни имели гладкие, а другие - морщинистые листья.

Пусть $\mu_i$, $i = 1,\ldots, N$, обозначают частоты фенотипа
$\underline{a}$ в каждой из $N$ серий, а $n_i$ обозначает число
растений в серии.

Если численности $n_i$ не слишком малы (порядка нескольких
десятков), то по теореме Муавра-Лапласа и \underline{при справедливости законов Менделя}
нормированные частоты (где $p = \frac{1}{4}$)
$$
\xi_i = \frac{\mu_i - n_i p}{\sqrt{n_i p ( 1 - p)}},
$$
 или
$$
\xi_i = \frac{\mu_i - \frac{n_i}{4}}{\sqrt{n_i \frac{1}{4}
\frac{3}{4}}}
$$
имеют (приближенно) распределение $N(0, 1)$. Поэтому на совокупность
$\xi_1, \xi_2, \ldots,\xi_n$ можно смотреть как на
 выборку (объема $N$) из $N(0, 1)$. Все это - если верен закон Менделя.

Возникает естественная мысль сравнить выборочную функцию $F_N(x)$,
построенную
 по этой выборке, и функцию стандартного нормального распределения
 (функцию Лапласа)
$$
\Phi(x) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^x e ^{-u^2/2} du.
$$
Согласно известной нам теореме Гливенко, случайная величина
$$
\Dc_N = \sup_x |F_N(x) - \Phi(x)| \eqno (*)
$$
при больших $N$ должна быть малой, если верны законы Менделя, ибо в
этом случае $\Dc_N \stackrel{P}{\longrightarrow} 0$ при {$ N
\to \infty$}.

Если же закон Менделя в обсуждаемых опытах не действует, то
вероятность появления фенотипа $a$ отличается от $\frac{1}{4}$. В
этом случае выборочная функция $F_N(\cdot)$ сходится не к
$\Phi(\cdot)$, а к другому пределу.

В результате
$$
\Dc_N \stackrel{P}{\longrightarrow} c > 0,
$$
если закон Менделя неверен.

Этих соображений, однако, недостаточно для точных статистических
выводов. Надо привлечь следующую теорему.

\underline{\bf Теорема Колмогорова (1933).}
\begin{quote}
$$
\Dc_N = \sup_{x \in R} |F_N(x) - \Phi(x)|
$$
и для любого $z > 0$
$$
\mathop{P}(\sqrt{N} \Dc_N < z) \longrightarrow K(z),
$$
где
$$
K(z) = 1 + 2 \sum_{k = 1}^\infty (-1)^k e ^{-2k^2 z^2},
$$
или $K(z) = \sum_{k = -\infty}^\infty (-1)^k e ^{-2k^2 z^2}$ для $z
> 0$. (Функцию $K(\cdot)$ называют {\it функцией
Колмогорова}).

В случае же его нарушения
$$
\sqrt{N}\Dc_N \longrightarrow \infty \mbox{ при } N \to \infty.
$$
\end{quote}

Это значит, что для конечных значений $N$ статистика $\sqrt{N}\Dc_N$
 должна принимать {\it большие значения}, если гипотеза неверна.

Таким образом, статистика $\sqrt{N}\Dc_N$ различно ведет себя
при гипотезе и при ее нарушении (при альтернативе).
 Именно это позволяет по величине $\sqrt{N}\Dc_N$ сделать вывод
о том, что же действует на самом деле: гипотеза или альтернатива.

 В данном случае естественно следующее решающее правило: отвергать
 гипотезу о том, что выборка извлечена из распределения с функцией
 $F(\cdot)$, если статистика $\sqrt{N}\Dc_{N}$ приняла (в
 опыте) слишком большое значение. Т.е. столь большое значение,
 которое маловероятно, если гипотеза верна.

Дать точный смысл этому предложению можно так.
\begin{itemize}
\item
 Выбираем уровень значимости $\ep$, $\ep>0$  - это вероятность отвергнуть
 гипотезу, когда она верна.
\item
 По этому значению $\ep$ вычисляем критическое значение,
 скажем ${\cal C}_{\ep}$,такое, что
$$
K({\cal C}_{\ep}) = 1 - \ep.
$$

\item
Если наблюдаемое значение $\sqrt{N}\Dc_N$ превосходит ${\cal
C}_{\ep}$ , мы проверяемую гипотезу отвергаем (как говорят -
на уровне $\ep$). В данном случае - это гипотеза (закон)
Менделя.
\end{itemize}

Судить о том, совместимо ли наблюденное в опыте значение статистики
$\sqrt{N}\Dc_{N}$ с проверяемой гипотезой, можно и иначе. Как
было сказано, против гипотезы (закона Менделя) говорят большие
значения
 $\sqrt{N}\Dc_{N}$, и тем сильнее, чем наблюденное значение выше.

Рассмотрим вероятность того, что в независимом повторении
проведенного опыта
 мы получим такое же или даже большее значение статистики
$\sqrt{N}\Dc_N$, чем наблюденное. (Вероятность эту вычисляем в
предположении, что гипотеза верна). Наблюденное значение надо
признать большим, если его трудно превзойти за счет случайности. То
есть, если упомянутая вероятность - малая. И обратно: если эта
 вероятность не мала, то и наблюденное значение считать большим не следует;
 оно совместимо с проверяемой гипотезой.

Обсуждаемую вероятность называют $p$-значением (по-английски - {\it
$p$-value}). Применять $p$-значения для проверки гипотез предложил
Фишер ({\it R. Fisher}).

В данной задаче $p$-значение равно $1-K(\sqrt{N}\Dc_N)$.

Вернемся к опытам Ермолаевой. Всего было две выборки: $N=98$ и
$N=123$. В обеих выборках наблюденные значения $\Dc_{N}$ были
далеки от критических: их $p$-значения были равны 0.51 и 0.63
соответственно. Таким образом, научная атака Т.Д. Лысенко на законы
Менделя не удалась.

\subsection{Оптимальный критерий Неймана-Пирсона}
\begin{center}
({\it J. Neyman, S. Pearson, 1933})
\end{center}

Статистический критерий $S$ для проверки гипотезы $H_0\cln P\in{\cal P}_0$ против альтернативы $H_1\cln P\in{\cal P}_1$ естественно
называть оптимальным, если среди всех критериев заданного уровня
значимости критерий $S$ имеет наибольшую мощность.

Чуть подробнее. Из двух критериев $R$ и $S$ данного уровня
значимости критерий $S$ называют более мощным, если
$$
\beta (Q,S)\ge \beta (Q,R) \qquad\mbox{для всех}\; Q\in{\cal
P}_{1}.\eqno(1)
$$

Критерий $S$ называют {\it оптимальным критерием} уровня $\al$,
если для любого другого критерия $R$ уровня $\al$ выполняется
соотношение (1). Критерий $S$ в этом случае называют также {\it
равномерно наиболее мощным критерием} уровня $\al$.

Оптимальный выбор критерия для проверки гипотезы
$H_{0}:P\in {\cal P}_{0}$ против альтернативы $H_1\cln P\in{\cal P}_1$ возможен лишь в немногих случаях. (Впрочем, некоторые из них
важны для статистической практики.) И там, где он удается, всё
основано на так называемой \underline{лемме Неймана\ч Пирсона}. Она
относится к простейшей ситуации: и гипотеза $H_{0}$, и альтернатива
$H_{1}$\т простые, то есть оба множества ${\cal P}_{0}$ и ${\cal
P}_{1}$\т одноточечные, каждое из них состоит из одного
распределения вероятностей $P_{0}$ и $P_{1}$ соответственно. (Если
множества ${\cal P}_{0}$ и ${\cal P}_{1}$ состоят каждое более чем
из одного распределения, гипотезу $H_{0}:P\in {\cal P}_{0}$ и
альтернативу $H_{1}:P\in {\cal P}_{1}$ называют {\it сложными}).

Оптимальный критерий для проверки простой гипотезы против простой
альтернативы мы построим в элементарной ситуации, когда
распределения $P_{0}$ и $P_{1}$ либо оба дискретны, либо оба имеют
плотности (относительно некоторой меры на $\Xc$).

Пусть $f_{0}(х) $ и $f_{1}(х)$, $х\in\Xc$, суть две плотности
распределений на $\Xc$ (или два дискретных распределения на $\Xc$). Пусть наблюдение $Х$ получено выбором элемента из $\Xc$
согласно $f_{0} $ либо $f_{1}$.
 Рассмотрим гипотезу $H_{0}: Х$ имеет плотность (распределение)
 $f_{0}$ и альтернативу $H_{1}: Х $ имеет плотность (распределение) $f_{1}$.

Рассмотрим множество вида
$$
S_{\la}=\{x: f_{1}(x)-\la f_{0}(x)\ge 0\},\quad \la >0 \eqno (2)
$$
как критерий для $H_{0}$ против $H_{1}$. [Точнее, мы рассмотрим всё
семейство множеств указанного вида, параметризованное переменной
$\la>0$, как семейство критических множеств. Эти критические
множества различаются уровнями значимости.]

Пусть $R$\т какой-либо статистический критерий для проверки $H_0$
против $H_{1}$ по наблюдению $Х$, $R\subset\Xc$.

Предположим, что
$$
P_{0}(X\in R)\le P_{0}(X\in S_{\la}). \eqno (3)
$$

То есть вероятность ошибки I рода для $R$ не выше чем для
$S_{\la }$. [В типичном случае для данного $R$ можно подобрать
критерий $S_{\la }$ вида $(b)$ с тем же уровнем значимости.
Тогда в $(3)$ стоит равенство.]

Тогда
\begin{description}
\item[(a)]
$$
P_{1}(X\in R)\le P_{1}(X\in S_{\la }),
$$
\item[(b)]
$$
P_{0}(X\in S_{\la })\le P_{1}(X\in S_{\la }).
$$
\end{description}

Пункт $(a)$ означает, что критерий $S_{\la }$ имеет наибольшую
мощность среди всех критериев, уровень значимости которых не
превосходит уровня значимости $S_{\la }$.

Пункт $(b)$ касается свойств самого критерия $S_{\la }$ и
утверждает, что функция мощности критерия $S_{\la }$ возрастает
при переходе от гипотетического распределения $P_{0}$ к
альтернативному $P_{1}$. [Такое свойство критерия называют {\it
несмещенностью}. Оно означает, что более вероятно (с помощью этого
критерия) отвергнуть проверяемую гипотезу, когда она неверна, чем
когда она верна - весьма естественное качество для критерия.]

Критерии вида (2) называют {\it критериями Неймана\ч Пирсона},
 а сформулированное выше утверждение об оптимальности критериев
(2)\т {\it леммой (теоремой) Неймана\ч Пирсона}.

Доказательства для распределений, имеющих плотности и для дискретных
распределений происходят одинаково - с той разницей, что интегралы
заменяются суммами. Поэтому достаточно рассмотреть
 что-либо одно; для определённости - плотности.

Записи будут компактными, если вместе с
 критериями $R$ и  $S_{\la  }$ рассмотреть их индикаторные
функции $I_{R}(х)$ и $I_{S}(х)$:

$$
I_{R}(x)=\case{1, & \text{ для } x\in R, \\ 0, & \text{ для } x
\notin R;} ,\qquad I_{S}(x)=\case{1, & \text{ для } x\in
S_{\la},
\\ 0, & \text{ для } x\notin S_{\la}. \\}
$$

С помощью $I_{R}$, $I_{S}$ вероятности событий $(Х\in R)$, $(Х\in
S_{\la })$ можно записать в виде математических ожиданий.
Усреднение (математическое ожидание) по $P_{0}$ обозначим через
$\Ef_0$, усреднение по $P_{1}$ - через $\Ef_1$. Например, $P_{0}(Х \in R)=\Ef_{0}I_R(X)$, а предложение $(3)$ имеет вид

$$
\Ef_0 I_{R}(X)\le \Ef_0 I_{S}(X). \eqno (4)
$$

{\it Доказательство} утверждения $(a)$.

Легко проверить, что справедливо неравенство

$$
I_{R}(x)[f_{1}(x)- \la f_{0}(x)]\le I_{S}(x)[f_{1}(x)-\la
f_{0}(x)]. \eqno (5)
$$

Действительно, если $f_{1}(x)-\la f_{0}(x)>0$, то
 $I_{S}(x)=1$ и (5) превращается в очевидное утверждение
$I_{R}(x)\le1$. Если же $f_{1}(x)-\la f_{0}(x)<0$, то
$I_{S}(x)=0$, и потому правая часть (5) обращается в нуль, а левая
часть (5) при этом неположительна, так что (5) верно и в этом
случае.

Интегрируем (5) по всему пространству. Результат запишем в виде
математических ожиданий.
$$
\Ef_{1}I_{R}(X)-\la \Ef_{0}I_{R}(X)\le \Ef_{1}I_{S}(X)-\la
\Ef_{0}I_{S}(X)
$$
или

$$
\Ef_{1}I_{S}(X)-\Ef_{1}I_{R}(X)\ge\la [\Ef_{0}I_{S}(X)-\Ef_{0}I_{R}(X)].
\eqno (6)
$$

В силу (4) и $\la >0$ правая часть (6) неотрицательна, что и
доказывает $(a)$. $\Box$

{\it Доказательство} утверждения $(b)$.

Для доказательства утверждения $(b)$ надо порознь рассмотреть для
$\la$, определяющего $S_{\la}$ в (2), две возможности:
$\la\ge 1$ и $\la <1$.
\begin{itemize}
\item
Допустим, что $\la\ge 1$. Тогда из (2) следует, что $f_{1}(x)\ge
f_{0}(x)$ для $x\in S_{\la }$. Поэтому

$$
P_{0}(X\in S_{\la})=\int\nolimits I_{S}(x)
f_{0}(x)dx\le\int\nolimits I_{S}(x)f_{1}(x)dx=P_{1}(X\in S_{\la
}),
$$

что и требуется.

\item
Допустим, что $\la <1$. Рассмотрим множество
$$
\overline{S}_{\la }=\{x: f_{1}(x)\le \la f_{0}(x)\}
$$

Его индикатор есть $1-I_{S}(x)$. При $\la <1$ получаем,
 что $f_{1}(x)\le f_{0}(x)$ для $x\in \overline{S}_{\la }$. Поэтому
$$
P_{1}(X\in \overline{S}_{\la })=\int\nolimits [1-I_{S}(x)]
f_{1}(x)dx\le \int\nolimits [1-I_{S}(x)]f_{0}(x)dx=P_{0}(X\in
\overline{S}_{\la }).
$$

Отсюда следует, что при $\la <1$
$$
1-P_{1}(X\in S_{\la })\le 1-P_{0}(X\in S_{\la }).
$$

Это доказывает $(b)$ и в этом случае. $\Box$
\end{itemize}

Доказанная теорема определяет вид наилучшего критерия. Если мы хотим
остановиться на оптимальном критерии уровня $\ep$, где
$\ep$ задано, мы должны подобрать $\la >0$ так, чтобы

$$
P_{0}(X\in S_{\la })=\ep. \eqno (7)
$$

В случае плотности это означает, что мы должны решить относительно
 $\la$ уравнение

$$
\int\limits_{\{x: f_{1}(x)\ge \la f_{0}(x)\}}
f_{0}(x)dx=\ep.
$$

В типичном случае решение существует (и единственно).

Для дискретно распределенных наблюдений $X$ уравнение (7) разрешимо
не для всех  $\ep>0$. В таком случае в поисках оптимального критерия уровня $\ep$ либо останавливаются на
критерии вида (2) с меньшим, чем назначенный $\ep$, с
вероятностью ошибки I рода (увеличивая тем самым вероятность ошибки
II рода), либо изменяют выбор уровня значимости так, чтобы (7) стало
разрешимо. Последнее правильнее, ибо назначение уровня значимости\т
решение в немалой степени произвольное.


\subsection{Равномерно наиболее мощные критерии}

Определение равномерно наиболее мощных критериев дано в начале
пункта 3. Как правило, для сложных гипотез и/или сложных альтернатив
равномерно наиболее мощных критериев не существует. Типично такое
положение, когда для каждой пары распределений $P_{0}\in {\cal
P}_{0}$, $P_{1}\in {\cal P}_{1}$ есть <<свой>> (определяемый леммой
Неймана\ч Пирсона) оптимальный критерий, но нет единого оптимального
критерия. Но есть важные (для практики) исключения из сказанного,
когда равномерно наиболее мощные критерии существуют.


\underline{Пример:}
\begin{quote}
проверка односторонних гипотез против односторонних альтернатив в
схеме Бернулли.
\end{quote}

Пусть проведено $n$, $n$ задано, испытаний Бернулли.
 Пусть $\ta\in (0,1)$ - неизвестная вероятность успеха.
Обозначим результат испытаний через $X=(X_{1}, \ldots, X_{n})$, где
$X_{i}=1$,
 если в $i$-ом испытании был успех, и $X_{i}=0$ в противном случае.

По наблюденному $X$ надо проверить гипотезу
$$
H_{0} : \ta \le\ta^{0}
$$
против альтернативы
$$
H_{1} : \ta >\ta^{0},
$$
где $\ta^{0}\in (0,1)$ задано.

Далее мы найдем р. н. м. критерий для проверки $H_{0}$ против
$H_{1}$. Этот критерий будет найден с помощью правила
Неймана\ч Пирсона.

\underline{Произвольно} выберем два значения $a$ и $b$ параметра
 $\ta$: $a$ из гипотетического множества $(0,\ta^{0}]$, $b$
 из альтернативного множества $(\ta^{0}, 1)$:
$$
0 < a \le \ta^{0} < b < 1 \eqno(1)
$$

Для проверки \underline{простой} гипотезы $\ta =a$ против
\underline{простой} альтернативы $\ta =b$ применим правило
 Неймана\ч Пирсона. Здесь:
$$
f_{1}(x)=b^{T_{n}(x)}(1-b)^{n-T_{n}(x)},
$$
$$
f_{0}(x)=a^{T_{n}(x)}(1-a)^{n-T_{n}(x)},
$$
где $x=(x_{1}, \ldots, x_{n})$ - точка выборочного пространства
$\Xc$, $x$\т произвольная последовательность из нулей и единиц,
$T_{n}(x)=\sum\limits_{i=1}^{n}x_{i}$. (Заметим, что $T_{n}(X)$ -
знакомая нам достаточная статистика, общее число успехов.)

Критические множества Неймана\ч Пирсона для пары $a$, $b$ суть
$$
S_{\la}=\{x:\frac{f_1(x)}{f_0(x)}\ge\la\} , \quad\la
>0
$$
или
$$
S_{\la}=\left\{x:
\left(\frac{b}{a}\frac{1-a}{1-b}\right)^{T_{n}(x)}\left(\frac{1-b}{1-a}\right)^{n}
\ge\la\right\},\quad\la >0. \eqno(2)
$$

Мы уже отмечали, что критерии Неймана\ч Пирсона образуют семейство
оптимальных критериев. Из этого семейства потом выбирают критерий
 заданного уровня значимости. Сейчас семейство (2) параметризовано
параметром $\la$, $\la >0$. Любая другая параметризация
этого семейства ничуть не хуже.

В частности, семейство (2) можно записать в виде
$$
\left\{x:
\left(\frac{b}{1-b}\frac{1-a}{a}\right)^{T_{n}(x)}\ge\la'\right\},
\quad\la' >0,
$$

где $\la'=\la\left(\frac{1-a}{1-b}\right)^{n}$.
 Впрочем, связь между новым параметром $\la'$ и старым параметром
 $\la$ не важна. При дальнейших изменениях параметризации мы такие
связи отмечать не будем. В силу (1)
$$
\frac{b}{1-b}\frac{1-a}{a}> 1.
$$

Поэтому (2) можно еще упростить:
$$
\{x: T_{n}(x)\ge t\},\; t>0. \eqno (3)
$$

Отметим главную особенность (3) как статистического критерия: его
вид не
 зависит
 от конкретных $a\le\ta^0$, $b>\ta^0$. Этот критерий  - общий для всех
 $a\in (0, \ta^{0}]$, $b\in (\ta^{0}, 1)$. Это означает, что критерий
 (3) в рассматриваемой задаче является равномерно наиболее мощным.

Статистическое правило теперь таково:

Отвергать гипотезу $H_{0}: \ta\le\ta^0$ против альтернативы
 $H_{1}: \ta >\ta^0$, если произошло событие
$$
T_{n}(X)\ge t, \eqno (4)
$$
где $t$ - некоторое критическое значение. (Это значение $t$ еще
предстоит уточнить). Заметим, что решение основывается на
достаточной статистике $T_{n}(X)=\sum\limits_{i=1}^{n}X_{i}$
(суммарном числе успехов), а не на самом наблюдении $X$. Эта черта
характерна для всякого критерия в тех статистических моделях $X$,
где существуют достаточные статистики.

Остается определить критическое значение $t$ в (4).

Для этого зададимся некоторым уровнем значимости $\ep$.
 Для $t$ должно выполняться условие
$$
P_{\ta}(T_{n}\ge t)\le\ep
 \qquad\mbox{ для всех }\;\ta\le\ta^0.
$$

Из утверждения $(b)$ леммы Неймана\ч Пирсона следует, что
$$
\supl{\ta : \ta\le\ta^0}P_{\ta}(T_{n}\ge t)= P_{\ta^0}(T_{n}\ge t).
$$

Поэтому условие для выбора $t$ упрощается:
$$
P_{\ta^0}(T_{n}\ge t)\le\ep. \eqno (5)
$$

Ради достижения наибольшей мощности против альтернативы $\ta
>\ta^{0}$ в качестве критического значения следует взять
наименьшее $t$, удовлетворяющее (5). Выбор $t$ при заданных $\ta$
и $n$ помогают осуществить таблицы для вероятности
$$
P_{\ta}(T_{n}\ge t)=\sum\limits_{k\ge
t}C_{n}^{k}\ta^k(1-\ta )^{n-k}
$$
как функции от $\ta$ и $t$; $\ta\in (0,1), t=\overline{1, n}$.

Можно не связывать себя заранее выбранным уровнем значимости и
принимать решения на основе $p$-значения ({\it p-value}) критической
статистики. В нашем случае против проверяемой гипотезы говорят
большие значения критической статистики $T_{n}$. $p$-значение
определяется как вероятность получить (при независимом повторении
опыта) не меньшее, чем получено, значение критической статистики (не
менее сильное, чем получено, свидетельство против проверяемой
гипотезы).

Если наблюденное значение значение статистики $T_{n}$ обозначить
 как $T_{n}$(набл.), сохранив за $T_{n}$ смысл случайной переменной,
то {\it p}-значением $T_{n}$(набл.) служит
$$
P_{\ta^{0}}(T_{n}\ge T_{n}(\mbox{набл.})). \eqno (6)
$$

Сопоставляя это выражение с (5), видим, что $p$-значение - это
наименьший уровень значимости, на котором еще можно опровергнуть
гипотезу $H_{0}$ по правилу (5).

Испытания Бернулли служат статистической моделью для многих реальных
процессов. В частности, при (массовом) производстве изделие может
оказаться негодным (брак). Если предположить, что появление брака -
дело случая, что бракованными
 различные изделия могут оказаться независимо друг от друга и что, наконец,
вероятность появления бракованного изделия постоянна, для описания
процесса мы можем применить схему Бернулли. Присутствие среди
изделий некоторой доли
 $\ta$ бракованных неизбежно для любого производства.

Величина $\ta^0$ может служить границей для все еще допустимой
доли брака;
 если эта доля выше, в производство требуется вмешательство (наладка станков,
 например).

Для контроля за долей текущего брака нужно производить регулярные
проверки: нужно проверять гипотезу $H_{0}: \ta\le\ta^0$ против
$H_{1}: \ta >\ta^0$. Выше мы установили, как это следует
делать наилучшим образом при простейшем плане эксперимента -
выборке.

Как объем выборки $n$, так и частота описанных проверок в нашей
постановке не определяются. Их устанавливают, исходя из расходов на
организацию и проведение контроля, от потерь от увеличения доли
брака, скорости изменения $\ta$ в течение работы и т.д.

Планы выборочного контроля, реально применяемые на массовых
производствах, могут быть значительно сложнее, чем изученная нами
простая выборка и контроль по качественному признаку (когда изделие
либо годно, либо нет). Научная и техническая литература, посвященная
контролю качества продукции, необъятна.

Равномерно наиболее мощные критерии (для проверки односторонних
гипотез против односторонних альтернатив) типичны для
однопараметрических экспоненциальных семейств распределений. Об этих
семействах мы упоминали в связи с неравенством Крамера\ч Рао и
эффективными оценками. Плотность (вероятность) наблюдения $X$ при
этом равна
$$
p(x,\ta)=\exp\{c(\ta)T(x)+S(x)+d(\ta)\}I_{A}(x).
$$

Биномиальные распределения, которые мы исследовали выше,
принадлежат этому классу. Если функция $c(\ta)$ монотонно зависит
от $\ta$, все
 проведенные выше выкладки повторяются практически без изменений и приводят
 к решающим правилам вида
$$
T_{n}\ge t\qquad\mbox{либо}\qquad T_{n}\le t.
$$

\subsection{Проверка линейных гипотез}
\subsubsection{Выбор степени многочлена}

В задачах регрессии $y$ по $x$ функциональный вид зависимости
ожидаемого значения отклика $\Ef(y|x)$, как функции $x$, бывает
известен далеко не всегда. В таких случаях аппроксимирующее
выражение для $\Ef(y|x)$ подбирают эмпирически. Часто для приближения
выражения $\Ef(y|x)$ используют многочлены от $x$.

Пусть, для простоты, $x$ - скалярная переменная. Предположим, что:
$$
\Ef(y|x)=a_{0}+a_{1}x+\cdots+a_{p}x^{p} \eqno (1)
$$
для некоторой степени $p\ge 0$ и некоторых коэффициентов $a_{0},
a_{1},\ldots, a_{p}$.

Далее предположим, что при некоторых заданных значениях $x_{1}\sco  x_{n}$ фактора $x$ проведены независимые измерения
$y_{1}\sco y_{n}$ отклика $y$, так что
$$
y_{i}=a_{0}+a_{1}x_{i}+\cdots+a_{p}x_{i}^{p}+\ep_{i}, \quad
i=\overline{1,n}, \eqno (2)
$$
где $\ep_{1}\sco \ep_{n}$ суть независимые случайные величины (ошибки). Мы предположим, что
$\ep_{i}\sim N(0,\si^{2}), i=\overline{1,n}$, причем дисперсия ошибки $\si^2$ неизвестна.

Выбор степени $p$ аппроксимирующего многочлена в формуле (1) всегда
представляет определенную проблему. Эту степень надо выбрать так,
чтобы погрешность в (1) (она же - систематическая ошибка в (2)) не
влияла на статистические выводы о $\Ef(y|x)$, которые мы сумеем
сделать по наблюдениям $(x_{i},y_{i})$, $i=\overline{1,n}$. Чем ниже эта степень,
тем легче интерпретировать результаты опытов. На практике эта степень редко превышает 3.

Особенно часто приходится отвечать на вопрос: можно ли для
аппроксимации $\Ef(y|x)$ обойтись многочленом первой степени, т.е.
простой линейной регрессией, или же надо обратиться к параболической
регрессии, т.е. к многочлену второй степени?

Статистически проблема выглядит так.

Предположим, что наблюдения $y$ удовлетворяют статистической модели
$$
y_{i}=a_{0}+a_{1}x_{i}+a_{2}x_{i}^{2}+\ep_{i}, \quad
i=\overline{1,n}, \eqno (3)
$$
где $\ep_{1}\sco \ep_{n}$\т суть неизвестные $N(0,\si^2)$, $a_{0}, a_{1}, a_{2}$ - неизвестные коэффициенты.
По наблюдениям (3) надо проверить гипотезу
$$
H_{0}: a_{2}=0\eqno(4)
$$
против альтернативы
$$
H_{1}: a_{2}\ne 0
$$

Гипотеза $H_{0}$ (4) состоит в том, что зависимость отклика от
фактора можно передать моделью
$$
y_{i}=a_{0}+a_{1}x_{i}+\ep_{i},   i=\overline{1,n}
$$
при тех же, что и выше, предположениях об ошибках $\ep_{1}\sco \ep_{n}$.

\subsubsection{Однофакторный дисперсионный анализ}

Пусть наблюдаются $k\ge 2$ независимых выборок, объемы которых
обозначим через $n_{1}\sco n_{k}$. Элементы выборки
номер $j$, $j=\overline{1,k}$, обозначим через $x_{ij}$, $i$
меняется от  1 до $n_{j}$. Предположим, что
$$
x_{ij}=a_{j} +\ep_{ij}, \eqno (5)
$$
где $\ep_{ij}$ ($j=\overline{1,k},i=\overline{1,n_{j}}$) суть независимые одинаково распределенные случайные
величины. Всюду в дальнейшем $\ep_{ij}\sim N(0,\si^2)$.

Такая модель возникает, например, при сравнении нескольких способов
обработки, нескольких условий хранения, нескольких мест размещения и
т.д. Модель (5) возникает также при любой классификации объектов по
одному признаку (однофакторная классификация).

При сравнении способов обработки часто бывает нужно выделить лучший
(или группу лучших, или группу наихудших и т.п.) способов обработки.
Целесообразно, однако, прежде задаться вопросом: дают ли наши данные
основания для такого выбора? По-видимому, нет, если с наблюдениями
(5) совместима гипотеза
$$
H_{0}: a_{1}=a_{2}=\cdots=a_{k}. \eqno(6)
$$

Легко видеть, что гипотеза (4) в модели (3) и гипотеза (6) в модели
(5) являются частными формами общей линейной гипотезы в линейной
модели, как она формулируется в следующем разделе.

\subsubsection{Общая линейная гипотеза}

Мы говорим, что в отношении наблюдения $X$ ($X$ - элемент линейного
пространства, в наших рассмотрениях $X\in \R^n$) действует линейная
модель, если наблюдение $X$ имеет структуру $X=l+\xi$, где
\begin{itemize}
\item
$l$ - неслучайный неизвестный вектор, который заведомо принадлежит
некоторому заданному линейному подпространству $L$;
\item
$\xi$ - случайный вектор (вектор ошибок).
\end{itemize}

Модель называют {\it гауссовской}, если $\xi$ имеет гауссовское распределение. В большинстве приложений
$\Ef\xi =0$, $\Df \xi =\si^2 I$, причем $\si^2$ неизвестно. (Такая форма матрицы ковариаций $\xi$ означает,
что компоненты вектора $X$ независимы и имеют одинаковые дисперсии.)

\underline{Линейная} гипотеза: гипотеза $H_{0}: l\in L_{0}$, где
$L_{0}$ - заданное линейное  подпространство, причем $L_{0}\subset
L$. Альтернативой к $H_{0}$ выступает отрицание $H_{0}$ в рамках
линейной модели: $H_{1}: l\notin L_{0}$, но при этом $l\in L$.

Линейную гипотезу можно рассматривать как частный случай общей
параметрической гипотезы о распределении наблюдения $X$.

\subsubsection{Критерий отношения правдоподобий}

Предположим, что случайная величина $X$ имеет плотность $f(x,\ta)$, где $\ta\in\Ta$\т неизвестный параметр.
Плотность берётся относительно некоторой меры, в нашем случае\т относительно меры Лебега в $\R^n$.

Гипотеза $H_{0}$ состоит в том, что параметр $\ta$ принадлежит
заданному множеству $\Ta_{0}$, более узкому, чем $\Ta$:
$\Ta_{0}\subset\Ta$. Критерий, предлагаемый для проверки
$H_{0}: \ta\in\Ta_{0}$ против $H_{1}:
\ta\in\Ta\wo \Ta_{0}$, строится по образцу критерия
Неймана\ч Пирсона.
\begin{itemize}
\item
Пусть $\hat \ta$ обозначает оценку параметра $\ta$,
вычисленную по наблюдению $X$ в предположении, что
$\ta\in\Ta$.
\item
Пусть $\hat{\hat \ta}$ обозначает аналогичную оценку, но
вычисленную в предположении, что $\ta\in\Ta_{0}$.
\item
Критические события теперь имеют вид
$$
S_{\la}=\left\{X: \frac{f(X,\hat\ta
)}{f(X,\hat{\hat\ta })}\ge \la\right\}. \eqno (1)
$$

Параметр $\la$, как обычно, выбирают по заданному уровню
значимости $\ep$ из условия
$$
P(S_{\la}|H_{0})\le \ep.
$$
\end{itemize}

Критерий (1) называют {\it критерием отношения правдоподобий.}

В рассматриваемой нами линейной модели оценки $\hat \ta$, $\hat{\hat\ta}$ (для пары $(l,\si^{2})$) нам
известны, и вскоре мы к ним обратимся. В общей задаче в качестве $f(x,\hat\ta )$ и $f(x,\hat{\hat\ta})$
обычно берут
$$
f(X,\hat\ta )=\maxl{\ta\in\;\ta} f(X,\ta),
$$
$$
f(X,\hat{\hat\ta} )=\maxl{\ta\in \Ta_{0}} f(X,\ta).
$$

Получаемые по такому правилу оценки $\ta$
$$\hat\ta=arg \maxl{\ta\in\Ta} f(X,\ta) \text{ и } \hat{\hat\ta}=arg \maxl{\ta\in\Ta_{0}} f(X,\ta)$$
называют {\it оценками наибольшего правдоподобия} (при условиях
$\ta\in\Ta$ и $\ta\in\Ta_{0}$).

Критерий отношения правдоподобий теперь имеет такие критические
события:
$$
S_{\la}=\left\{X:\frac{\maxl{\ta\in\;\ta}f(X,\ta )}{\maxl{\ta\in \Ta_{0}}f(X, \ta )}> \la\right\}.
$$

Само выражение $f(X,\ta )$, рассматриваемое как функция $\ta$,
называют {\it правдоподобием $\ta$}.

Отсюда и названия: оценки наибольшего правдоподобия и критерий
отношения правдоподобий. Свойства оценок наибольшего правдоподобия
мы еще будем изучать, но позже.

\subsubsection{Применение критерия
отношения правдоподобий к проверке линейных гипотез}

Применим критерий отношения правдоподобий к проверке линейных
гипотез. В рассматриваемой гауссовской модели правдоподобие есть
$$
f(X,\ta )=\left(\frac{1}{\sqrt{2\pi }}\right)^n (\si^2)^{-n/2}\exp\left\{-\frac{1}{2\si^2}|X-l|^2\right\}.
\eqno (1)
$$

При условии, что $l\in L$, оценки $\hat l, \hat\si^2$ суть
$$
\hat l=\proj_{L}X, \eqno (2)
$$
$$
\hat\si^2=\frac{1}{n-m}|\proj_{L^{\perp}}X|^2= \frac{1}{n-m}|X-\proj_{L}X|^2,
$$

где $m=\dim L$.

При условии, что $l\in L_{0}$, оценки $\hat{\hat l}, \hat{\hat\si}^2$ суть
$$
\hat{\hat l}=\proj_{L_{0}}X, \eqno (3)
$$
$$
\hat{\hat\si}^2=\frac{1}{n-m_{0}} |\proj_{L_{0}^{\perp}}X|^2= \frac{1}{n-m_{0}}|X-\proj_{L_{0}}X|^2,
$$
где $m_{0}=\dim L_{0}$.

В обоих случаях показатель экспоненты $-\frac{|X-\;l|^2}{2\si^2}$ при подстановке вместо $l$, $\si^2$ их
оценок превращается в постоянную, не зависящую от $X$ величину: в первом случае это - $-(n-m)/2$, во втором -
$-(n-m_{0})/2$.

Поэтому семейство критических событий (6.5.4.1) для проверки
гипотезы $H_{0}$ имеет вид
$$
\{X:
\frac{|X-\proj_{L_{0}}X|^2}{|X-\proj_{L}X|^2}\ge\la\}.
\eqno(4)
$$

(Параметр $\la$ в (4) не тождественен параметру $\la$ в
(6.5.4.1); несмотря на это мы употребили для них один и тот же
символ. Как уже отмечалось в 6.4, для нас важна параметризация
семейства критических событий, но не связь между различными
возможными параметризациями. Поэтому соотношение между параметрами в
(6.5.4.1) и (4) мы можем оставить без внимания.)

Ради дальнейшего упрощения (4) введем в рассмотрение еще одно
линейное подпространство: ортогональное дополнение $L_{0}$ до $L$.
Обозначим его через $L_{1}$. Итак, $L_{1}\perp L_{0}$, $L_{0}\oplus
L_{1}=L$. Теперь $\R^n$ представимо в виде суммы трех попарно
ортогональных подпространств $L_{0}, L_{1}$ и $L^{\perp}$.
 (Как обычно, $L^{\perp}$ обозначает ортогональное дополнение $L$ до всего пространства $\R^n$):
$$
\R^n=L_{0}+L_{1}+L^{\perp}.
$$

В связи с этим для $X$ действует разложение
$$
X=\proj_{L_{0}}X+ \proj_{L_{1}}X+ \proj_{L^{\perp}}X,
$$
причем
$$
|X-\proj_{L_{0}}X|^2=| \proj_{L_{1}}X|^2+ |\proj_{L^{\perp}}X|^2. \eqno
(5)
$$

В силу (5) критерий отношения правдоподобий (4) можно преобразовать:
$$
\frac{\frac{1}{m_{1}}|
\proj_{L_{1}}X|^2}{\frac{1}{n-m}|\proj_{L^{\perp}}X|^2}\ge\la
\eqno(6)
$$
с учетом замечаний к (4).

Вспомним, что оценкой для $\si^2$ при условии, что $l\in L$, служит
$$
\frac{1}{n-m}|\proj_{L^{\perp}}X|^2. \eqno (7)
$$

Это несмещенная оценка для $\si^2$, вне зависимости от того, верна или нет гипотеза $H_{0}:l\in L_{0}$. Если
же $H_{0}$ верна, то для $\si^2$ можно предложить еще одну несмещенную оценку, притом статистически
независимую от первой: это
$$
\frac{1}{m_{1}}| \proj_{L_{1}}X|^2. \eqno (8)
$$

Если гипотеза $H_{0}$ неверна, оценка (8) преображает смещение - тем
больше, чем больше $|\proj_{L_{1}}l|^2$. (Но о смещении - чуть позже,
когда будем говорить о распределениях (7) и (8)). Поэтому
критериальная статистика в (6) - это отношение двух независимых
оценок дисперсии. Если гипотеза $H_{0}$ верна, это отношение
отличается от 1 только за счет случайных колебаний. Представление об
их размере дает распределение статистики (6) при гипотезе.

Обсудим распределение статистики из (6) при гипотезе и при
альтернативе. Лемма об ортогональном разложении 4.3.2 говорит, что
$$
|\proj_{L^{\perp}}X|^2\stackrel{d}{=}\si^2\chi^2(n-m),
$$
$$
|\proj_{L_{1}}X|^2\stackrel{d}{=}\si^2\chi^2(m_1, \De ),
$$
где параметр нецентральности $\De =\frac{1}{\si^2}|\proj_{L_{1}}l|^2$. Если верна гипотеза $H_{0}$, то $\De
=0$.

Критериальная статистика из (6) распределена как $F(m_{1},
n-m,\De )$:
$$
\frac{\frac{1}{m_{1}}|
\proj_{L_{1}}X|^2}{\frac{1}{n-m}|\proj_{L^{\perp}}X|^2}\stackrel{d}{=}F(m_{1},
n-m,\De).\eqno(9)
$$

(Соотношение (9) объясняет, между прочим, и принятое для
эф-отношения название дисперсионного отношения Фишера.)

Примечательно, что при гипотезе $H_{0}$ статистика (9) распределена свободно (от влияния неизвестных
параметров $l,l\in L_{0}$, и $\si^2$). (Это свойство получено нами сверх ожиданий. Ничто в наших выкладках
того не обещало.) Поэтому выбор критического значения $\la$ в (6) очень упрощается: для этого надо (с помощью
таблиц распределения, например) решить уравнение
$$
P\{F(m_{1}, n-m,\De)\ge \la\}=\ep.
$$

В качестве критического значения (для проверки $H_{0}$ на уровне
$\ep$) в (6) надо взять $(1-\ep)$-квантиль
эф-распределения с $m_{1}$, $n-m$ степенями свободы. Которую мы уже
когда-то обозначили $F_{1-\ep }(m_{1}, n-m)$.

С вычислительной точки зрения более удобной формой для статистики
(9) может быть выражение
$$
\frac{\frac{1}{m-m_{0}}| \proj_{L}X-\proj_{L_{0}}X|^2}
{\frac{1}{n-m}|X-\proj_{L}X|^2}. \eqno (10)
$$

Итак, получили статистическое правило:
\begin{itemize}
\item
Отвергаем гипотезу $H_{0}$ на уровне $\ep$, если статистика
(9) или (10) превосходит $F_{1-\ep}(m_{1}, n-m)$.
\end{itemize}

Из свойств эф-отношения следует, что мощность этого критерия монотонно возрастает вместе с ростом параметра
нецентральности $\De =\frac{1}{\si^2}|\proj_{L_{1}}X|^2$.

\subsubsection{Пример: две нормальные выборки.}

Рассмотрим две независимые нормальные выборки
\begin{itemize}
\item
$x_{1}\sco x_{m}$, где $x_{i}\sim N(a,\si^2)$

и
\item
$y_{1}\sco y_{n}$, где $y_{i}\sim N(b,\si^2),$

параметры $a$, $b$ и $\si^2$ неизвестны.
\end{itemize}

Подлежащая проверке гипотеза
$$
H_{0}:a=b. \eqno (1)
$$

Альтернатива к ней
$$
H_{1}: a\ne b.
$$

В $(n+m)$-мерном пространстве рассмотрим векторы
$$
Z=(x_{1}\sco x_{m}, y_{1}, \sco y_{n})^T,
$$
$$
e_{1}=(\underbrace{1,\ldots , 1}_{m},\underbrace{0,\ldots
,0}_{n})^T,
$$
$$
e_{2}=(\underbrace{0,\ldots , 0}_{m},\underbrace{1,\ldots
,1}_{n})^T,
$$
$$
\ep =(\xi_{1},\ldots , \xi_{m}, \xi_{m+1},\ldots
,\xi_{m+n})^T,
$$
где $\xi_{1}, \xi_{2}, \ldots $ суть независимые $N(0,\si^2)$.

Вектор $Z$ можно представить в виде
$$
Z=ae_{1}+be_{2}+\ep.
$$

Ясно, что $Z$ следует линейной гауссовской модели, причем $\Ef Z\in L(e_{1}, e_{2})$, где $L(e_{1}, e_{2})$ обозначает (двумерное)
линейное подпространство с базисом $e_{1}, e_{2}$. При гипотезе
$H_{0}$ вектор $\Ef Z$ лежит в одномерном линейном подпространстве
$L_{0}$, порожденном единственным вектором $e_{1}+e_{2}$.

Для проверки $H_{0}$ против $H_{1}$ с помощью статистики (6.5.4.10)
надо вычислить
$$
|\proj_{L}Z - \proj_{L_{0}}Z|^2 \mbox{  и  } |Z - \proj_{L}Z|^2.
$$

Будем использовать обозначения
$$
\ol x=\frac{1}{m}\sum\limits_{i=1}^{m}x_{i}, \qquad
s^2_{x}=\frac{1}{m-1}\sum\limits_{i=1}^{m}(x_{i}-\ol x)^2,
$$
$$
\ol y=\frac{1}{n}\sum\limits_{j=1}^{n}y_{j}, \qquad
s^2_{y}=\frac{1}{n-1}\sum\limits_{j=1}^{n}(y_{j}-\ol y)^2.
$$

Легко видеть, что
$$
\proj_{L}Z=\ol xe_{1}+\ol ye_{2},
$$
$$
\proj_{L_{0}}Z=\left(\frac{m}{m+n}\ol x+\frac{n}{m+n}\ol
y\right)(e_{1}+e_{2}).
$$

Отсюда
$$
|Z - \proj_{L}Z|^2=(m-1)s^{2}_{x}+(n-1)s^{2}_{y},
$$
$$
|\proj_{L}Z - \proj_{L_{0}}Z|^2=\frac{mn}{m+n}(\ol x-\ol y)^2.
$$

В этих обозначениях статистика (6.5.5.10) и последующее
статистическое правило таковы:
\begin{itemize}
\item
Отвергать $H_{0}: a=b$ на уровне $\ep$, если
$$
\frac{mn(m+n-2)}{m+n}\frac{(\ol x- \ol
y)^2}{\sum\limits_{i=1}^{m}(x_{i}-\ol
x)^2+\sum\limits_{j=1}^{n}(y_{j}-\ol
y)^2}>F_{1-\ep}(1,m+n-2). \eqno (2)
$$
\end{itemize}

Обычно вместо эф-статистики (2) рассматривают статистику Стьюдента
$t$, причем $t^2=F$:
$$
t=\frac{\sqrt{\frac{mn}{m+n}}(\ol x-\ol
y)}{\sqrt{\frac{1}{m+n-2}[(m-1)s_{x}^{2}+(n-1)s_{y}^{2}]}}.
\eqno (3)
$$

При гипотезе $H_{0}$ статистика (3) распределена по Стьюденту с
$m+n-2$ степенями свободы.

С помощью (3) можно отдельно проверять $H_{0}$ против односторонних
альтернатив: против правосторонней
$$
H^{+}: a>b
$$
или левосторонней
$$
H^{-}: a<b.
$$

\subsubsection{Заключение}

Теория гауссовских линейных моделей составляет классическую главу
математической статистики, ее большое достижение и достояние. Вместе
с тем, с прикладной точки зрения, гауссовские методы не свободны от
недостатков и ограничений.

Эти методы {\underline{не следует}} применять, если распределение
наблюдений (или ошибок) определенно не гауссовское. В статистических
задачах за пределами геодезии, астрономии и т.п. негауссовские
ошибки - это скорее правило, чем исключение.

Гауссовские методы (к которым я здесь отношу и метод наименьших
квадратов) применять {\underline{опасно}}, если распределения близки
к гауссовским, но не исключают появления далеко отстоящих от центра
наблюдений. (Их называют грубыми ошибками или {\it выбросами}.)
Статистические оценки (и другие правила), оптимальные для
гауссовских распределений, оказываются чувствительными к выбросам.
Даже небольшая доля таких <<засоряющих>> значений в общем массиве
данных может радикально изменить результаты статистического анализа.

Поэтому для приложений нужны и другие статистические методы. Об
одном из них, не опирающемся на какую-либо параметрическую форму
распределений (и поэтому называемом параметрическим), простом
математически и достаточно универсальном, будем рассказывать далее.

\section {Ранговые методы}

\subsection{Общее определение рангов}


От любой числовой последовательности (в которой нет повторяющихся
чисел) можно перейти к последовательности их номеров, если указан
принцип их линейного упорядочения (нумерации). Обычно числовые
совокупности упорядочивают от меньшего к большему, т.е. в
возрастающем порядке. (Но бывает и по-другому.)

Номера, которые получили элементы числовой последовательности при
упорядочении, называют их {\it рангами}.

(Понятно требование, чтобы в совокупности не было одинаковых чисел:
неясно, как упорядочить одинаковые числа. Им надо бы дать одинаковые
номера). Как бы ни проводилось упорядочение числовой совокупности,
совокупность их рангов - это одна из перестановок натуральных чисел
$1,2,\ldots, n$, где $n$ - размер исходной совокупности.

Пусть теперь исходная совокупность $X=(x_{1}\sco x_{n})$ -
выборка из некоторого непрерывного распределения. С вероятностью 1
эта выборка не имеет одинаковых элементов.

Рассмотрим ранги величин $x_{1}\sco x_{n}$. Для
определенности, при упорядочении в порядке возрастания. Обозначим из
через $R(x_{1})\sco R(x_{n})$.

Основное свойство случайных рангов:
$$
P(\vec R(X)=\vec r):=P(R(x_{1})=r_1, R(x_{2})=r_2, \ldots)=\frac{1}{n!},
$$
где $(r_{1}\sco r_{n})$ - произвольная перестановка чисел
$(1,2,\ldots, n)$.

Заметим, что распределение рангов - равномерное и не зависит от
того, каким было исходное распределение случайных величин
$(x_{1}\sco  x_{n})$, т.е. выборки $X$. (Если исходное
распределение - непрерывное).

\subsection{Сравнение двух выборок, могущих отличаться сдвигом: постановка задачи}
Пусть:
\begin{itemize}
\item
$X=(x_{1},\ldots, x_{n})$ - выборка, функция распределения
$P(x_{i}\le u)=F(u)$;
\item
$Y=(y_{1}, \ldots, y_{n})$ - выборка из $F(u-\ta)$, независимая
от $X$;
\item
$\ta \in \R$ - параметр сдвига, $F(\cdot)$ - непрерывная функция,
в остальном - неизвестная.
\end{itemize}

В этой постановке надо
\begin{itemize}
\item[(a)]
Проверить гипотезу $H: \ta =0$ против лево- и правосторонних
альтернатив $H^{-}: \ta <0$, $H^{+}: \ta >0$;
\item[(b)]
Построить доверительные интервалы для $\ta$;
\item[(c)]
Указать точечную оценку $\ta$.
\end{itemize}
Все это возможно с помощью ранговых средств.

\subsection{Критерий ранговых сумм (Wilcoxon)}
\begin{center}
{\bf\underline{Ранговый метод}}  (проверки гипотезы $H$)
\end{center}

Рассмотрим объединенную совокупность $(X, Y)$:
$$
x_{1}\sco x_{m}, y_{1}\sco y_{n}.
$$

От чисел $\{x\}$, $\{y\}$ перейдем к их рангам в объединенной
совокупности $(X, Y)$. Обозначим ранги игреков через $\vec S:
R(y_{j})=S_{j}$.

Ясно, что при гипотезе $H$ в качестве $(S_{1}\sco S_{n})$
с одинаковыми вероятностями может появиться любая совокупность $n$
чисел, взятых из отрезка натуральной последовательности $1,
2,\ldots, N$, где $N=m+n$.

Эта вероятность равна $1/[N(N-1)\ldots (N-n+1)]$.

В частности, $P(R(y_{j})=S)=\frac{1}{N}$ для любого $S=1, 2, \ldots,
N$.

Чтобы понять, каково распределение рангов игреков
$(S_{1}\sco S_{n})$ при альтернативах $H^{-}$ или $H^{+}$,
представим выборку из $Y$ как продолжение выборки из $X$, но <<со сдвигом>>:
$$
y_{1}=\ta + x_{m+1}, \ldots, y_{n}=\ta + x_{m+n}.
$$

Здесь $x_{m+1},x_{m+2},\ldots, x_{m+n}$ - независимые (в
совокупности) и не зависящие от $x_{1}\sco x_{n}$
случайные величины, имеющие ту же, что и $x_{1}\sco x_{n}$, функцию распределения $F(\cdot)$.

Теперь ясно, что:
\begin{itemize}
\item
При альтернативе $H^{+}(\ta >0)$: $P(y_{j}>x_{i})>\frac{1}{2}$.
\item
При альтернативе $H^{-}(\ta <0)$ верно противоположное
неравенство $P(x_{i}>y_{j})>\frac{1}{2}$.
\end{itemize}

Поэтому при $H^{+}$ для игреков, т.е. для случайных величин
$(S_{1}\sco S_{n})$, более вероятны значения из правой
части ряда $1, 2, \ldots, N$, чем из левой.

При $H^{-}$ - наоборот, для рангов $(S_{1}\sco S_{n})$
более вероятны малые числа из $1, 2, \ldots, N$.

Выявленное различие в распределениях $\vec S$ при гипотезе и при
альтернативах можно усилить, если в качестве критериальной
статистики взять их сумму. Это - так называемая {\it статистика
Уилкоксона}, или, чуть пространнее, {\it статистика ранговых сумм
Уилкоксона} (Wilcoxon):
$$
W_{m,n}:=\sum\limits_{j=1}^{n}S_{j}.
$$

Как следует из сказанного ранее, при гипотезе $H$ (т.е. в случае
однородности выборок $X$ и $Y$) статистика $W_{m,n}$ распределена
свободно: ее распределение не зависит от того, какова (непрерывная)
функция $F$; распределение $W_{m,n}$ одинаково для всех них. Поэтому
распределение $W_{m,n}$ при гипотезе $H$ можно вычислить для любой
пары натуральных чисел $m$ и $n$. Эти распределения табулированы.

При альтернативе $H^{+}$ для $W_{m,n}$ становятся более вероятными
большие значения: для $z>0$
$$
P(W_{m,n}\ge z\,\,|\, H^{+}) >P(W_{m,n}\ge z\,\,|\,H).
$$

При $H^{-}$ справедливо противоположное неравенство:
$$
P(W_{m,n}\le z\,\,|\, H^{-}) >P(W_{m,n}\le z\,\,|\,H).
$$

Приняв во внимание эти различия в статистическом поведении $W_{m,n}$
при гипотезе и альтернативах, можно предложить правило проверки $H$
против $H^{-}$ либо $H^{+}$.

\begin{center}
{\bf\underline{Правило проверки $H$ против $H^{+}$}}
\end{center}
\begin{enumerate}
\item
Выбираем уровень значимости $\ep >0$.
\item
По заданному $\ep >0$ (с помощью таблицы распределения
$W_{m,n}$ при гипотезе) находим $(1-\ep )$-квантиль
$W_{m,n}$ - т.е. такое число $w(\ep , m, n)$, что
$$
P(W_{m,n}\ge w(\ep , m, n)\,\,|\,H)=\ep.
$$

(Лучше выбрать $\ep$ так, чтобы это уравнение имело решение\т  из-за дискретности распределения $W_{m,n}$ это возможно только для
некоторых значений $\ep$).
\item
Опровергаем гипотезу $H$ в пользу $H^{+}$ на уровне $\ep$, если
наблюденное значение $W_{m,n}$ равно или превосходит $w(\ep, m, n)$, т.е. если
$$
\mbox{набл.}W_{m,n}\ge w(\ep , m, n).
$$
\end{enumerate}

Правило проверки $H$ против $H^{-}$ выглядит аналогично, с
естественными изменениями.

Если же с гипотезой $H$ конкурирует двусторонняя альтернатива
$\overline{H}: \ta\ne 0$, то правило выглядит так:
\begin{itemize}
\item
опровергать $H$ в пользу $\overline H$, если наблюденное значение
$W_{m,n}$ далеко (легко уточнить, что это значит) отклоняется от
центра распределения $W_{m,n}$ при $H$.
\end{itemize}

Так как это распределение симметричное (проверьте!), то упомянутый
центр равен $\Ef_{0}W_{m,n}$. (Индексом ноль отмечаем распределения,
соответствующие $\ta =0$). Проверьте, что
$$
\Ef_{0}W_{m,n}=\frac{n(m+n+1)}{2}.
$$
Можно показать, что функции мощности этих критериев возрастают по мере удаления значения $\ta$ от 0.

\subsection{Связь доверительного оценивания и проверки гипотез}

Пусть $X$ - наблюдение, $P_{\ta}$ - распределение $X$, $\ta$ -
неизвестный параметр.

Предположим, что для проверки гипотезы $H_{t}: \ta =t$ мы
располагаем статистическим критерием, уровень которого
$\le\ep$. Пусть $\delta(X, t)$ - индикаторная функция
критерия. (Отвергаем $ H_{t}: \ta =t$, если $\delta(X, t)=1$.)

Доверительное множество для параметра $\ta$ с доверительной
вероятностью $\ge 1-\ep$
$$
C(X)=\left\{t: \delta(X, t)=0\right\}.
$$

Т.е. доверительное множество образуют те значения параметра, которые
совместимы с наблюдением $X$ (точнее, с $X$ совместимы распределения
вероятностей).

Легко видеть, что
$$
P_{\ta}(\ta\in C(X))\ge 1-\ep .
$$

Ибо событие $\ta\in C(X)$ означает, что $\delta(X, t)=0$, т.е.
гипотеза, что истинное значение параметра есть $\ta$, не
отвергнута - а при параметре $\ta$ эта вероятность $\ge
1-\ep$.

\underline{Пример:} (доверительная) оценка сдвига одной
параметрической выборки относительно другой.

Пусть
\begin{itemize}
\item
$X=(x_{1}\sco x_{n})$- выборка из $N(a,\si^{2})$,

\item
$Y=(y_{1}\sco y_{n})$- выборка из $N(b,\si^{2})$.
\end{itemize}

Здесь $\ta =(b-a)$ - сдвиг выборки $Y$ относительно $X$.

Для проверки гипотезы $H_{0}: a =b$, т.е. $H_{0}: \ta =0$ мы
располагаем статистикой
$$
F=\frac{mn}{m+n}\frac{\left(\ol x-\ol y\right)^2}{s^2}.
$$

Рассмотрим гипотезу $\ta =t$, $t$ - задано. Можно свести задачу к
предыдущей, если выборку $Y$ преобразовать в $Z=(z_{1}\sco z_{n})$, где $z_{j}=y_{j}-t$.

Критериальная статистика для проверки $H_{t}:\ta =t$ теперь
равна
$$
\frac{mn}{m+n}\frac{\br{\ol x-(\ol y-t)}^2}{s^2}.
$$

(Заметим, что при таком преобразовании $Y$ в $Z$ оценка дисперсии
$s^2$ не изменяется).

Решающее правило для проверки $H_{t}:\ta =t$ на уровне значимости
$\ep$: не опровергать $H_{t}$, если
$$
\sqrt{\frac{mn}{m+n}}\frac{\bm{\ol x-(\ol y-t)}}{s}<t_{1-\ep /2}.
$$

Решая это неравенство относительно $t$, получим для $\ta$
доверительный интервал
$$
\left\{\ol y-\ol x -\sqrt{\frac{m+n}{mn}}st_{1-\ep /2} < \ta <\ol y-\ol x+\sqrt{\frac{m+n}{mn}}st_{1-\ep/2}\right\}.
$$

Критическое значение $t_{1-\;\ep /2}$ находим с помощью
таблиц распределения Стьюдента с $m+n+2$ степенями свободы.

\subsection{Доверительная оценка параметра сдвига одной выборки относительно другой}

Доверительную оценку параметра сдвига одной выборки относительно
другой можно получить и для выборок, распределенных не по
нормальному, но по произвольному закону (лишь бы непрерывному).
 Для этого надо воспользоваться статистическим критерием, действенным в этих условиях. Скажем, критерием Уилкоксона. Критерий Уилкоксона надо применять для проверки гипотезы однородности выборок

\eqn{\label{samples}x_{1}\sco x_{m}, \quad y_{1}-t\sco y_{n}-t\quad \fa t\in \R.}

Обозначим статистику Уилкоксона для \eqref{samples} через $W_{m,n}(t)$:
$$
W_{m,n}(t)=\sum\limits_{j=1}^{n}R(y_{j}-t).
$$

Теперь доверительное множество для неизвестного истинного значения
параметра сдвига $\ta$ (доверительная вероятность которого равна
$1-2\al$) есть
$$
\{t: nN-w(\al, m, n)<W_{m,n}(t)< w(\al, m, n)\}. \eqno (**)
$$

Остается дать явный вид этому доверительному множеству.

Рассмотрим статистику $W_{m,n}(t)$ как функцию переменного $t\in
\R$. При $t\to -\infty$ (т.е.для значений $t$, больших по модулю и
отрицательных) каждое значение $y_{j}-t$, $j=\overline{1,n}$,
превосходит любое значение $x_{i}$, $ i=\overline{1,m}$. Поэтому
здесь
$$
W_{m,n}(t)=N+(N-1)+\ldots +(N-(n-1)),
$$
т.е. равно $\max W_{m,n}=nN-\frac{n(n-1)}{2}=\frac{1}{2}n(n+2m+1)$.
При $t\to+\infty$ по противоположным соотношениям между $y_{j}-t$ и
$x_{i}$ находим, что здесь
$$
W_{m,n}(t)=1+2+\ldots +n=\frac{n(n+1)}{2}=\min W_{m,n}.
$$

Далее отметим, что $W_{m,n}(t)$ монотонно  не возрастает (убывает),
когда $t$ растет, и что каждое уменьшение величины $W_{m,n}$
происходит скачком на единицу, когда $t$ переходит через одно из
$mn$ чисел $x_{i}-y_{j}$ ($i=\overline{1,m}, j=\overline{1,n}$).

(Для контроля: $\max W_{m,n}+\min W_{m,n}=2\Ef_{0}W_{m,n}$, $\max
W_{m,n}-\min W_{m,n}=mn$, т.е. равен количеству единичных скачков).

График функции $y=W_{m,n}(t)$, $t\in \R$:

\vskip1pc

\centerline{
\begin{picture}(500,190)
\put(30,30){\vector(1,0){400}} \put(20,180){\vector(1,0){60}}
\put(88,160){\vector(1,0){7}} \put(88,160){\vector(-1,0){8}}
\put(102,140){\vector(1,0){8}} \put(102,140){\vector(-1,0){7}}
\put(130,120){\vector(-1,0){20}} \put(200,120){\vector(1,0){20}}
\put(240,100){\vector(1,0){20}} \put(240,100){\vector(-1,0){20}}
\put(280,80){\vector(1,0){20}} \put(280,80){\vector(-1,0){20}}
\put(320,65){\vector(1,0){30}} \put(320,65){\vector(-1,0){20}}
\put(400,50){\vector(-1,0){50}} \put(30,30){\vector(0,1){160}}
\put(30,120){\vector(0,1){20}} \put(30,120){\vector(0,-1){20}}
\put(165,30){\vector(1,0){55}} \put(165,30){\vector(-1,0){55}}
\put(20,185){$y$} \put(440,15){$t$} \put(110,40){дов.интервал для
$\ta$} \put(115,28){\line(0,1){4}} \put(120,28){\line(0,1){4}}
\put(125,28){\line(0,1){4}} \put(130,28){\line(0,1){4}}
\put(135,28){\line(0,1){4}} \put(140,28){\line(0,1){4}}
\put(145,28){\line(0,1){4}} \put(150,28){\line(0,1){4}}
\put(155,28){\line(0,1){4}} \put(160,28){\line(0,1){4}}
\put(165,28){\line(0,1){4}} \put(170,28){\line(0,1){4}}
\put(175,28){\line(0,1){4}} \put(180,28){\line(0,1){4}}
\put(185,28){\line(0,1){4}} \put(190,28){\line(0,1){4}}
\put(195,28){\line(0,1){4}} \put(200,28){\line(0,1){4}}
\put(205,28){\line(0,1){4}} \put(210,28){\line(0,1){4}}
\put(80,180){\line(0,-1){150}} \put(95,160){\line(0,-1){130}}
\put(110,140){\line(0,-1){110}} \put(220,120){\line(0,-1){90}}
\put(260,100){\line(0,-1){70}} \put(300,80){\line(0,-1){50}}
\put(350,65){\line(0,-1){35}}
\put(150,140){это $w(\al ,m,n)$}
\put(350,105){это $nN-w{\al,m,n}$}
\put(60,15){$(\min y_{j}-\max x_{i})$}
\put(330,15){$(\max y_{j}-\min x_{i})$}
\put(73,20){\vector(1,1){7}}
\put(343,20){\vector(1,1){7}}
\put(410,50){$\min W_{m,n}$}
\put(90,180){$\max W_{m,n}$} \put(350,30){\circle*{3}}
\put(80,30){\circle*{3}} \put(110,30){\circle*{3}}
\put(220,30){\circle*{3}} \put(260,30){\circle*{3}}
\put(300,30){\circle*{3}} \put(300,80){\circle*{3}}
\put(350,60){\circle*{3}} \put(95,150){\circle*{3}}
\put(80,170){\circle*{3}} \put(110,130){\circle*{3}}
\put(30,140){\line(1,0){110}} \put(30,100){\line(1,0){370}}
\end{picture}}

\vskip1pc

Ради некоторых дальнейших удобств при $t=y_{j}-x_{i}$ положим
$W_{m,n}(t)$ равным полусумме пределов справа и слева. Это
равносильно соглашению, что при ранжировании совпадающих значений мы
приписываем всем им одинаковые (средние) ранги.

Из свойств функции $W_{m,n}(t)$ и ее графика следует, что
доверительное множество $(**)$ есть интервал; его концами служат
некоторые элементы из множества $\{x_{i}-y_{j}, i=\overline{1,m},
j=\overline{1,n}\}$, которые нетрудно указать точно. Для этого
сказанное множество нужно упорядочить, а затем выбрать порядковые
статистики с нужными номерами. (Из рисунка видно, какие это номера).

\subsection{Точечная оценка сдвига (величины $\ta$)}

Статистика $W_{m,n}(t)$ количественно выражает степень согласия
(однородности) двух выборок: $x_1\sco x_m$ и
$y_{1}-t\sco y_{n}-t$. Чем более отклоняется
$W_{m,n}(t)$ от $\Ef_{0}W_{m,n}$ (от ожидаемого значения $W_{m,n}$ при
полной однородности), тем больше (сильнее) различаются выборки. Эти
две выборки тем ближе к однородным (если мерить с помощью статистики
Уилкоксона), чем ближе $W_{m,n}(t)$ к $\Ef_{0}W_{m,n}$.

Отсюда вытекает предложение: выбрать в качестве точечной оценки
неизвестного сдвига $\ta$ величину $\hat\ta$ такую, что
$$
W_{m,n}(\hat\ta)=\Ef_{0}W_{m,n} (\mbox{ т.е. }
=\frac{n(n+m+1)}{2}).
$$

Из графика видно, что
$$
\hat\ta = med(\{x_{i}-y_{j}, i=\overline{1,m},
j=\overline{1,n}\}).
$$
($\hat\ta$ - так называемая медиана Ходжеса-Лемана).

\subsection{Асимптотическая нормальность статистики ранговых сумм Уилкоксона}

\subsubsection{Формулировка теорем}
\underline{\bf Теорема 1.}
\begin{quote}
Пусть $(x_{1},\ldots ,x_{m})$ и $(y_{1}, \ldots , y_{n})$ суть
независимые выборки из непрерывных распределений, статистика $W_{m,
n}$ ранговых сумм Уилкоксона вычислена по этим выборкам. Тогда при
$m, n\to \infty$
$$
\frac{W_{m, n}-\Ef W_{m, n}}{\sqrt{\Df W_{m, n}}}
\stackrel{d}{\longrightarrow}N(0, 1).
$$
\end{quote}

Введем статистику Манна\ч Уитни ({\it Mann\ч Whitney}):
$$
H_{m, n}: =\sum\limits^{m}_{i=1}\sum\limits^{n}_{j=1}I(x_{i}<y_{j}).
$$

С вероятностью 1
$$
W_{m, n}=H_{m, n}+\frac{n(n+1)}{2}.
$$

Поэтому для доказательства теоремы 1 достаточно доказать

\underline{\bf Теорема 2.}
\begin{quote}
В условиях теоремы 1
$$
\frac{H_{m, n}-\Ef H_{m, n}}{\sqrt{\Df H_{m, n}}}
\stackrel{d}{\longrightarrow}N(0, 1).
$$
\end{quote}

Теорема 2\т это частный случай теоремы 3 об асимптотическом
поведении так называемой {\it U-статистики} ({\it U}-statistics). (В данном случае, $H_{m, n}$ - это двувыборочная $U$-статистика.)
$$
U_{m, n}: =\sum\limits^{m}_{i=1}\sum\limits^{n}_{j=1}f(x_{i},y_{j}).
$$

\underline{\bf Теорема 3.}
\begin{quote}
Пусть $(x_{1},\ldots ,x_{m})$ и $(y_{1}, \ldots , y_{n})$\т две
независимые выборки, функция $f(x, y)$ такова, что
$$
\Ef f^2(x_{1}, y_{1})<\infty , \Ef(\Ef[f(x_{1}, y_{1})|x_{1}])^2>0 ,
\Ef[\Ef(f(x_{1}, y_{1})|y_{1})]^2>0.
$$

Тогда при $m, n\to \infty$
$$
\frac{U_{m, n}-\Ef U_{m, n}}{\sqrt{\Df U_{m, n}}}
\stackrel{d}{\longrightarrow}N(0, 1).
$$
\end{quote}

Мы докажем теорему 3, ограничиваясь случаем $\Ef f=0$ (что
соответствует однородной выборке в теореме 2), поскольку этот случай
для нас более важен и поскольку в этом случае легко вычислить
$\Ef_{0}U_{m, n}$ и $\Df _{0}U_{m, n}$.

По ходу доказательства нам будет необходима так называемая

\underline{\bf Теорема Слуцкого.}
\begin{quote}
Пусть:
\begin{itemize}
\item
случайная последовательность $\{\xi_{n}\}$ сходится по распределению
к случайной величине $\xi$;
\item
случайная последовательность $\{\eta_{n}\}$ сходится по вероятности
к постоянной величине $C$.
\end{itemize}

Тогда при $n\to \infty$
\begin{itemize}
\item[(a)]
$$
\xi_{n}+\eta_{n}\stackrel{d}{\longrightarrow}\xi +C.
$$
\item[(b)]
$$
\xi_{n}\eta_{n}\stackrel{d}{\longrightarrow}C\xi.
$$
\end{itemize}
\end{quote}

\subsubsection{Доказательство теоремы 3: начало}

Вместо $x_{i}$, $y_{j}$ будем писать $X$, $Y$. Мы предполагаем, что
$\Ef f(X, Y)=0$ и, следовательно, $\Ef U_{m,n}=0$.

Введем случайные величины $\al (X)$ и $\beta (Y)$:
$$
\al (X)=\Ef[f(X, Y)|X],\qquad \beta (Y)= \Ef[f(X, Y)|Y].
$$

Представим $U_{m, n}$ в виде
$$
U_{m,
n}=\sum\limits^{m}_{i=1}\sum\limits^{n}_{j=1}[f(x_{i},y_{j})-\al
(x_{i})-\beta
(y_{j})]+\sum\limits^{m}_{i=1}\sum\limits^{n}_{j=1}[\al
(x_{i})+\beta (y_{j})]=
$$
$$
=n\sum\limits^{m}_{i=1}\al (x_{i})+ m\sum\limits^{n}_{j=1}\beta
(y_{j})+\De_{m, n},
$$
где
$$
\De_{m,
n}=\sum\limits^{m}_{i=1}\sum\limits^{n}_{j=1}[f(x_{i},y_{j})-\al
(x_{i})-\beta (y_{j})].
$$

Далее дробь $U_{m, n}/\sqrt{\Df U_{m, n}}$, предельное поведение
которой и есть предмет теоремы 3 ($\Ef U_{m,n}=0$), представляем в
виде:
$$
\frac{U_{m, n}}{\sqrt{\Df U_{m, n}}}=
\frac{n\sum\limits^{m}_{i=1}\al (x_{i})+
m\sum\limits^{n}_{j=1}\beta
(y_{j})}{\underbrace{\sqrt{\Df [n\sum\limits^{m}_{i=1}\al (x_{i})+
m\sum\limits^{n}_{j=1}\beta (y_{j})]}}_{\xi_{m, n}}}
\:\underbrace{\sqrt{\frac{\Df [n\sum\limits^{m}_{i=1}\al
(x_{i})+ m\sum\limits^{n}_{j=1}\beta (y_{j})]}{\Df U_{m, n}}}}_{C_{m,
n}}\: + \:\underbrace{\frac{\De_{m, n}}{\sqrt{\Df U_{m,
n}}}}_{\eta_{m, n}}
$$
или, коротко:
$$
\frac{U_{m, n}}{\sqrt{\Df U_{m, n}}}=\xi_{m, n}C_{m,
n}+\eta_{m, n}.
$$

Для доказательства теоремы 3 достаточно показать, что
\begin{itemize}
\item[(a)]
$C_{m, n}\longrightarrow 1$,
\item[(b)]
$\xi_{m, n}\stackrel{d}{\longrightarrow}N(0, 1)$,
\item[(c)]
$\eta_{m, n}\stackrel{p}{\longrightarrow}0$.
\end{itemize}

Затем применить теорему Слуцкого.

\subsubsection{Вычисление дисперсии $U$-статистик.}

Ключевую роль играет вычисление дисперсии $U$-статистик. Поэтому мы
выделяем это в отдельный пункт. Так как $\Ef f=0$, то
$$
\Df U_{m, n}=\Ef U_{m, n}^{2}=\sum\limits^{m}_{i=1}\sum\limits^{m}_{i'=1}
\sum\limits^{n}_{j=1}\sum\limits^{n}_{j'=1}\Ef f(x_{i}, y_{j})f(x_{i'},
y_{j'}).
$$

Стоящую в правой части сумму представим в виде четырех слагаемых,
каждое из которых есть сумма, где индексы удовлетворяют условиям:
$$
\sum\nolimits_{1}=\sum\nolimits \ldots \sum\nolimits (i\ne i', j\ne
j'),
$$
$$
\sum\nolimits_{2}=\sum\nolimits \ldots \sum\nolimits (i=i', j\ne
j'),
$$
$$
\sum\nolimits_{3}=\sum\nolimits \ldots \sum\nolimits (i\ne i',
j=j'),
$$
$$
\sum\nolimits_{4}=\sum\nolimits \ldots \sum\nolimits (i= i', j=j').
$$

\begin{enumerate}
\item
$\sum\nolimits_{1}=0$, т.к. $\Ef f=0$.
\item
$\sum\nolimits_{2}=mn(n-1)\Ef f(x_{1}, y_{1})f(x_{1},
y_{2})=mn(n-1)\Df \al$, так как
$$
\Ef f(x_{1}, y_{1})f(x_{1}, y_{2})=\Ef\Ef[f(x_{1}, y_{1})f(x_{1}, y_{2})|x_{1}]=
\Ef\{\Ef[f(x_{1}, y_{1})|x_{1}] \Ef[f(x_{1}, y_{2})|x_{1}]\}
$$
$$
=\Ef\al (x_{1})\al (x_{1})=\Df \al,
$$
ибо $\Ef\al (x_{1})=0$.
\item
$\sum\nolimits_{3}=mn(m-1)\Df \beta$ - аналогично.
\item
$\sum\nolimits_{4}=mn\Ef f^2=mn\Df f(x, y)$.
\end{enumerate}

Поэтому
$$
\Df U_{m, n}=mn(n-1)\Df \al +nm(m-1)\Df \beta +mn\Df f.
$$

\subsubsection{Доказательство теоремы 3: окончание}
\begin{itemize}
\item
\underline{ Утверждение (c)} есть следствие неравенства Чебышева для
$\eta_{m, n}$, ибо
$$
\Df \eta_{m, n}=\frac{\Df \De_{m, n}}{mn[n\Df \al +m\Df \beta
+ \const]}\longrightarrow 0,
$$
так как (в силу 7.7.3):
$$
\Df \De_{m, n}=mn\Df [\tilde f(x_{1}, y_{1})-\tilde\al
(x_{1})-\tilde\beta (y_{1})]$$ ибо для функции $\tilde f=f(x_{1},
y_{1})-\al (x_{1})+\beta (y_{1})$ слагаемые $\sum\nolimits_{3}=0$
и $\sum\nolimits_{2}=0$.
\item
\underline{ Утверждение (a)} очевидно, ибо
$$
\Df [n\sum\limits^{m}_{i=1}\al (x_{i})+ m\sum\limits^{n}_{j=1}\beta
(y_{j})]=n^2m\Df \al +m^2n\Df \beta .
$$
\item
\underline{ Утверждение (b)} есть одна из форм центральной
предельной теоремы. Ее легко доказать методом \\
характеристических функций, по аналогии с доказательством
центральной предельной теоремы для суммы независимых одинаково
распределенных случайных величин.
\end{itemize}

\subsubsection{Доказательство теоремы Слуцкого.}

Ограничимся доказательством утверждения (a).

Надо показать, что для любой непрерывной ограниченной функции
$f(\cdot)$ справедливо утверждение
$$
\Ef f(\xi_{n}+\eta_{n})\to \Ef f(\xi +C).
$$

Докажем это утверждение. Точнее, мы покажем, что при $n\to \infty$
$$
\Ef[f(\xi_{n}+\eta_{n})-f(\xi +C)]\to 0.
$$

Заметим, что для любого $\ep >0$ существует $A>0$, такое,
что $P(|\xi |>A)<\ep$.

Поскольку $\xi_{n}\stackrel{d}{\to}\xi$, то для достаточно больших
$n$
$$
P(|\xi_n |>A)<2\ep .
$$

Далее: для любого $\delta >0$ для достаточно больших $n$
$$
P(|\eta_{n}-C |>\delta)<\ep,
$$

т.к. $\eta_{n}\stackrel{p}{\to}C$.

Поскольку
$$
\Ef[f(\xi_{n}+\eta_{n})-f(\xi +C)]=
$$
$$
=\Ef[f(\xi_{n}+\eta_{n})-f(\xi_{n} +C)]+\Ef[f(\xi_{n}+C)-f(\xi +C)],
\eqno (*)
$$
достаточно показать, что каждое из двух слагаемых в правой части
$(*)$ для достаточно больших $n$ становится меньше любого наперед
заданного числа.

Начнем с первого из них.

Рассмотрим
$$
\Ef[f(\xi_{n}+\eta_{n})-f(\xi_{n} +C)]=
$$
$$
=\Ef[f(\xi_{n}+\eta_{n})-f(\xi_{n} +C)][I(|\xi |\le A)+I(|\xi
|>A)][I(|\eta_{n}-C |\le \delta)+I(|\eta_{n}-C |>\delta)]
$$
$$
=\Ef[f(\xi_{n}+\eta_{n})-f(\xi_{n} +C)]I(|\xi |\le A)I(|\eta_{n}-C
|\le \delta)+R_{n}
$$

Через $R_{n}$ обозначена сумма, составленная из прочих слагаемых,
которые получаются, когда мы раскроем скобки. В каждом из этих
слагаемых есть либо $ I(|\xi |>A)$, либо $ I(|\eta_{n}-C |>\delta)$,
либо оба.

Каждое из упомянутых слагаемых можно оценить по модулю сверху как $2M\ep$, где $M=\maxl{u}f(u)$.

Обратимся к главному слагаемому и заметим, что $\xi_{n}$ и
$\eta_{n}$ в нем ограничены. Поэтому значения $\xi_{n}+\eta_{n}$
принадлежат компакту.

Так как функция $f(\cdot)$ непрерывна, на этом компакте она
равномерно непрерывна. Это означает, что $\forall
\ep>0 \quad \exists \delta>0:$ если $|u-v|<\delta$, то
$|f(u)-f(v)|<\ep$.

Здесь
$$
|(\xi_{n}+\eta_{n})-(\xi_{n}-C)|=|\eta_{n}-C|\le\delta,
$$
так что
$$
|f(\xi_{n}+\eta_{n})-f(\xi_{n}-C)|<\ep.
$$

В итоге получаем, что для произвольного $\ep$ и достаточно
больших $n$
$$
|\Ef[f(\xi_{n}+\eta_{n})-f(\xi_{n}+C)]|<K\ep,
$$
где $K$ - некоторая постоянная.

Обратимся ко второму слагаемому в $(*)$.

Из сходимости $\xi_{n}\stackrel{d}{\to}\xi$ следует, что
$$
|\Ef f(\xi_{n}+C)-\Ef f(\xi +C)|<\ep
$$
для $\ep >0$ и достаточно больших $n$.

Возвращаясь к $(*)$, заключаем, что для достаточно больших $n$ верно
$$
|\Ef f(\xi_{n}+C)-\Ef f(\xi +C)|<\tilde K\ep
$$
где $\tilde K$ - некоторая постоянная. Поскольку $\ep$ может
быть выбрано произвольно малым, утверждение теоремы доказано.

\subsubsection{Применение теоремы 1 для вычисления статистики Уилкоксона}

Теорема 1 бывает полезна для вычисления критических значений
статистики $W_{m, n}$ при больших $m, n$.

Чтобы воспользоваться теоремой 1, надо вычислить $\Df _{0}W_{m, n}$
(дисперсию при гипотезе, т.е. для однородных выборок $(x_{1},\ldots
, x_{m})$ и $(y_{1}, \ldots , y_{n})$).

Мы вычислим $\Df _{0}H_{m, n}=\Df _{0}W_{m, n}$.

Воспользуемся результатом пункта 7.7.3, положив
$$
f(x_{1}, y_{1})=I (x_{1}<y_{1})-\Ef I (x_{1}<y_{1})= I (x_{1}<y_{1})-P
(x_{1}<y_{1}).
$$

Как сказано, ограничимся однородными выборками. Тогда
$$
P(x_{1}<y_{1})= P(x_{1}>y_{1})=1/2.
$$

Общую функцию распределения (непрерывную!) обозначим через
$$
F(u)=P(x_{i}<u)=P(y_{j}<u).
$$

Вычисляем
$$
\al (x_{i})=
$$
$$
\Ef\{[I (x_{i}<y_{j})-1/2]|x_{i}\}= P (x_{i}<y_{j}|x_{i})-1/2=1- P
(y_{j}<x_{i}|x_{i})-1/2=1/2-F(x_{i}).
$$

Аналогично: $\beta (y_{j})=F(y_{j})-1/2$.

Заметим, что для случайной величины $X$, имеющей непрерывную функцию
распределения $F(u)=P(X<u)$, <<новая>> случайная величина $\xi =F(X)$
распределена равномерно на [0, 1].

Доказательство следует из чертежа:

\vskip1pc

\centerline{\begin{picture}(500,150)
\put(80,20){\vector(1,0){230}} \put(110,20){\vector(0,1){110}}
\put(80,110){\line(1,0){230}} \put(115,115){$y$} \put(300,10){$u$}
\put(80,0){Событие $\{F(X)<z\}$} \put(290,100){$y=F(u)$}
\put(330,60){Пусть} \put(330,50){$0<z<1$} \put(100,70){$z$}
\put(110,70){\line(1,0){50}} \put(160,20){\line(0,1){50}}
\put(101,20){\line(0,1){3}} \put(109,20){\line(0,1){3}}
\put(105,20){\line(0,1){3}} \put(113,20){\line(0,1){3}}
\put(117,20){\line(0,1){3}} \put(121,20){\line(0,1){3}}
\put(125,20){\line(0,1){3}} \put(129,20){\line(0,1){3}}
\put(133,20){\line(0,1){3}} \put(137,20){\line(0,1){3}}
\put(141,20){\line(0,1){3}} \put(145,20){\line(0,1){3}}
\put(149,20){\line(0,1){3}} \put(153,20){\line(0,1){3}}
\put(157,20){\line(0,1){3}} \put(160,20){\line(0,1){3}}
\put(84,20){\line(0,1){3}} \put(88,20){\line(0,1){3}}
\put(92,20){\line(0,1){3}} \put(96,20){\line(0,1){3}}
\put(99,20){\line(0,1){3}}
\end{picture}}



Ясно, что $P(F(X)<z)=z$.

Получили, что при гипотезе (однородности)

$$
\al (x_{i})=1/2-U_{i},\qquad \beta (y_{j}) =V_{j}-1/2,
$$

где $U_{1}, \ldots , U_{m}$, $V_{1}, \ldots , V_{n}$ суть
независимые случайные величины, равномерно распределенные на [0, 1].

Очевидно, что
$$
\Ef_{0}\al^{2}=\Df U_{i}=\frac{1}{12}=\Ef_{0}\beta_{j}^{2}=\Df V_{j}=\frac{1}{12}.
$$

Поэтому
$$
\Df _{0}H_{m, n}=\Df _{0}W_{m,
n}=\frac{mn(n-1)}{12}+\frac{m(m-1)n}{12}+\frac{mn}{4}=\frac{mn(m+n+1)}{12}.
$$
ибо $\Df _{0}f$ здесь равно
$$
\Df _{0}f=\Df _{0}I(x_{1}<y_{1})=P(x_{1}<y_{i})[1-P(x_{1}<y_{1})]=1/4.
$$

Итак, для непрерывных однородных выборок теорема 1 дает:
$$
W^{*}_{m, n}= \frac{W_{m,n}-n\frac{n+m+1}{2}}{\sqrt{mn\frac{m+n+1}{12}} }
\stackrel{d}{\longrightarrow}N(0, 1) \text{ при } m, n\to \infty.
$$


Пользоваться этим нормальным приближением (для не слишком малых или
больших вероятностей) можно при $m, n\ge 10$. Центральная предельная
теорема не дает нам оценок для скорости сходимости. Сказанное
правило подтверждается сравнением точного распределения $W_{m, n}$ и
его нормальной аппроксимации.

\section{Метод наибольшего правдоподобия}

\subsection{Определения}
Пусть $X$ - наблюденная случайная величина, распределение которой
принадлежит параметрическому семейству $P_{\ta}$,
$\ta\in\Ta$; пусть $\ta^{0}$ обозначает истинное значение
параметра.

Предположим, что распределения $P_{\ta }$ имеют плотность
(обозначаемую $p(x, \ta )$) относительно какой-либо меры. (Если
эта мера считающая, то $p(X, \ta )$ - это вероятность события
$X=x$).

{\it Правдоподобием} значения параметра $\ta$ называют (случайную
величину) $p(X, \ta )$.

То значение параметра $\ta$, для которого правдоподобие принимает
наибольшее значение, называют {\it оценкой наибольшего
правдоподобия} $\ta$:
$$
\hat\ta=\arg \maxl{\ta\in\;\ta}p(X,\ta). \eqno (1)
$$

Асимптотические свойства оценок наибольшего правдоподобия мы изучим
для выборки, объем которой неограниченно возрастает.

Итак, пусть $X=(x_{1}, \ldots ,x_{n})$ - выборка из распределения,
обладающего плотностью $f(x, \ta )$, где $\ta\in\Ta$\т неизвестный параметр; его истинное значение (при котором получена
выборка $X$) есть $\ta^{0}\in\Ta$.

Относительно оценки (1) мы докажем - при определенных условиях на
$f(\cdot , \ta )$, что
\begin{itemize}
\item[a)]
$\hat\ta_{n}$ - \underline{состоятельная} оценка для
$\ta^{0}$,
\item[b)]
$\hat\ta_{n}$ распределена \underline{асимптотически нормально}.
\end{itemize}

Дадим определения.

\underline{\bf Определение 1.}
\begin{quote}
Оценка $t=t(X)$ параметра $\ta$ называется {\it состоятельной},
если $t(X)\stackrel{p}{\longrightarrow}\ta^{0}$ при $n\to\infty$.
\end{quote}

\underline{\bf Определение 2.} (упрощенное)
\begin{quote}
Мы говорим, что статистика $\hat\ta_{n}$ распределена {\it
асимптотически нормально}, когда
$$
\sqrt{n}(\hat\ta_{n}-\ta^{0})\stackrel{d}{\longrightarrow}N(0,\si^{2})
$$
для некоторых $\ta^{0}$ и $\si^{2}$.

При этом $\ta^{0}$ называют {\it асимптотическим средним}, а $\si^{2}/n$ - {\it асимптотической дисперсией}
$\hat\ta_{n}$.
\end{quote}

\subsection{Состоятельность оценок наибольшего правдоподобия}
Начнем с леммы (варианта т.н. неравенства информации).

\underline{\bf Лемма.}
\begin{quote}
Пусть $f(\cdot )$, $g(\cdot )$ - две плотности вероятности.

Тогда
$$
\int\nolimits f(x)\ln f(x)dx\ge \int\nolimits f(x)\ln g(x)dx,
\eqno(1)
$$
причем равенство возможно, только если $f=g$ почти всюду.
\end{quote}


\underline{\bf Соглашения:}

\begin{enumerate}
\item
Для интегралов допускается значение $-\infty$.
\item
Будем считать, что
$$
\int\limits_{A}f(x)\ln g(x)dx=0 ,\qquad\mbox{если $f(x)=0$ для $x\in
A$}
$$
вне зависимости от значений $g(\cdot )$.
\end{enumerate}

{\it Доказательство.}

Достаточно показать, что
$$
\int\nolimits f(x)\ln \frac{g(x)}{f(x)}dx\le 0.
$$

Заметим, что $\ln (1+x)\le x$ для $x\ge -1$. (См. на рисунке 1
графики функций $y=x$ и $y=\ln(1+x)$)

% TO\Df O: add picture
%\begin{picture}(500,200)
%\end{picture}
%\begin{center}
%{\it Рисунок 1.}
%\end{center}

Рассмотрим множество $A=\{x: f(x)>0\}$.

Для $x\in A$:
$$
\ln\frac{g(x)}{f(x)}\equiv\ln
\left[1+\left(\frac{g(x)}{f(x)}-1\right)\right]\le
\frac{g(x)}{f(x)}-1.
$$

Умножив обе части неравенства на $f(\cdot )$, интегрируем:
$$
\int\nolimits f(x)\ln \frac{g(x)}{f(x)}dx\le
\int\nolimits [g(x)-f(x)]dx=0,
$$
ч.т.д. $\Box$.

\subsection{Почему оценка наибольшего правдоподобия состоятельна -
правдоподобное рассуждение.}

Если $X=(x_{1}, \ldots ,x_{n})$ - выборка из распределения с
плотностью $f(x, \ta )$, то правдоподобие $X$ имеет вид
$\prod^{n}_{i=1}f(x_{i}, \ta )$, а оценка наибольшего
правдоподобия (8.1.1) есть
$$
\arg \maxl{\ta\in\Ta}\prod^{n}_{i=1}f(x_{i}, \ta ),
$$
или
$$
\arg \maxl{\ta\in\Ta}\left[\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i}, \ta )\right].
$$

(Точка экстремума не изменяется при переходе от функции к ее
логарифму и при умножении на положительное число.)

В силу закона больших чисел при $n\to\infty$
$$
\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i}, \ta )
\stackrel{p}{\longrightarrow} \Ef_0\log f(x_{i}, \ta ), \eqno (1)
$$
где $\Ef_0$ означает усреднение по плотности $f(x, \ta^{0} )$, где
$\ta^{0}$ - истинное значение $\ta$.

Поэтому естественно ожидать, что
$$
\arg \maxl{\ta\in\Ta}\left[\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i}, \ta )\right]
\stackrel{p}{\longrightarrow} \arg \maxl{\ta\in\Ta}\Ef_0\log f(x_{i}, \ta ).
$$

Согласно лемме из 8.2 справедливо (8.2.1); это неравенство для
$g(x)=f(x, \ta )$, $f(x)=f(x, \ta^{0} )$ дает:
$$
\Ef_0 \log f(x_{i}, \ta )\equiv\int\nolimits [\log f(x,\ta
)]f(x,\ta^{0})dx\le \int\nolimits [\log
f(x,\ta^{0})]f(x,\ta^{0})dx.
$$

Следовательно,
$$
\arg \maxl{\ta\in\Ta}\Ef_0 f(x_{i}, \ta )=\ta^{0}.
$$

Доказательство сходимости
$\hat\ta_{n}\stackrel{P}{\longrightarrow}\ta^{0}$ надо
проводить, учитывая свойства $\Ef_0\log f(x_{1}, \ta )$, как
функции $\ta$, $\ta\in\Ta$.
 Если эта функция непрерывна по $\ta$, обычно удается такой план:
\begin{itemize}
\item
Показать, что сходимость в (1) равномерна по $\ta$ на компакте,
содержащем $\ta^{0}$.
\item
В этом случае можно утверждать, что существует последовательность
локальных экстремумов функции $\hat\ta_{n}$, по вероятности
сходящаяся к $\ta^{0}$:
$$\hat\ta_{n}\stackrel{P}{\longrightarrow}\ta^{0}, \quad n\ra\bes. \eqno (2)$$
\end{itemize}

\subsection{Доказательство сходимости
$\hat\ta_{n}\stackrel{P}{\longrightarrow}\ta^{0}$ для
одномерного случая} В одномерном случае доказательство очевидно.

Чтобы доказать (8.3.2), мы покажем, что (локальный) экстремум
функции
$$
\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i}, \ta )
$$
при достаточно больших $n$ со сколь угодно близкой к 1 вероятностью
лежит внутри интервала ($\ta^{0}$ - $h$, $\ta^{0}$+$h$), где
$h$ - произвольное число.
% TO\Df O: insert picture
%\begin{picture}(500,150)
%\end{picture}

\begin{center}
{\it Рисунок 2.}
\end{center}

Так как
$$
\Ef_0\log f(x_{1}, \ta^{0})> \Ef_0\log f(x_{1}, \ta^{0}\pm h),
$$
то можно подобрать такое $\ep >0$, что
$$
\Ef_0\log f(x_{1}, \ta^{0} )- \ep > \Ef_0\log f(x_{1},
\ta^{0}\pm h)+ \ep.
$$

Для произвольного, но фиксированного $\delta >0$, в силу упомянутого
в 8.3 закона больших чисел (8.3.1) для достаточно больших $n$
выполняется неравенство:
$$
P\left\{\left|\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i},
\ta^{0})- \Ef_0\log f(x_{1},
\ta^{0})\right|<\ep\right\}>1-\delta ,
$$


$$
P\left\{\left|\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i},
\ta^{0}\pm h)- \Ef_0\log f(x_{1}, \ta^{0}\pm
h)\right|<\ep\right\}>1-\delta .
$$

Поэтому
$$
P\left\{\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i},
\ta^{0})>\frac{1}{n}\sum\limits^{n}_{i=1}\log f(x_{i},
\ta^{0}\pm h)\right\}>1-2\delta.
$$

Поэтому (при достаточно больших $n$) экстремум (локальный) функции
правдоподобия из (8.1.1) лежит в сколь угодно узкой окрестности
точки $\ta^{0}$. Поэтому последовательность этих локальных
экстремумов сходится (по вероятности) к $\ta^{0}$, что и
требовалось доказать. $\Box$

\subsection{Асимптотическая нормальность оценок наибольшего
правдоподобия (по выборке из регулярного семейства)}

(См. Ивченко, Медведев, $\S 2.4$.)

Пусть $X=(x_{1}, \ldots ,x_{n})$ - выборка из распределения с
плотностью (вероятностью) $p(x, \ta )$, $\ta\in\Ta\subset
\R$. (После того, как мы закончим исследование одномерного параметра
$\ta$, мы обсудим, какие изменения надо сделать, когда
$\ta\in\Ta\subset \R^{r}$.) Множество $\Ta$ будем считать
открытым.

В рассматриваемом случае оценка наибольшего правдоподобия есть
решение уравнения правдоподобия
$$
\frac{\pd}{\pd\ta}\sum\limits^{n}_{i=1}\log
p(x_{i}, \ta^{0})=0 \eqno (1)
$$

Считая, что $p(x, \ta )$ трижды дифференцируема по $\ta$,
предположим, что существует функция $M(x)$ такая, что

\begin{enumerate}
\item
$$
\left|\frac{\pd^3}{\pd\ta^3}\log
p(x,\ta )\right|<M(x),
$$

\item
$$
\Ef_{\ta}M(x)<\infty
$$
для всех $\ta\in\Ta$.
\end{enumerate}

В дальнейшем ради краткости будем писать
$$
l(x,\ta )=\frac{\pd
}{\pd\ta}\sum\limits^{n}_{i=1}\log p(x,\ta ).
$$

Введем новую переменную $\tau$, положив
$$
\ta=\ta^0+\frac{\tau}{\sqrt{n}}.
$$

Теперь уравнение правдоподобия (1) имеет вид
$$
\frac{1}{\sqrt{n}}\sum\limits^{n}_{i=1}
l(x_{i},\ta^0 +\frac{\tau}{\sqrt{n}})=0. \eqno (2)
$$

Разлагаем левую часть (2) по формуле Тейлора в точке 0. Получим:
$$
\frac{1}{\sqrt{n}} \sum\limits^{n}_{i=1}
l(x_{i},\ta^{0})+ \frac{1}{\sqrt{n}}
\sum\limits^{n}_{i=1} l'_{\ta }(x_{i},\ta^{0})
\frac{\tau}{\sqrt{n}}+\frac{1}{2\sqrt{n}}
\sum\limits^{n}_{i=1} l''_{\ta\ta }(x_{i},\tilde\ta_n)
\left(\frac{\tau}{\sqrt{n}}\right)^2=0, \eqno (3)
$$
где $\tilde\ta_{n}$ - некая промежуточная точка между
$\ta^{0}$ и $\ta$.

Заметим, что если ограничить область изменения переменной $\tau$
произвольным компактом, т.е. предположить, что $|\tau |<C$ для
некоторого $C$, то третье слагаемое окажется (при $n\to\infty$)
бесконечно малым.

Действительно:
$$
\left|\frac{1}{\sqrt{n}} \sum\limits^{n}_{i=1}
l''_{\ta\ta }(x_{i},\tilde\ta_n)
\left(\frac{\tau}{\sqrt{n}}\right)^2\right|<
\frac{C^2}{\sqrt{n}}\left|\frac{1}{n}\sum\limits^{n}_{i=1}
M(x_{i})\right|\stackrel{P}{\longrightarrow}0,
$$
т.к. по закону больших чисел $$
\frac{1}{n}\sum\limits^{n}_{i=1}
M(x_{i})\stackrel{P}{\longrightarrow}\Ef_{\ta }M(x_{1}).
$$

Сопоставим решение уравнения (2), левая часть которого представлена
в форме (3), и решение уравнения
$$
\frac{1}{\sqrt{n}} \sum\limits^{n}_{i=1}
l(x_{i},\ta^{0})+ \frac{1}{\sqrt{n}}
\sum\limits^{n}_{i=1} l'_{\ta }(x_{i},\ta^{0})
\frac{\tau}{\sqrt{n}}=0. \eqno (4)
$$
(Левая часть в (3), но без третьего слагаемого).

Решение (4) очевидно:
$$
\tau^{*}_{n}=\frac{-\frac{1}{\sqrt{n}}
\sum\limits^{n}_{i=1} l(x_{i},\ta^{0})}
{\frac{1}{\sqrt{n}} \sum\limits^{n}_{i=1} l'_{\ta
}(x_{i},\ta^{0}) \frac{1}{\sqrt{n}}}. \eqno (5)
$$

При этом легко увидеть, что при $n\to\infty$
$$
\tau^{*}_{n}\stackrel{d}{\longrightarrow}N(0,(i(\ta^{0}))^{-1}).
$$

Здесь $ i(\ta^{0})$ - количество информации (по Фишеру) о
$\ta$, содержащейся в одном наблюдении $x_{1}$.

Действительно, числитель (5) есть сумма независимых случайных
величин $\frac{\pd
}{\pd\ta}\sum\limits^{n}_{i=1}\log p(x_{i},
\ta^{0}),\qquad i=\overline{1, n}$.

При обсуждении неравенств Крамера\ч Рао мы отметили, что
$$
\Ef_{\ta }\frac{\pd
}{\pd\ta}\sum\limits^{n}_{i=1}\log p(x_{i}, \ta)=0
$$
для $\ta\in\Ta$, и что
$$
\Ef_{\ta
}\left[\frac{\pd}{\pd\ta}\sum\limits^{n}_{i=1}\log
p(x_{i}, \ta)\right]^{2}=i(\ta ).
$$

По центральной предельной теореме числитель (5) по
распределению сходится к $ N(0, i(\ta^{0}))$, когда $n\to\infty$.

Знаменатель (5) по закону больших чисел сходится (по вероятности) к
$\Ef_{\ta }l'_{\ta }(x_{i},\ta^{0})$, где
$\ta$=$\ta^{0}$.

Мы (при упомянутых выше обсуждениях) отмечали, что
$$
\Ef_{\ta }\left[\frac{\pd^2
}{\pd\ta^2}\sum\limits^{n}_{i=1}\log p(x_{i},
\ta)\right]=-i(\ta ).
$$

Поэтому (по теореме Слуцкого) при $n\to\infty$
$$
\tau^{*}_{n}\stackrel{d}{\longrightarrow}N(0,(i(\ta^{0}))^{-1}).
\eqno (6)
$$

Разумеется, надо проверить отдельно (дополнительно), что
$$
0<i(\ta )<\infty.
$$

Остается убедиться, что решение уравнения (2) асимптотически
эквивалентно решению уравнения (4) - эквивалентно в том смысле, что
при $n\to\infty$ разность между ними стремится к нулю (по
вероятности).

Мы уже отмечали, что левые части (2) и (4) отличаются бесконечно
мало (и притом равномерно по $\tau$), когда $|\tau |<C$, $C$ -
произвольная постоянная.

Рассмотрим левую часть (4) как функцию от $\tau$: $y=\psi_{n}(\tau
)$.


Для достаточно больших $n$ график левой части (2), скажем
$y=\ph_{n}(\tau )$, будет - при $\tau<C$ - проходить в
$\ep$-окрестности графика $y=\psi_{n}(\tau )$.

Поскольку $\ep >0$ может быть выбрано сколь угодно малым, у
уравнения правдоподобия (2) найдется решение $\hat\tau_{n}$, такое,
что $\hat\tau_{n}-\tau^{*}_{n}\stackrel{P}{\longrightarrow}0$ - при
том дополнительном условии, что уравнение (4) имеет решение,
принадлежащее компакту $\{\tau :|\tau |<C\}$.

Остается сделать последнее замечание, чтобы завершить исследование
(2). Так как $\tau^{*}_{n}$ (решение (4)) асимптотически нормально,
можно выбрать упомянутый выше компакт $\{\tau :|\tau |<C\}$ так,
чтобы для произвольно выбранного $\delta >0$
$$
P(|\tau^{*}_{n} |<C)>1-\delta
$$
для достаточно больших $n$.

Таким образом, со сколь угодно близкой к 1 вероятностью, уравнение
(4) имеет корень на выбранном компакте (для достаточно больших $n$),
притом этот корень $\hat\tau_{n}$ распределен также, как и
$\tau^{*}_{n}$, т.е. при $n\to\infty$
$$
\hat\tau_{n}\stackrel{d}{\longrightarrow}N(0,(i(\ta^{0}))^{-1}).
\eqno (7)
$$

Вернемся к переменной $\ta =\ta^{0}+\frac{\tau
}{\sqrt{n}}$,
$\hat\ta_{n}=\ta^{0}+\frac{\hat\tau_n
}{\sqrt{n}}$, $\hat\tau_{n}=\sqrt{n}(\hat\ta_{n}-\ta^{0})$.

Утверждение (7) означает, что
$$
\sqrt{n}(\hat\ta_{n}-\ta^{0})
\stackrel{d}{\longrightarrow}N(0,(i(\ta^{0}))^{-1}).
$$

Следовательно, мы доказали, что (при наложенных на $p(x, \ta )$
выше условиях)
 существует решение (точнее, последовательность решений) уравнения правдоподобия (1)
 $\hat\ta_{n}$, сходящееся к $\ta^{0}$ и распределенное асимптотически
нормально $N(\ta^{0}, \frac{1}{ni(\ta^{0})})$.

\subsection{Многомерный случай}

Для многомерного параметра $\ta$ все исследование проходит так
же, как и для
 одномерного, с очевидными изменениями.
\begin{itemize}
\item
Так, уравнение правдоподобия (1) теперь - векторное (т.е. (1)
представляет собой систему уравнений).
\item
Условие о третьих производных формулируется так:
$$
\left|\frac{\pd^3}{\pd\ta_{i}\pd\ta_{j}\pd\ta_{k}}\log
p(x,\ta )\right|<M(x),
$$
и т.д.
\item
Место количества информации $i(\ta )$ займет теперь матрица
информации ${\cal J}(\ta)$, а окончательный результат примет вид
$$
\hat\ta_{n} \stackrel{d}{\longrightarrow}N(\ta^{0},n^{-1}{\cal
J}^{-1}(\ta^{0})).
$$
\end{itemize}

\section{Асимптотическая нормальность оценок
(статистических функций фон Мизеса)}

Пусть $x_{1}, \ldots ,x_{n}$ - выборка из распределения (для
простоты - одномерного), неизвестную функцию распределения которого
обозначим через $F(\cdot )$. По этой выборке мы хотим оценить
функционал $T(F)$, $T(\cdot )$ задан (на множестве или подмножестве
функций распределения). Воспользуемся для этого близостью к $F(\cdot
)$ выборочной (эмпирической) функции распределения $F_{n}(\cdot )$:
\begin{itemize}
\item
Если $T(\cdot )$ - непрерывный функционал, то $ T(F_{n} )\approx
T(F)$, т.е.
$$
T(F_{n})\stackrel{P}{\longrightarrow}T(F)
$$
при $n\to\infty$.
\end{itemize}

\underline{\bf Примеры функционалов $T(F)$:}
\begin{enumerate}
\item
Моменты и квантили функции распределения $F(\cdot )$.
\item
Второй центральный момент случайной величины $X$, функция
распределения которой есть $F(\cdot )$:
$$
\Ef(X-\Ef X)^2=\frac{1}{2}\int\limits_{-\infty}^{+\infty}\int\limits_{-\infty
}^{+\infty }(x-y)^2dF(x)dF(y).
$$
\item
Оценка наибольшего правдоподобия для семейства распределений
$F(x,\ta )$, $\ta\in\Ta$, соответствует функционалу
$$
T(F)=\arg\maxl{\ta\in\Ta }\int\nolimits\log f(x,\ta )dF(x).
$$
\item
Для оценивания неизвестного параметра $\ta$ по выборке,
распределение которой принадлежит семейству $F(x,\ta )$,
$\ta\in\Ta$, можно применять (использовать) различные
функционалы $T(F)$.

Пусть, например, по выборке из $N(a, \si^2)$ мы хотим оценить неизвестное $a$. В качестве $T(F)$ мы можем
взять, например, функционалы
$$
T(F)=\int\nolimits xdF(x)
$$
и
$$
T(F)=med\; F.
$$
\end{enumerate}

Если функционал $T(F)$ в каком-либо смысле дифференцируем, то
$$
T(G)=T(F+(G-F))=T(F)+\int\nolimits a(x)d(G-F)+R, \eqno (1)
$$
где $a(\cdot )$ - некоторая функция, $R$ - остаточный член, который
убывает быстрее, чем $G-F$. Эта формула - аналог формулы Тейлора для
функции нескольких переменных.

Пусть, действительно, $f(X)=f(x_{1}, \ldots ,x_{p})$, $dX=(dx_{1},
\ldots , dx_{p})$. Тогда
$$
f(X+dX)=f(X)+\sum\limits_{i=1}^{p}\frac{\pd f}{\pd
x_{i}}dx_{i}+o(dX)
$$
$$
=f(X)+[\nabla f(X)][dX]+o(dX).
$$

В бесконечномерном варианте суммирование заменяется интегрированием.

Заметим, что линейный функционал $\int\nolimits ad(G-F)$ задан на
линейном пространстве разностей функций распределения. Мы можем
распространить его определение и на множество функций распределения.
Для этого достаточно указать значение $\int\nolimits a(X)dF(X)$.
Фактически, речь идет о выборе функции $a(X )$: возьмем $a(\cdot )$
таким, чтобы
$$
\int\nolimits a(x)dF(x)=0. \eqno (2)
$$

Тогда (1) превращается в
$$
T(G)=T(F)+ \int\nolimits a(x)dG(x)+R. \eqno (3)
$$

(Впрочем, можно было бы начать сразу с (3). Тогда (2) стало бы
следствием (3).)

Функционал $\int\nolimits a(X)dG(X)$ - это производная $T(F)$ в
направлении $G$ по G\^ateaux. По определению, производная по
G\^ateaux равна
$$
\lim\limits_{\la\to +0}\la^{-1}[T((1-\la )F+\la
G)-T(F)], \eqno (4)
$$
если этот предел существует.

Возьмем в (3) в качестве $G$ функцию распределения
$$
F+\la (G-F)=(1-\la )F+\la G, \qquad\mbox{ где }
\la\in [0,1].
$$

Подставив это выражение в (3) и перейдя к пределу по $\la\to
+0$, получим сказанное.

Для функции $a(\cdot )$ можно получить явное (более явное)
выражение, если в (4) в качестве $G(\cdot )$ взять функцию
распределения вероятностей, сосредоточенную в одной точке.

Пусть $\De_{u}(x)$ - функция распределения, сосредоточенная в
точке $u$:
$$
\De_{u}(x)=\case{0, &если\; x<u,\cr 1, &если\; x>u.\cr}
$$

Тогда
$$
\lim\limits_{\la\to +0}\la^{-1}[T((1-\la
)F+\la\De_{u})-T(F)]=\int\nolimits a(x)d\De_{u}(x)=a(u).
\eqno (5)
$$


\subsection{Функция влияния}

Формулу (5) можно трактовать и так:
$$
T((1-\la )F+\la\De_{u})\approx T(F)+\la a(u). \eqno
(6)
$$

Функция $(1-\la )F+\la\De_{u}$ соответствует смеси двух
распределений: $F(\cdot )$, взятого с весом $(1-\la)$, и
$\De_{u}$, взятого с весом $\la$.

Такое распределение возникает, когда к (основному) распределению
$F(\cdot )$ <<примешана>> некоторая доля $\la$ наблюдений,
происходящих не из $F(\cdot )$ , а просто равных числу $u$.
Соответственно в выборке, извлеченной из такого распределения,
помимо наблюдений, подчиняющихся распределению $F(\cdot )$, есть
доля $\la$ <<посторонних>> величин $u$. В статистике такие
посторонние значения называют {\it выбросами}, {\it грубыми
ошибками}, {\it засорениями} и т.д.

Формулы (5) и (6) показывают, какое влияние на $T(F)$ оказывают эти
засоряющие
 значения. Поэтому другое название для $a(x)$ - {\it функция влияния}. За ней
 закрепилось довольно неуклюжее обозначение:
$$
a(x)=IF (x, T,F)
$$
($IF$ - первые буквы {\it <<influence function>>}).

Функция влияния показывает, сколь значительно может измениться
$T(F)$ из-за появления <<засоряющих>> элементов в выборке. Таким
образом, она служит одной из количественных характеристик
устойчивости $T(F)$ к засорению.

\subsection{Асимптотическая нормальность $T(F_{n})$}

Теперь применим (3), чтобы получить асимптотическое распределение
оценки $T(F)$ по выборке. В силу (3):
$$
T(F_{n})=T(F)+\int\nolimits a(x)dF_{n}(x)+R_{n}. \eqno (7)
$$

Ясно, что
$$
\int\nolimits a(x)\,dF_{n}(x)=\frac{1}{n}\sum\limits_{i=1}^{n}a(x_{i}),
$$
причем $\Ef a(x_{i})=0$. (Ибо $\Ef a(x_{i})=\int\nolimits a(x)\,dF(x)=0$.)

Заметим, что случайные величины $a(x_{i})$ независимы и одинаково
распределены. Поэтому
$$
\frac{1}{\sqrt{n}}\sum\limits_{i=1}^{n}a(x_{i})\stackrel{d}{\longrightarrow}N(0,\Ef a^2(x_{1})),
$$
если
$$
\Ef a^2(x_{1})=\int\nolimits a^2(x)\,dF(x)<\infty.
$$

Таким образом,
$$
\int\nolimits a(x)dF_{n}(x)=O(\frac{1}{\sqrt{n}}).
$$

Если остаточный член $R_{n}$ в (7) стремится к нулю быстрее, чем
$\frac{1}{\sqrt{n}}$, то
$$
\sqrt{n}[T(F_{n})-T(F)]\stackrel{d}{\longrightarrow}N(0, Var\;
IF(x_{1}, T, F)). \eqno (8)
$$

Это и есть утверждение об асимптотической нормальности случайной
величины (статистики) $T(F_{n})$ при $n\to\infty$.

Приведенное рассуждение не является доказательством. Однако оно
приводит к правильным результатам (во всех известных случаях). Оно
позволяет предугадать ответ (который затем можно доказывать
отдельно).

Задачи.
\begin{itemize}
\item
Вычислите функции влияния для двух функционалов: $T(F)=\int\nolimits
xdF$ и $T(F)=med\,F$.
\item
Убедитесь, что первая из них неограниченно возрастает по $u$, так
что $\ol x=\sum\limits_{i=1}^{n}x_{i}$ (как статистическая оценка)
неустойчива (not robust).
\item
С помощью функции влияния найдите асимптотическое распределение $med
(x_{1}, \ldots ,x_{n})$ - медианы выборки $x_{1}, \ldots ,x_{n}$ из
распределения $F$, считая, что $F'(\mu )>0$, где $\mu$ - медиана
$F$, т.е. $F(\mu)=1/2$.
\end{itemize}

\subsection{Асимптотическое неравенство Крамера\ч Рао}

Пусть распределение $F(x,\ta)$ имеет плотность $f(x, \ta )$,
$\ta\in\Ta$, $\Ta\subset \R$ - открытое множество.

Пусть
$$
T(F(\cdot ,\ta ))=\ta
$$
для $\ta\in\Ta$.

(Такие функционалы называют {\it состоятельными по Фишеру}.)

Пусть $\ta^{0}$ - некоторое фиксированное значение параметра
$\ta$, $\ta^{0}\in\Ta$. Положим (для краткости)
$F^{0}(x)=F(x,\ta^{0})$.

Применим (3), полагая $G(x)=F(x,\ta )$,
$F(x)=F^{0}(x)=F(x,\ta^{0})$.

Получаем
$$
\ta\equiv T(F(\cdot, \ta ))=T(F^0)+\int\nolimits IF(y, T,
F^0)dF(y,\ta)+R. \eqno (9)
$$

В данном случае остаточный член $R$ есть функция от $\ta$,
$\ta^{0}$. Предположим, что
$$
R=(\ta -\ta^{0})g(\ta ,\ta^0).
$$

Примем все предположения о семействе $F(\cdot, \ta )$, которые мы
сделали ранее, при доказательстве неравенства Крамера\ч Рао. Да и
действовать будем по той же схеме.

Дифференцируя (9) по $\ta$ в точке $\ta=\ta^{0}$, найдем:
$$
1=\int\nolimits IF(y, T, F^{0})\frac{\pd
}{\pd\ta }f(y, \ta )\Bigr|_{\ta=\ta^0}dy,
$$
или
$$
1=\int\nolimits IF(y, T, F^{0})\left[\frac{\pd
}{\pd\ta }\ln f(y, \ta^{0})\right] f(y,\ta^0 )dy.
$$

Правую часть можно записать как математическое ожидание, если ввести
случайную величину $X$, которая имеет плотность $f(y,\ta^{0})$:
$$
1=\Ef_{0}[IF(X, T, F^{0})][\frac{\pd }{\pd\ta }\ln f(X,
\ta^{0})].
$$

Согласно неравенству Коши-Римана-\ldots ,
$$
(\Ef\xi\eta )^2\le (\Ef\xi^2)(\Ef\eta^2).
$$

Отсюда
$$
1\le \underbrace{\Ef_{0}[IF(X, T, F^{0})]^2}_{{\mbox{Это
}Var\;IF(X, T, F^{0})}}\cdot \underbrace{\Ef_{0}[\frac{\pd
}{\pd\ta }\ln f(X, \ta^{0})]^2}_{{\mbox{Это
}I(\ta^{0})}}.
$$

Следовательно, для любого $\ta^{0}\in\Ta$
$$
Var\;IF(X, T, F^{0})\ge \frac{1}{I(\ta^{0})}. \eqno
(10)
$$

Левая часть (10) - это асимптотическая дисперсия $T(F_{n})$,
 согласно (8). Следовательно, состоятельная по Фишеру оценка
 параметра $\ta$ не может иметь асимптотическую дисперсию
(будучи асимптотически нормальной), меньшую, чем $I^{-1}(\ta )$.

\section{Критерии согласия типа Пирсона-Фишера}

Они относятся к независимым испытаниям с несколькими исходами и
 гипотезам об их вероятностях.

Рассмотрим независимые испытания с $m$ ($m\ge 2$) исходами.
Обозначим их исходы через $A_{1}\sco A_{m}$.

Вероятности этих исходов неизменны во всех испытаниях. Обозначим эти
вероятности через $p_{1}\sco p_{m}$, причем
$\sum\limits_{i=1}^{m}p_{i}=1$. Описанные испытания будем
называть{\it испытаниями Бернулли} (даже в случае $m>2$).

Предположим, что в $n$ испытаниях Бернулли были зарегистрированы
частоты (количества осуществлений) $\mu_{1}\sco \mu_{m}$ исходов $p_{1}\sco p_{m}$; при этом
$\sum\limits_{i=1}^{m}\mu_{i}=n$. Теоремы, обсуждаемые в этой главе,
касаются проверок гипотез о $\vec p=(p_{1}\sco p_{m})^T$ по
частотам $\vec \mu=(\mu_{1},\ldots , \mu_{m})^T$.

Начнем с первого критерия такого рода, установленного К. Пирсоном
(Karl Pearson) к 1900 году. (Теорему Пирсона, которая будет
сформулирована чуть позже, можно считать первой значительной
теоремой математической статистики). Критерий Пирсона относится к
проверке простой гипотезы о вероятностях:

$$
H_{0}: \vec p=\vec p^{\; 0}
$$
или, подробнее,
$$
H_{0}: p_{1}=p_{1}^0\sco p_{m}=p_{m}^0,
$$
где $p_{1}^0\sco p_{m}^0$ - заданные положительные
вероятности, $\sum\limits_{i=1}^{m}p_{i}^{0}=1$. Правило Пирсона
имеет асимптотический характер и может корректно применяться лишь
при достаточно большом количестве испытаний $n$ (что это означает\т обсудим позже).

\subsection {Правило К. Пирсона}
\begin{quote}
Отвергнуть $H_{0}: \vec p=\vec p^{\; 0}$ на (приближенном) уровне
 $\ep$, $\ep >0$, если
$$
\sum\limits_{i=1}^{m}\frac{(\mu_{i}-np_{i}^{0})^2}{np_{i}^{0}}>\chi^2_{1-\ep
}(m-1).
$$
\end{quote}

Здесь $\chi^2_{1-\ep }(m-1)$ обозначает
($1-\ep$)-квантиль
 распределения хи-квадрат с ($m-1$) степенью свободы.

Вопрос о том, какие численности $n$ достаточно велики для того,
чтобы, при необходимости, можно было обращаться к этому правилу,
довольно темен, несмотря на долгую его историю.

Осторожная (консервативная) рекомендация: должны выполняться
соотношения $nр_{i}^{0}\ge 5$ для всех $i=\overline{1, m}$.

Сказанное правило основано на асимптотических свойствах статистики
Пирсона
$$
X_{n}^{2}:=\sum\limits_{i=1}^{m}\frac{(\mu_{i}-np_{i}^{0})^2}{np_{i}^{0}}
$$
при гипотезе (когда истинные вероятности $\vec p=\vec p^{\; 0}$) и
альтернативе (когда $\vec p\ne\vec p^{\; 0}$).

\begin{itemize}
\item
Начнем со случая $\vec p\ne\vec p^{\; 0}$. Перепишем $X^2_{n}$ в
виде
$$
X_{n}^{2}=n\sum\limits_{i=1}^{m}\Bigl(\frac{\mu_{i}}{n}-p_{i}^{0}\Bigr)^2/p_{i}^{0}.
$$

По закону больших чисел (в данном случае - это теорема Бернулли)
$$
\frac{1}{n}\vec\mu\longrightarrow\vec p.
$$

Поэтому
$$
\sum\limits_{i=1}^{m}\Bigl(\frac{\mu_{i}}{n}-p_{i}^{0}\Bigr)^2/p_{i}^{0}\stackrel{P}{\longrightarrow}\sum\limits_{i=1}^{m}\frac{(p_{i}-p_{i}^{0})^2}{p_{i}^{0}}.
$$

Этот предел положителен, если и только если $\vec p\ne\vec p^{\;
0}$.

Отсюда  следует, что при альтернативе статистика $X^2_{n}$
неограниченно возрастает:
$$
X_{n}^{2}\stackrel{P}{\longrightarrow}\infty
$$
при $n\to\infty$.

\item
Асимптотическое поведение $X^2_{n}$ при гипотезе $\vec p=\vec p^{\;
0}$:
\end{itemize}

\underline{\bf Теорема} ({\it Karl Pearson}, 1900 г.).

При $n\to\infty$
$$
\sum\limits_{i=1}^{m}\frac{(\mu_{i}-np_{i}^{0})^2}{np_{i}^{0}}\stackrel{d}{\longrightarrow}\chi^2_{0}(m-1).
$$

(Случайная величина $\chi^{2}_{n}$ при $n\to\infty$ сходится по
 распределению к хи-квадрат с ($m-1$) степенями свободы).

Таким образом, большие значения $X^2_{n}$, маловероятные при
гипотезе $H_{0}$, оказываются в области больших вероятностей при
альтернативе
 $\ol H_{0}$.

На этом свойстве $X^2_{n}$ и основано приведенное выше правило
проверки гипотезы $H_{0}: \vec p=\vec p^{\; 0}$.

Мы докажем эту теорему чуть позже.

\subsubsection{Многомерная теорема Муавра-Лапласа}
\begin{quote}
В описанной выше схеме испытаний Бернулли с $m$ исходами при
$n\to\infty$:
$$
\sqrt{n}(\frac{1}{n}\vec\mu - \vec
p)\stackrel{d}{\longrightarrow}N(0, {\cal P}-\vec p\vec p^{\; T}),
$$
где ${\cal P}=diag (p_{1},\ldots , p_{m})$ - диагональная матрица.
\end{quote}

{\it Доказательство.}

Доказательство этой теоремы можно провести методом
характеристических функций практически так же, как и доказательство
классической теоремы Муавра-Лапласа, когда $m=2$.

В этом последнем случае обычно рассматривают не весь вектор частот
(двумерный), но лишь одну его координату, ибо вторая при этом
полностью определяется первой (их сумма равна $n$).

Представляем вектор $\vec\mu =(\mu_{1},\ldots , \mu_{m})^T$ в виде
суммы $n$ независимых и одинаково распределенных случайных векторов
$\vec x_{j}$, $j=\overline{1, n}$, $j$ - номер испытания.

Все координаты $m$-мерного вектора $\vec x_{j}$ равны 0, за
исключением одной, которая равна 1. Единица стоит на том месте,
номер которого соответствует осуществившемуся в $j$-ом испытании
исходу из ряда $A_{1},\ldots ,A_{m}$.

Ясно, что
$$
\vec\mu =\sum\limits^{n}_{j=1}\vec x_{j}
$$
и что случайные векторы $\vec x_{1},\ldots , \vec x_{j},\ldots$
независимы и одинаково распределены.

Согласно центральной предельной теореме для независимых и одинаково
распределенных случайных слагаемых при $n\to\infty$
$$
\frac{1}{\sqrt{n}}\sum\limits^{n}_{j=1}(\vec
x_{j}-\Ef\vec x_{j})\stackrel{d}{\longrightarrow}N(0,\Sigma ),
$$
где
$$
\Sigma=\Ef\vec x_{j}\vec x_{j}^{\; T}-(\Ef\vec x_{j})(\Ef\vec x_{j})^T.
$$

Очевидный подсчет дает

$$
\Ef\vec x_{j}=\vec p,\qquad \Df \vec x_{j}={\cal P}-\vec p\vec p^{\; T}.
$$

Заметим, что матрица ${\cal P}-\vec p\vec p^{\; T}$ вырождена. Ее
ранг равен ($m-1$).

Если бы не это обстоятельство, предельное распределение хи-квадрат
для нормы вектора
$$
\xi_{n}\stackrel{d}{\longrightarrow} N(0,\Sigma )
$$
мы могли бы получить немедленно. Ибо очевидно, что
$$
\xi_{n}^{T}\Sigma^{-1}\xi_{n}\stackrel{d}{\longrightarrow}
\chi^{2}(m).
$$
$\Box$

\subsubsection{Доказательство теоремы Карла Пирсона}

Введем в рассмотрение вектор
$$
\xi_{n}:=\sqrt{n}{\cal P}^{-1/2}(\frac{1}{n}\vec\mu -\vec p).
$$

Легко видеть, что при $n\to\infty$
$$
\xi_{n}\stackrel{d}{\longrightarrow}N(0, I-zz^T),
$$
где $I$ - единичная матрица, $z=(\sqrt{p_{1}}\sco \sqrt{p_{m}})^T$.

Ведем \underline{ортогональную} матрицу $V$, первая строка которой
есть $(\sqrt{p_{1}}\sco \sqrt{p_{m}})^T$, а прочие
строки произвольны. Заметим, что при $n\to\infty$
$$
V\xi_{n}\stackrel{d}{\longrightarrow}N(0, I_{1}),$$ где $I_{1}$ -
матрица ($m\times m$), которая получена из единичной заменой
 левой верхней единицы нулем:
$$
I_{1}=\left(\begin{array}{cccc}
0 & 0 & \ldots & 0\\
0 & 1 & \ldots & 0\\
\vdots &\vdots &\ddots &\vdots \\
0 & 0 & \ldots & 1
\end{array}\right).
$$

Это доказывает простая выкладка:
$$
\Df (V\xi_{n})=V(\Df \xi_{n})V^T=V(1-zz^T)V^T=
$$
$$
VV^T-(Vz)(Vz)^T=I-\left(\begin{array}{cccc}
1 & 0 & \ldots & 0\\
0 & 0 & \ldots & 0\\
\vdots &\vdots &\ddots &\vdots \\
0 & 0 & \ldots & 0
\end{array}\right),
$$
ибо $Vz=(1,0,\ldots , 0)^T$.

Теперь
$$
|\xi_{n}|^2=\sum\limits^{m}_{i=1}\Bigl(\frac{1}{\sqrt{p_{i}}}\sqrt{n}(\frac{1}{n}\mu_{i}
-p_{i})\Bigr)^2=\sum\limits^{m}_{i=1}\frac{(\mu_{i}-np_{i})^2}{np_{i}},
$$
а также
$$
|\xi_{n}|^2=|V\xi_{n}|^2\stackrel{d}{\longrightarrow} |N(0,
I_{1})|^2=\chi^{2}(m-1).
$$

Здесь через $|N(0, I_{1})|^2$ мы обозначили квадрат длины, т.е.
сумму квадратов координат гауссовского вектора
$$
(0,\eta_{2},\ldots , \eta_{m})^T,
$$
где $\eta_{2},\ldots , \eta_{m}$ суть независимые стандартные
гауссовские случайные величины $N(0, 1)$.

По определению,
$$
\eta_{2}^2+\ldots +\eta_{m}^2=\chi^{2}(m-1).
$$
$\Box$

\subsection{Сложные гипотезы}

Здесь мы рассмотрим гипотезы о $\vec p$ вида
$$
H: \vec p\in Q,
$$
где $Q$ - некоторое заданное гладкое многообразие, принадлежащее симплексу \\
$\{\vec p:\sum\limits^{m}_{i=1}p_{i}=1, p_{1}\ge 0,\ldots , p_{m}\ge
0\}$. <<Гладкое>> здесь означает, что в каждой точке $\vec p\in Q$
существует касательное линейное многообразие. Размерность $\vec p$
обозначим через $r$.

Справедлива

\underline{\bf Теорема 1} ({\it J.\,Neyman, E.\,Pearson}, 1928):
\begin{quote}
При $n\to\infty$
$$
\min\limits_{\vec p\in Q}\sum\limits^{m}_{i=1}\frac{(\mu_{i}-np_{i})^2}{np_{i}}\stackrel{d}{\longrightarrow}
\chi^2(m-r-1). \eqno (*)
$$
\end{quote}

Заметим, что при вычислении статистики из $(*)$ обычно находят и то
значение $\vec p\in Q$, при котором достигается минимум в $(*)$. Это
минимизирующее значение часто называют {\it оценкой} $\vec p\in Q$,
полученной по
 {\it <<методу минимума хи-квадрат>>}.

Другая формулировка той же теоремы возникает, когда многообразие $Q$
задано
 параметрически, т.е., когда гипотеза $\vec p\in Q$ представима в виде
$$
\vec p=\vec p(\ta ),
$$
где $\ta$ - $r$-мерный параметр.

Пусть $\hat\ta_{n}$  - оценка наибольшего правдоподобия для
неизвестного $\ta$, основанная на частотах $\mu_{1}, \ldots
,\mu_{m}$. (Либо иная оценка, но с теми же асимптотическими
свойствами, что и $\hat\ta_{n}$). Тогда справедлива

\underline{\bf Теорема 2.}
\begin{quote}
При $n\to\infty$
$$
\sum\limits^{m}_{i=1}\frac{(\mu_{i}-np_{i}(\hat\ta
))^2}{np_{i}(\hat\ta )}
\stackrel{d}{\longrightarrow}\chi^{2}(m-r-1). \eqno (**)
$$
\end{quote}

Эти теоремы и другие, подобные, часто связывают с именем Р. Фишера (R.\,A.\,Fisher).

Фишер был первым, кто заметил уменьшение числа
степеней свободы предельного распределения хи-квадрат, когда
параметры оцениваются по выборке, и ровно настолько, сколько
независимых параметров пришлось оценить. Он обнаружил это при
проверке гипотезы о независимости признаков в таблицах
 сопряженности. Мы будем говорить об этом в 10.5.

А сейчас, чтобы окончить, сформулируем правило проверки $H: \vec
p\in Q$, основанное на приведенных выше теоремах. А также на том
факте, что статистики $(*)$ и $(**)$ неограниченно возрастают при
$n\to\infty$, если истинное значение $\vec p\notin Q$.


\underline{\bf Правило} проверки $H: \vec p\in Q$ против $\ol H:
\vec p\notin Q$.
\begin{quote}
Отвергаем $H$ на (приближенном) уровне $\ep >0$, если
статистика $(*)$ или $(**)$ превосходит ($1-\ep$)-квантиль
$\chi^2(m-r-1)$.
\end{quote}

Это правило применимо <<для достаточно больших $n$>>. Осторожная
(консервативная) практическая рекомендация: $\mu_{i}\ge 5$.
 (Впрочем, разные авторы говорят несколько различное на эту тему.)

\subsection{Таблицы сопряженности.}

Предположим, что каждый объект некоторой (бесконечной) совокупности
может быть классифицирован по двум признакам $A$ и $B$. Признак $A$
 при этом принимает $r$ значений, признак $B$ - $s$ значений, соответственно
$A_{1},\ldots ,A_{r}$ и $B_{1},\ldots , B_{s}$. Каждый объект
обладает некоторой комбинацией $A_{i}B_{j}$, $i=\overline{1, r}$,
$j=\overline{1, s}$, значений признаков $A$ и $B$.

Пусть $p_{ij}$ обладает комбинацией признаков $A_{i}B_{j}$.

Пусть $\mu_{ij}$ - число комбинаций $A_{i}B_{j}$, зарегистрированное
при случайном выборе $n$ объектов из генеральной совокупности
($\mu_{ij}$ - выборочные частоты). Таблицу частот $\|\mu_{ij},
i=\overline{1, r}, j=\overline{1, s}\|$ называют {\it таблицей
сопряженности } признаков $A$ и $B$.

Важная статистическая гипотеза - гипотеза о независимости признаков
$A$ и $B$.

В этом случае
$$
p_{ij}\equiv P(A_{i}B_{j})=P(A_{i})P(B_{j}).
$$

Вероятность появления $A_{i}$ и вероятность появления $B_{j}$
обозначим через $p_{i\cdot }$ и $p_{\cdot j}$ соответственно. При
этом
$$
p_{i\cdot }=\sum\limits^{s}_{j=1}p_{ij}, p_{\cdot
j}=\sum\limits^{r}_{i=1}p_{ij}.
$$

Гипотеза независимости признаков теперь может быть выражена так:
$$
H: p_{ij}= p_{i\cdot }p_{\cdot j} \qquad\mbox{для всех }
i=\overline{1, r}, j=\overline{1, s}.
$$

Каждое извлечение объекта из генеральной совокупности - это
испытание Бернулли, которое оканчивается одним из $m=rs$ исходов
$A_{i}B_{j}$.

При гипотезе $ H: p_{ij}= p_{i\cdot }p_{\cdot j}$, вероятности этих
исходов выражаются через параметры $p_{i\cdot }$, $p_{\cdot j}$.
Поэтому вектор вероятностей (в данном случае - матрица размера
($r\times s$)) $\vec p=|p_{ij}|$ принадлежит ($r+s-2$)-мерному
многообразию. (Размерности именно $r+s-2$, так как параметры
подчиняются связям $\sum\limits_{j=1}^{r}p_{i\cdot }=1$,
$\sum\limits_{i=1}^{s}p_{\cdot j}=1$.)

Поскольку мы имеем дело с испытаниями Бернулли и гипотезой о
вероятностях в этих испытаниях, мы можем воспользоваться
результатами пункта 10.4.

Для этого найдем оценки наибольшего правдоподобия для $p_{i\cdot }$
и $p_{\cdot j}$ и затем применим теорему 2.

Правдоподобие $\|p_{ij}\|$, основанное на таблице $|\mu_{ij}|$, равно
$$
n!\prod\limits_{i=1}^{r}\prod\limits_{j=1}^{s}\frac{1}{(\mu_{ij})!}(p_{ij})^{\mu_{ij}}.
$$

При гипотезе независимости правдоподобие упрощается: правдоподобие \\
$|p_{i\cdot }, p_{\cdot j}, i=\overline{1, r}, j=\overline{1, s}|$
равно
$$
Const \prod\limits_{i=1}^{r}(p_{i\cdot})^{\mu_{i\cdot
}}\prod\limits_{j=1}^{s}(p_{\cdot j})^{\mu_{\cdot j}}.
$$
где $\mu_{i\cdot }=\sum\limits_{j=1}^{s}\mu_{ij},\mu_{\cdot j}=
\sum\limits_{i=1}^{r}\mu_{ij}$, $Const$ означает множитель, не
содержащий параметров $p_{i\cdot }$, $p_{\cdot j}$ (и поэтому не
влияющий на оценки
 наибольшего правдоподобия).

Далее легко находим оценки наибольшего правдоподобия:
$$
\hat p_{i\cdot }=\frac{\mu_{i\cdot }}{n}, \hat p_{\cdot
j}=\frac{\mu_{\cdot j}}{n}\qquad \mbox{ для } i=\overline{1, r},
j=\overline{1, s}.
$$

Статистика $X^2_{n}$ из теоремы 2 здесь
$$
X^2_{n}=\sum\limits_{i=1}^{r}\sum\limits_{j=1}^{s}\frac{(\mu_{ij}-n\frac{\mu_{i\cdot
}}{n}\frac{\mu_{\cdot j}}{n})^2}{ n\frac{\mu_{i\cdot
}}{n}\frac{\mu_{\cdot j}}{n}}.
$$

При гипотезе независимости признаков
$$
X^2_{n}\stackrel{d}{\longrightarrow}\chi^2((r-1)(s-1)),
$$
ибо $rs-(r+s-2)-1=(r-1)(s-1)$.

Гипотезу независимости признаков следует отвергать, если наблюденное
(вычисленное) значение статистики $X^2_{n}$ слишком велико
 (по сравнению с квантилями распределения хи-квадрат с указанным числом
 степеней свободы).



\end{document}
